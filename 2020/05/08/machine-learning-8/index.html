

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/Blog/img/favicon.ico">
  <link rel="icon" href="/Blog/img/favicon.ico">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Daolin">
  <meta name="keywords" content="">
  
    <meta name="description" content="混淆矩阵 Confusion Matrix 精准率 Precision 和 召回率 Recall F1 Score-精准率和召回率的调和平均值  精准率召回率曲线 ROC曲线">
<meta property="og:type" content="article">
<meta property="og:title" content="python3入门机器学习(8)-评价分类结果">
<meta property="og:url" content="https://daolinzhou.github.io/Blog/2020/05/08/machine-learning-8/">
<meta property="og:site_name" content="Daolin&#39;s Repository">
<meta property="og:description" content="混淆矩阵 Confusion Matrix 精准率 Precision 和 召回率 Recall F1 Score-精准率和召回率的调和平均值  精准率召回率曲线 ROC曲线">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/intro/cureve_p_r.PNG">
<meta property="article:published_time" content="2020-05-08T21:32:34.000Z">
<meta property="article:modified_time" content="2020-06-02T20:34:39.775Z">
<meta property="article:author" content="Daolin">
<meta property="article:tag" content="python3">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://daolinzhou.github.io/Blog/intro/cureve_p_r.PNG">
  
  
  <title>python3入门机器学习(8)-评价分类结果 - Daolin&#39;s Repository</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/Blog/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"daolinzhou.github.io","root":"/Blog/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/Blog/local-search.xml"};
  </script>
  <script  src="/Blog/js/utils.js" ></script>
  <script  src="/Blog/js/color-schema.js" ></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/Blog/">
      <strong>Daolin&#39;s Repo</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/Blog/intro/longyin.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="python3入门机器学习(8)-评价分类结果">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-05-08 14:32" pubdate>
        2020年5月8日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      9.9k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      83 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">python3入门机器学习(8)-评价分类结果</h1>
            
            <div class="markdown-body">
              <link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><p>混淆矩阵 Confusion Matrix</p>
<p>精准率 Precision 和 召回率 Recall</p>
<p>F1 Score-精准率和召回率的调和平均值 </p>
<p>精准率召回率曲线</p>
<p>ROC曲线</p>
<span id="more"></span>
<h1 id="评价分类结果"><a href="#评价分类结果" class="headerlink" title="评价分类结果"></a>评价分类结果</h1><h2 id="分类算法的评价"><a href="#分类算法的评价" class="headerlink" title="分类算法的评价"></a>分类算法的评价</h2><p>逻辑回归算法是一个非常常用的分类算法</p>
<p>评价算法的好坏对于<strong>回归问题</strong>来说, MSE, MAE, RMSE, R<sup>2</sup>都是非常好的指标</p>
<p>但是对于<strong>分类算法</strong>来说, 至今为止只使用<strong>分类准确度</strong>这一个指标</p>
<p><br></p>
<h3 id="分类准确度的问题"><a href="#分类准确度的问题" class="headerlink" title="分类准确度的问题"></a>分类准确度的问题</h3><p>实际上分类准确度在评价算法时是有一个很重要的问题的</p>
<p><br></p>
<p>举一个例子:</p>
<p>一个癌症预测系统, 输入体检信息, 可以判断是否有癌症</p>
<p>假设做出来的系统的预测准确率99.9%</p>
<p>那么这个系统是一个好的系统还是不好的系统 ?</p>
<blockquote>
<p>99.9% 很高, 可能很多人都认为是一个好的系统, 然而实际上是不够好的</p>
</blockquote>
<p>如果在实际情况下, 癌症产生的概率只有0.1%, 那意味着我们的系统检测所有人都是健康, 即可达到99.9%的准确率. 因为只有0.1%的人有癌症</p>
<p>这样实际就相当于系统什么都没作, 但是准确度却达到了99.9%</p>
<blockquote>
<p>更极端一些, 癌症产生的概率只有0.01%, 那意味着我们的系统检测所有人都是健康, 即可达到99.99%的准确率</p>
<p>这意味着机器学习系统是失败的, 因为它比预测所有人都是健康的准确度更低</p>
</blockquote>
<p>这就是使用分类准确度衡量分类系统的问题所在</p>
<p><br></p>
<p>这样的问题发生在数据是极度偏斜的情况</p>
<p>对于<strong>极度偏斜(Skewed Data)的数据</strong>, 只使用<strong>分类准确度</strong>是远远不够的</p>
<p>对于这样的数据如果使用分类准确度的话, 可能得到一个非常高的分类准确度, 但其实算法是不够好的, 甚至是非常烂的</p>
<p>正因为这种情况, 所以需要引入其他的指标来判断分类算法的好坏</p>
<p><br></p>
<h2 id="混淆矩阵-Confusion-Matrix"><a href="#混淆矩阵-Confusion-Matrix" class="headerlink" title="混淆矩阵 Confusion Matrix"></a>混淆矩阵 Confusion Matrix</h2><p>对于二分类问题</p>
<p>混淆矩阵是一个2乘2的矩阵</p>
<p><img src="/Blog/intro/confusion_matrix.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>每一行代表对于要预测的问题的真实值</p>
<p>每一列代表分类算法预测的值</p>
<p><img src="/Blog/intro/confusion_matrix_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>依然从一个例子出发, 假设有10000人检测癌症, 1代表患病, 0代表不患病</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">真实\预测</th>
<th style="text-align:center">0</th>
<th style="text-align:center">1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>0</strong></td>
<td style="text-align:center">9978</td>
<td style="text-align:center">12</td>
</tr>
<tr>
<td style="text-align:center"><strong>1</strong></td>
<td style="text-align:center">2</td>
<td style="text-align:center">8</td>
</tr>
</tbody>
</table>
</div>
<p>对于这10000个人中,</p>
<p>有9978个人本身没有患癌症, 同时算法预测他们也没有患癌症. </p>
<p>有12个人没有患癌症, 但是算法却预测他们患癌症了</p>
<p>有2个人患癌症, 但是算法预测错误, 算法说他们没有患癌症</p>
<p>有8个人患癌症, 算法预测正确</p>
<p><br></p>
<h3 id="精准率和召回率"><a href="#精准率和召回率" class="headerlink" title="精准率和召回率"></a>精准率和召回率</h3><h3 id="精准率-precision"><a href="#精准率-precision" class="headerlink" title="精准率(precision)"></a>精准率(precision)</h3><script type="math/tex; mode=display">
precision = \frac {TP} {TP+FP}</script><p><img src="/Blog/intro/confusion_matrix_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>就是预测数据为1, 预测对了的概率是多少</p>
<p>分母是这一列的值的和, 而分子是预测对的值</p>
<p><br></p>
<p>为什么管他叫精准率</p>
<p><strong>因为通常在有偏的数据中, 我们将分类1作为真正关注的对象</strong></p>
<p>精准率就是预测<strong>我们关注的事件</strong>有多准,  <strong>我们做的所有为1的预测中有多少是正确的</strong></p>
<p>例如在医疗中将1作为真正的患病, 精准率, 就是预测癌症真正的成功率</p>
<p>精准率=40%就可以解释为: 每做100次患病预测, 平均会有40次预测是对的</p>
<p><br></p>
<h3 id="召回率-recall"><a href="#召回率-recall" class="headerlink" title="召回率(recall)"></a>召回率(recall)</h3><script type="math/tex; mode=display">
recall=\frac {TP}{TP+FN}</script><p><img src="/Blog/intro/confusion_matrix_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>召回率的分母真实值为1的那一行, 分子是真实值为1, 而预测值也为1的值</p>
<p><strong>召回率就是事件真实发生, 并且被我们正确预测的比例</strong></p>
<p>在这个例子中就是有10个癌症患者, 对于这10个癌症患者我们成功预测出了几个</p>
<p>召回率=80%可以解释为: 每当有100个癌症患者进行检测, 我们能成功找到80个癌症患者</p>
<p><br></p>
<blockquote>
<p>精准率是: 我们作100次分类为1的预测, 其中有几次是准确的</p>
<p>召回率是: 实际有100次分类为1的事件发生, 我们预测出几个</p>
</blockquote>
<p><img src="/Blog/intro/confusion_matrix_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="为什么说精准率和召回率是比分类准确度更好的指标"><a href="#为什么说精准率和召回率是比分类准确度更好的指标" class="headerlink" title="为什么说精准率和召回率是比分类准确度更好的指标?"></a>为什么说精准率和召回率是比分类准确度更好的指标?</h3><p>对于极度有偏的数据, 10000个人, 我们预测所有人都是健康的, 这种情况下</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">真实\预测</th>
<th style="text-align:center">0</th>
<th style="text-align:center">1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>0</strong></td>
<td style="text-align:center">9990</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center"><strong>1</strong></td>
<td style="text-align:center">10</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
</div>
<p>准确度为99.9%, 因为9990个人全都预测对了</p>
<p>精准率 = 0/(0+0) 无意义, 通常定义此时的精准率也为0, 因为它做了一个没有意义的事, 所以直接给它一个可能的最低值</p>
<p>召回率 = 0/(10+0) = 0</p>
<p>我们已经知道这个系统没有意义: 它对所有人的预测都为0</p>
<p>它的精准率是99.9%, 但它的精准率和召回率都是最低值</p>
<p>通过这两个指标判断出这个预测算法是完全没有用的</p>
<p><br></p>
<h3 id="编程实现"><a href="#编程实现" class="headerlink" title="编程实现"></a>编程实现</h3><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">TN</span>(<span class="hljs-params">y_true, y_predict</span>):<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(y_true) == <span class="hljs-built_in">len</span>(y_predict)<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>((y_true == <span class="hljs-number">0</span>) &amp; (y_predict == <span class="hljs-number">0</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">FP</span>(<span class="hljs-params">y_true, y_predict</span>):<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(y_true) == <span class="hljs-built_in">len</span>(y_predict)<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>((y_true == <span class="hljs-number">0</span>) &amp; (y_predict == <span class="hljs-number">1</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">FN</span>(<span class="hljs-params">y_true, y_predict</span>):<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(y_true) == <span class="hljs-built_in">len</span>(y_predict)<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>((y_true == <span class="hljs-number">1</span>) &amp; (y_predict == <span class="hljs-number">0</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">TP</span>(<span class="hljs-params">y_true, y_predict</span>):<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(y_true) == <span class="hljs-built_in">len</span>(y_predict)<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>((y_true == <span class="hljs-number">1</span>) &amp; (y_predict == <span class="hljs-number">1</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">confusion_matrix</span>(<span class="hljs-params">y_true, y_predict</span>):<br>    <span class="hljs-keyword">return</span> np.array([<br>        [TN(y_true, y_predict), FP(y_true, y_predict)],<br>        [FN(y_true, y_predict), TP(y_true, y_predict)]<br>    ])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">precision_score</span>(<span class="hljs-params">y_true, y_predict</span>):<br>    tp = TP(y_true, y_predict)<br>    fp = FP(y_true, y_predict)<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> tp / (tp + fp)<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">recall_score</span>(<span class="hljs-params">y_true, y_predict</span>):<br>    tp = TP(y_true, y_predict)<br>    fn = FN(y_true, y_predict)<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> tp / (tp + fn)<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    digits = datasets.load_digits()<br>    X = digits.data<br>    y = digits.target.copy()<br><br>    <span class="hljs-comment"># 手动让数据集偏斜, 只关注等于9的手写数字</span><br>    y[digits.target == <span class="hljs-number">9</span>] = <span class="hljs-number">1</span><br>    y[digits.target != <span class="hljs-number">9</span>] = <span class="hljs-number">0</span><br><br>    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="hljs-number">666</span>)<br>    log_reg = LogisticRegression()<br>    log_reg.fit(X_train, y_train)<br>    <span class="hljs-comment"># 0.975</span><br>    <span class="hljs-comment"># print(log_reg.score(X_test, y_test))</span><br>    y_log_predict = log_reg.predict(X_test)<br>    <span class="hljs-built_in">print</span>(TN(y_test, y_log_predict))  <span class="hljs-comment"># 403</span><br>    <span class="hljs-built_in">print</span>(FP(y_test, y_log_predict))  <span class="hljs-comment"># 2</span><br>    <span class="hljs-built_in">print</span>(FN(y_test, y_log_predict))  <span class="hljs-comment"># 9</span><br><br>    <span class="hljs-comment"># 精准率 0.9473</span><br>    <span class="hljs-built_in">print</span>(precision_score(y_test, y_log_predict))<br>    <span class="hljs-comment"># 召回率 0.8</span><br>    <span class="hljs-built_in">print</span>(recall_score(y_test, y_log_predict))<br></code></pre></td></tr></table></figure>
<p><br></p>
<p>scikit-learn中的混淆矩阵, 精准率和召回率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix, precision_score, recall_score<br><br><span class="hljs-comment"># scikit-learn中的混淆矩阵</span><br><span class="hljs-built_in">print</span>(confusion_matrix(y_test, y_log_predict))<br><span class="hljs-built_in">print</span>(precision_score(y_test, y_log_predict))<br><span class="hljs-built_in">print</span>(recall_score(y_test, y_log_predict))<br></code></pre></td></tr></table></figure>
<p>调用方式和我们自己写的是一样的</p>
<p><br></p>
<p>实际上只引入了两个指标: 精准率与召回率</p>
<p>其他的概念都是为这两个指标服务的. 但是对于两个指标应该如何解读?</p>
<p>比如说一种算法精准率高而召回率低, 另一种算法精准率低而召回率高. 此时对于这两种算法应该如何取舍.</p>
<p><br></p>
<p>和大多数机器学习取舍的答案是一样的, 应该视具体使用场景而定 </p>
<p>有的时候我们注重精准率. 如股票预测</p>
<p><strong>精准率描述的是: 我们做的所有为1的预测中有多少是正确的</strong></p>
<blockquote>
<p>我们预测股票上升, 相应的就要买入, 所以我们希望预测大部分是正确的</p>
<p>而可能有一些股票也上升, 但预测它会下降, 不买入并不会造成很大的损失, 此时我们是不关注的, 股票预测是不用考虑召回率的 </p>
<p>但如果判断上升, 但判断结果错误会带来损失</p>
</blockquote>
<p>而对于另外的一些场景, 召回率是比精准率重要的</p>
<p>最典型的就是在医疗领域</p>
<blockquote>
<p>召回率低就是说本来有一个病人得病了, 但我们没有预测出来, 病人的病情会继续恶化. 因此召回率非常重要, 我们希望把所有的有病患者都预测出来</p>
<p>但精准率低一些是没有关系的, 也就是有一些人没有病, 但我们却错误地认为他们有病. 此时让他们进行进一步的检查就好了</p>
<p>在更深一步的检查中可能就会发现他们没有病</p>
<p>此时False Positive只是让一些人群多做一些检查而已</p>
</blockquote>
<p><br></p>
<h2 id="F1-Score"><a href="#F1-Score" class="headerlink" title="F1 Score"></a>F1 Score</h2><p>有的时候我们可能不会这么极端, 而是希望获得两个指标的平衡, 同时关注精准率和召回率. 此时我们就会使用一种新的指标 <strong>F1 Score</strong></p>
<p>F1 Score的目的就是兼顾精准率和召回率两个指标</p>
<blockquote>
<p>如何兼顾两个指标? 一个简单的方法就是取二者的平均值.</p>
<p>F1 Score背后的理念和取二者的平均值是差不多的, 不过它的计算方法是这样一个式子</p>
</blockquote>
<script type="math/tex; mode=display">
F1 = \frac {2\cdot precision\cdot recall}{precision + recall}</script><p>F1 Score 是 precision 和 recall 的调和平均值</p>
<p><br></p>
<h3 id="什么是调和平均值"><a href="#什么是调和平均值" class="headerlink" title="什么是调和平均值?"></a>什么是调和平均值?</h3><script type="math/tex; mode=display">
\frac 1{F1}=\frac 12(\frac 1 {precision}+\frac1 {recall})</script><p>就是两个指标倒数的平均值是F1的倒数</p>
<p>F1就是调和平均值</p>
<p><br></p>
<p>为什么要取精准率和召回率的调和平均值?</p>
<p>调和平均值的一个特点就是<strong>如果二者极度不平衡, 得到的结果就会特别低</strong></p>
<p>只有这二者都非常高, 调和平均值才会非常高</p>
<blockquote>
<p>这是和算数平均值不同的地方, 算数平均值即使某一个非常低, 另一个非常高, 平均值也可能非常高</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">f1_score</span>(<span class="hljs-params">precision, recall</span>):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> (<span class="hljs-number">2</span> * precision * recall) / (precision + recall)<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span><br></code></pre></td></tr></table></figure>
<p><br></p>
<h2 id="Precision-Recall-的平衡"><a href="#Precision-Recall-的平衡" class="headerlink" title="Precision-Recall 的平衡"></a>Precision-Recall 的平衡</h2><p><img src="/Blog/intro/logic_reg_cost.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>逻辑回归的分类原理:</p>
<p>通过训练的过程找到一组参数θ, 这个参数和样本x点乘后的结果和0作比较. 如果大于等于0. 通过Sigmoid函数就可以说: 通过这个样本判定为1的概率是大于等于0.5的</p>
<p> 基于这样的算法就引出了决策边界这样一个概念</p>
<p><img src="/Blog/intro/balance_p_r.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>一个问题就出现了, 为什么让θ乘以x等于0? 如果设置任意一个常量</p>
<p><img src="/Blog/intro/balance_p_r_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>让这个阈值作为决策边界? 其实这样也形成了一个决策边界</p>
<p>这样的想法就相当于为回归算法引入了一个新的超参数</p>
<p>通过指定threshold, 可以平移决策边界对应的直线. 从而影响分类结果</p>
<p><br></p>
<p><img src="/Blog/intro/balance_p_r_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>假设我们关注的是五角星, 而threshold=0, 大于0, 就判定为五角星, 小于0判定为圆.</p>
<p>由此就可以得出相应的精准率和召回率</p>
<p>此时如果挪动阈值, 再求精准率和召回率:</p>
<p><img src="/Blog/intro/balance_p_r_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>随着阈值逐渐增大, 精准率逐渐升高, 召回率在逐渐降低</p>
<p>随着阈值逐渐减小, 精准率逐渐降低, 召回率在逐渐升高</p>
<p><strong>精准率和召回率是互相矛盾的变量</strong></p>
<p><br></p>
<h3 id="编程测试"><a href="#编程测试" class="headerlink" title="编程测试"></a>编程测试</h3><p>scikit-learn中没有设计可以改变阈值的函数</p>
<p>因此要想改变阈值, 要绕一个弯子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">log_reg.decision_function(X_test)<br></code></pre></td></tr></table></figure>
<p>decision_function 返回一个向量可以得到这组样本的score值</p>
<p>因此可以基于这个函数设计一个根据不同的阈值进行分类的函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 获得所有样本的score</span><br>decision_scores = log_reg.decision_function(X_test)<br><span class="hljs-comment"># 阈值为5, 进行过滤</span><br>y_predict_2 = np.array(decision_scores &gt;= <span class="hljs-number">5</span>, dtype=<span class="hljs-string">&#x27;int&#x27;</span>)<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">[[404   1]</span><br><span class="hljs-string"> [ 21  24]]</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-built_in">print</span>(confusion_matrix(y_test, y_predict_2))<br><span class="hljs-built_in">print</span>(precision_score(y_test, y_predict_2)) <span class="hljs-comment"># 0.96</span><br><span class="hljs-built_in">print</span>(recall_score(y_test, y_predict_2)) <span class="hljs-comment"># 0.53</span><br></code></pre></td></tr></table></figure>
<p><br></p>
<p>如果阈值为-5, 精准率和召回率分别是0.72, 0.88</p>
<p>如果阈值为0, 精准率和召回率分别是0.94, 0.8</p>
<p>如果阈值为5, 精准率和召回率分别是0.96, 0.53</p>
<p><br></p>
<p>那么具体设计一个分类算法时, threshold应该安装什么标准选取?</p>
<p><br></p>
<p>用可视化的方式再深度理解一下精准率和召回率之间的关系</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">precisions = []<br>recalls = []<br><span class="hljs-comment"># 每隔0.1个单位就计算一次精准率和召回率</span><br>thresholds = np.arange(np.<span class="hljs-built_in">min</span>(decision_scores), np.<span class="hljs-built_in">max</span>(decision_scores), <span class="hljs-number">0.1</span>)<br><span class="hljs-keyword">for</span> threshold <span class="hljs-keyword">in</span> thresholds:<br>    y_predict = np.array(decision_scores &gt;= threshold, dtype=<span class="hljs-string">&quot;int&quot;</span>)<br>    precisions.append(precision_score(y_test, y_predict))<br>    recalls.append(recall_score(y_test, y_predict))<br><br>plt.plot(thresholds, precisions)<br>plt.plot(thresholds, recalls)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/Blog/intro/cureve_p_r.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>显然蓝色的曲线是精确率, 它随着threshold的增大而增大, 而黄色的曲线是召回率, 它随着threshold的增大而降低</p>
<p><br></p>
<h2 id="精准率-召回率曲线"><a href="#精准率-召回率曲线" class="headerlink" title="精准率-召回率曲线"></a>精准率-召回率曲线</h2><p>把横轴看作精确率, 纵轴看作召回率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.plot(precisions, recalls)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/Blog/intro/cureve_p_r_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>随着precision增大, recall逐渐减小</p>
<p>在这个曲线上, 通常会看到一个非常陡峭的下降的点, 这个点就是精确率和召回率平衡最好的位置(在这之后召回率会急剧下降)</p>
<p><br></p>
<p>而在scikit-learn中有一个方法可以直接获得曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># thresholds的元素个数比Precision和recall少一个</span><br><span class="hljs-comment"># 最后一个Precision和recall是1和0, 没有对应的threshold</span><br>precisions, recalls, thresholds = precision_recall_curve(y_test, decision_scores)<br>plt.plot(thresholds, precisions[:-<span class="hljs-number">1</span>])<br>plt.plot(thresholds, recalls[:-<span class="hljs-number">1</span>])<br>plt.show()<br><br>plt.plot(precisions, recalls)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/Blog/intro/cureve_p_r_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/cureve_p_r_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>这个函数会根据数据自动寻找合适的threshold, 以及它认为最重要的那部分数据. 所以和自己画的图不一样</p>
<p>但是依然可以看出二者互相制约</p>
<p><br></p>
<p>precision-recall曲线整体是这样的</p>
<p><img src="/Blog/intro/cureve_p_r_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>假设有两个算法, 或者同一个算法中用两组超参数</p>
<p>每训练出一个模型就对应一个Precision-Recall曲线</p>
<p><img src="/Blog/intro/cureve_p_r_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>显然<strong>外面曲线的模型</strong>是优于里面曲线的模型的</p>
<p>所以如果一个模型<strong>PR曲线更靠外</strong>的话, 这个模型就更加好</p>
<p>于此我们可以看到, PR曲线可以作为选择模型, 选择算法, 选择超参数的一个指标</p>
<p><br></p>
<p>有的时候曲线更靠外这个说法有些抽象, 所以有时, 也会以<strong>曲线与X轴Y轴包裹的面积</strong>来衡量模型好坏. 面积越大, 模型越好</p>
<p>虽然如此, 但是通常我们不用PR曲线的面积来衡量模型的优劣, 而是使用了另外一根曲线和XY轴包裹的面积来衡量模型的优劣: ROC 曲线</p>
<p><br></p>
<p><br></p>
<h2 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h2><p>Receiver Operation Characteristic Curve</p>
<p>是一个统计学上经常使用的术语, 用于描述 TPR 和 FPR 之间的关系</p>
<p><br></p>
<h3 id="TPR"><a href="#TPR" class="headerlink" title="TPR"></a>TPR</h3><p>True Positive Rate的缩写, 有时也称为 Detection Rate</p>
<p><img src="/Blog/intro/tpr.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>其实TPR和Recall是一个意思</p>
<p>预测为1, 预测对了的数量. 占真实为1的百分比</p>
<p><br></p>
<h3 id="FPR"><a href="#FPR" class="headerlink" title="FPR"></a>FPR</h3><p>False Positive Rete的缩写</p>
<p><img src="/Blog/intro/fpr.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>预测为1, 但预测错了, 占真实值为0的百分比</p>
<p><br></p>
<p><img src="/Blog/intro/tpr_fpr.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>TPR和FPR依然存在联系</p>
<p>同样假设1为五角星, 是我们关注的, 0为圆圈. 分割线右边预测为1(五角星)</p>
<p><img src="/Blog/intro/tpr_fpr_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>threshold逐渐降低, FPR和TPR逐渐升高</p>
<p>FPR和TPR是呈现一个相一致的趋势, TPR越高, FPR也越高</p>
<p>为了提高TPR, 就要拉低threshold, 此时犯FP错误的概率也会增高</p>
<p><br></p>
<h3 id="编程绘制曲线"><a href="#编程绘制曲线" class="headerlink" title="编程绘制曲线"></a>编程绘制曲线</h3><p>实现TPR和FPR, 绘制曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">TPR</span>(<span class="hljs-params">y_true, y_predict</span>):<br>    tp = TP(y_true, y_predict)<br>    fn = FN(y_true, y_predict)<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> tp / (tp + fn)<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">FPR</span>(<span class="hljs-params">y_true, y_predict</span>):<br>    fp = FP(y_true, y_predict)<br>    tn = TN(y_true, y_predict)<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> fp / (fp + tn)<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0.0</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    digits = datasets.load_digits()<br>    X = digits.data<br>    y = digits.target.copy()<br><br>    <span class="hljs-comment"># 手动让数据集偏斜, 只关注等于9的手写数字</span><br>    y[digits.target == <span class="hljs-number">9</span>] = <span class="hljs-number">1</span><br>    y[digits.target != <span class="hljs-number">9</span>] = <span class="hljs-number">0</span><br><br>    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="hljs-number">666</span>)<br>    <span class="hljs-comment"># 获得模型</span><br>    log_reg = LogisticRegression()<br>    log_reg.fit(X_train, y_train)<br>    decision_scores = log_reg.decision_function(X_test)<br><br>    fprs = []<br>    tprs = []<br>    thresholds = np.arange(np.<span class="hljs-built_in">min</span>(decision_scores), np.<span class="hljs-built_in">max</span>(decision_scores), <span class="hljs-number">0.1</span>)<br>    <span class="hljs-keyword">for</span> threshold <span class="hljs-keyword">in</span> thresholds:<br>        y_predict = np.array(decision_scores &gt;= threshold, dtype=<span class="hljs-string">&quot;int&quot;</span>)<br>        fprs.append(FPR(y_test, y_predict))<br>        tprs.append(TPR(y_test, y_predict))<br>    plt.plot(fprs, tprs)<br>    plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/Blog/intro/tpr_fpr_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>scikit-learn中提供的ROC曲线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_curve<br><br>fprs, tprs, threshold = roc_curve(y_test, decision_scores)<br>plt.plot(fprs, tprs)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><br></p>
<p><img src="/Blog/intro/tpr_fpr_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>对于这条曲线来说, 我们通常关注曲线下方面积的大小</p>
<p>面积越大, 就说明分类效果越好</p>
<p>因为ROC曲线上ROC越小的时候, 也就是FPR越低的时候, 也就是犯False Positive的错误越少的时候, 如果曲线的值越高, 也就是TPR越大, 得到True Positive结果越多的时候. 曲线整体就会被抬的越高, 曲线下方面积就会越大, 此时分类算法就更好</p>
<p><br></p>
<h3 id="如何求这个面积"><a href="#如何求这个面积" class="headerlink" title="如何求这个面积"></a>如何求这个面积</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 自己实现的</span><br>dx = np.empty(<span class="hljs-built_in">len</span>(fprs)-<span class="hljs-number">1</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(fprs)-<span class="hljs-number">1</span>):<br>    dx[i] = fprs[i+<span class="hljs-number">1</span>]-fprs[i]<br><span class="hljs-built_in">print</span>(np.array(tprs[<span class="hljs-number">1</span>:]).dot(dx))<br><br><span class="hljs-comment"># scikit-learn中的方法</span><br><span class="hljs-comment"># Area Under the Curve</span><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_auc_score<br><span class="hljs-comment"># 0.98</span><br><span class="hljs-built_in">print</span>(roc_auc_score(y_test, decision_scores))<br></code></pre></td></tr></table></figure>
<p>面积最大为1</p>
<p>其实ROC-AUC对于非常有偏的数据并不敏感</p>
<p>不像Precision-Recall那样对有偏的数据那么敏感, 所以看模型的精准率和召回率是非常有必要的</p>
<p><br></p>
<p>那么ROC-AUC的用途在哪里?</p>
<p><img src="/Blog/intro/tpr_fpr_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>用途主要在于比较<strong>两个模型</strong>的优劣</p>
<p>两个算法, 两个模型, 或者同样一个算法的两组超参数得到的模型</p>
<p>这样的情况下, 应该选择ROC下方面积更大的模型. 我们认为这样的模型是一个更好的模型</p>
<p><br></p>
<p><br></p>
<h2 id="多分类问题中的混淆矩阵"><a href="#多分类问题中的混淆矩阵" class="headerlink" title="多分类问题中的混淆矩阵"></a>多分类问题中的混淆矩阵</h2><p>confusion_matrix天然支持多分类问题</p>
<p>和二分类问题中的混淆矩阵解读的方式的一样的</p>
<p>矩阵中是第i行第j列的位置, 行这个方向代表真值, 列方向代表预测值</p>
<p>因此真值为 i , 我们预测为 j 的样本数量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(confusion_matrix(y_test, y_predict))<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">[[147,   0,   1,   0,   0,   1,   0,   0,   0,   0],</span><br><span class="hljs-string"> [  0, 123,   1,   2,   0,   0,   0,   3,   4,  10],</span><br><span class="hljs-string"> [  0,   0, 134,   1,   0,   0,   0,   0,   1,   0],</span><br><span class="hljs-string"> [  0,   0,   0, 138,   0,   5,   0,   1,   5,   0],</span><br><span class="hljs-string"> [  2,   5,   0,   0, 139,   0,   0,   3,   0,   1],</span><br><span class="hljs-string"> [  1,   3,   1,   0,   0, 146,   0,   0,   1,   0],</span><br><span class="hljs-string"> [  0,   2,   0,   0,   0,   1, 131,   0,   2,   0],</span><br><span class="hljs-string"> [  0,   0,   0,   1,   0,   0,   0, 132,   1,   2],</span><br><span class="hljs-string"> [  1,   9,   2,   3,   2,   4,   0,   0, 115,   4],</span><br><span class="hljs-string"> [  0,   1,   0,   5,   0,   3,   0,   2,   2, 134]]</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<p>对角线位置的元素最大, 就是数字本身就是i, 同时我们预测为i. 就是说算法犯的错误还是比较少的</p>
<p>不过在一些位置还是会犯一些错误, 可以通过绘制矩阵直观地看到犯错误比较多的地方</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">cfm = confusion_matrix(y_test, y_predict)<br>plt.matshow(cfm, cmap=plt.cm.gray)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/Blog/intro/tpr_fpr_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>这个图中, 越亮的地方代表数值越大, 越暗的地方数值越小, 对角线的方块是最亮的, 之后少数错误</p>
<p>然而我们关注的是犯错的地方在哪, 所以在对矩阵进行相应的一些处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">row_sums = np.<span class="hljs-built_in">sum</span>(cfm, axis=<span class="hljs-number">1</span>)<br>err_matrix = cfm / row_sums<br><span class="hljs-comment"># 不关系预测正确的元素, 所以对角线填充为0</span><br>np.fill_diagonal(err_matrix, <span class="hljs-number">0</span>)<br>plt.matshow(err_matrix, cmap=plt.cm.gray)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/Blog/intro/tpr_fpr_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>越亮的地方, 犯的错误越多. 有了这样的提示就可以改进算法了</p>
<p>改进方式就是: 得到的结果又把它规约成了一个二分类问题, 换句话说, 现在多分类问题算法结果很容易混淆1和9, 以及1和8</p>
<p>所以我们可以微调 1和9,1和8 这两个二分类问题中的threshold来提高整体多分类问题的准确度</p>
<blockquote>
<p>也有可能问题的出现不在算法层面上, 有可能在样本数据的层面上</p>
<p>所以此时最好拿出样本看看来直观地理解为什么会有这样的分类错误产生</p>
<p>很有可能样本数据也有一定的问题, 即使样本数据没有问题, 通过这样的观察, 我们也很有可能总结出新的样本特征</p>
</blockquote>
<p><br></p>
<p><br></p>
<h2 id="基于混淆矩阵的其他评估指标"><a href="#基于混淆矩阵的其他评估指标" class="headerlink" title="基于混淆矩阵的其他评估指标"></a>基于混淆矩阵的其他评估指标</h2><p><img src="/Blog/intro/cf_oth.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/Blog/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/Blog/tags/python3/">python3</a>
                    
                      <a class="hover-with-bg" href="/Blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/Blog/2020/05/09/machine-learning-9/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">python3入门机器学习(9)-SVM支撑向量机</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/Blog/2020/05/05/machine-learning-7/">
                        <span class="hidden-mobile">python3入门机器学习(7)-逻辑回归</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/Blog/js/events.js" ></script>
<script  src="/Blog/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/Blog/js/local-search.js" ></script>



  
    <script  src="/Blog/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/Blog/js/boot.js" ></script>


</body>
</html>
