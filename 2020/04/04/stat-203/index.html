

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/Blog/img/favicon.ico">
  <link rel="icon" href="/Blog/img/favicon.ico">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Daolin">
  <meta name="keywords" content="">
  
    <meta name="description" content="FIC 统计-203 的重点知识">
<meta property="og:type" content="article">
<meta property="og:title" content="统计自整理">
<meta property="og:url" content="https://daolinzhou.github.io/Blog/2020/04/04/stat-203/">
<meta property="og:site_name" content="Daolin&#39;s Repository">
<meta property="og:description" content="FIC 统计-203 的重点知识">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/intro/stat_u_dependence_what.PNG">
<meta property="article:published_time" content="2020-04-04T20:01:30.000Z">
<meta property="article:modified_time" content="2022-04-25T17:08:15.037Z">
<meta property="article:author" content="Daolin">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="统计学">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://daolinzhou.github.io/Blog/intro/stat_u_dependence_what.PNG">
  
  
  <title>统计自整理 - Daolin&#39;s Repository</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/Blog/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"daolinzhou.github.io","root":"/Blog/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/Blog/local-search.xml"};
  </script>
  <script  src="/Blog/js/utils.js" ></script>
  <script  src="/Blog/js/color-schema.js" ></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/Blog/">
      <strong>Daolin&#39;s Repo</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/Blog/intro/science_gate_time.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="统计自整理">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-04-04 13:01" pubdate>
        2020年4月4日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      17k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      142 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">统计自整理</h1>
            
            <div class="markdown-body">
              <link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><p>FIC 统计-203 的重点知识<span id="more"></span></p>
<h2 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h2><p>一个正态分布长这样</p>
<p><img src="/Blog/intro/Normal_distribution.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<h5 id="u决定了什么"><a href="#u决定了什么" class="headerlink" title="u决定了什么"></a>u决定了什么</h5><p>固定σ = 1, 而变化u的正态分布函数</p>
<p><img src="/Blog/intro/stat_u_dependence_what.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>红色图形的对称轴在 x=-2</p>
<p>绿色图形的对称轴在 x=0</p>
<p>蓝色图形的对称轴在 x=2</p>
<p>可以看出, u决定了这个图形的对称轴在哪里</p>
<p><br></p>
<h5 id="σ决定了什么"><a href="#σ决定了什么" class="headerlink" title="σ决定了什么"></a>σ决定了什么</h5><p>固定u = 0, 即对称轴在0, 变化 σ 的正态分布函数</p>
<p><img src="/Blog/intro/stat_u_dependence_what_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>σ = 0.5 的图形是最窄的, 也是最高的</p>
<p>σ = 1 时位于中间</p>
<p>σ = 2 的图形是最宽的, 也是最矮的</p>
<p>σ决定的是这个曲线的高低和胖瘦</p>
<p><br></p>
<p>u就是这个分布的均值(期望值), σ就是分布的标准差</p>
<p><br></p>
<h4 id="正态分布的特征"><a href="#正态分布的特征" class="headerlink" title="正态分布的特征"></a>正态分布的特征</h4><p>并不是所有这样的曲线都叫正态分布, 正态分布有着独有的特征</p>
<p><img src="/Blog/intro/Normal_distribution_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Normal_distribution_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<ul>
<li><p>u - σ, u + σ 之间的面积为 68.26%, 也就是说, 在正态分布中, 数值落在(u - σ, u + σ) 的概率为 68.26%</p>
</li>
<li><p>u - 2σ, u + 2σ 之间的面积为 95.44%, 也就是说, 在正态分布中, 数值落在(u - 2σ, u + 2σ) 的概率为 95.44%</p>
</li>
<li><p>u - 3σ, u + 3σ 之间的面积为 99.74%, 也就是说, 在正态分布中, 数值落在(u - 3σ, u + 3σ) 的概率为 99.74%</p>
</li>
</ul>
<p>因此正态分布有3σ法则</p>
<p><strong>3σ法则</strong>: 正态变量的取值范围是正负无穷, 但它的值几乎肯定落在(u-3σ, u+3σ)</p>
<p>满足这些性质的, 同时长成这个样子的曲线, 才叫正态分布</p>
<p><br></p>
<h3 id="标准正态分布"><a href="#标准正态分布" class="headerlink" title="标准正态分布"></a>标准正态分布</h3><p>当u=0, σ=1时的分布我们称为<strong>标准正态分布</strong></p>
<p><img src="/Blog/intro/Normal_distribution_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>右上角是当X服从正态分布时, 如何求得Z服从标准正态分布</p>
<p><br></p>
<h4 id="上-下-α分位点"><a href="#上-下-α分位点" class="headerlink" title="(上/下)α分位点"></a>(上/下)α分位点</h4><p><img src="/Blog/intro/Normal_distribution_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>让Zα之上的面积等于α, 若α大于0小于1, 则称Zα为标准正态分布的上α分位点</p>
<p>同理, 让Zα之下的面积等于α, 若α大于0小于1, 则称Zα为标准正态分布的下α分位点</p>
<p><br></p>
<p>正态分布有一个特别有用的性质, 如果X服从任意正态分布</p>
<p><img src="/Blog/intro/normal_dis.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>我们可以把X转化为z值在计算, z服从标准正态分布, 可以使用</p>
<p>查值来找到对应的值</p>
<p>z = (x - E(X)) / sqrt(V(X))</p>
<p><br></p>
<h2 id="期望值和方差"><a href="#期望值和方差" class="headerlink" title="期望值和方差"></a>期望值和方差</h2><p>随机试验: 抛3次硬币, 我们对 <strong>X=正面朝上的次数</strong> 感兴趣</p>
<p>X的可能值: 0, 1, 2, 3</p>
<p><img src="/Blog/intro/expect_value.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>一共有2的立方种可能, k面朝上的次数为(3 choose k)</p>
<p><strong>PMF(probability Mass Function)</strong></p>
<p>离散型随机变量的分布函数: Distribution function for a discrete random variable</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">X</th>
<th style="text-align:center">0</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P(X)</td>
<td style="text-align:center">1/8</td>
<td style="text-align:center">3/8</td>
<td style="text-align:center">3/8</td>
<td style="text-align:center">1/8</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<p>随机试验2: 抛一枚不公平的硬币3次, P(head) = 1/3</p>
<p><strong>Y=正面朝上的次数</strong></p>
<p><img src="/Blog/intro/expect_value_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>PMF:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Y</th>
<th style="text-align:center">0</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P(Y)</td>
<td style="text-align:center">8/27</td>
<td style="text-align:center">12/27</td>
<td style="text-align:center">6/27</td>
<td style="text-align:center">1/27</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<h3 id="期望值"><a href="#期望值" class="headerlink" title="期望值"></a>期望值</h3><p>期望值也可以理解成均值</p>
<blockquote>
<p>我常用的一种方法就是:</p>
<p>以随机试验2举例, Y的每个取值都有一个可能性</p>
<p>假设有27个数, 这27个数由 8个0, 12个1, 6个2, 1个3 组成, 求E(Y)就等于求这27个数的均值</p>
</blockquote>
<p><img src="/Blog/intro/expect_value_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<h3 id="期望值的性质"><a href="#期望值的性质" class="headerlink" title="期望值的性质"></a>期望值的性质</h3><ol>
<li>E(c <em> W) = c </em> E(W), c是常数</li>
<li>E(c) = c,  c是常数: 可以理解为求c的均值, c的均值就是c</li>
<li>E(W+T) = E(W)+E(T), W和T是<strong>任意</strong>随机变量, W和T可能有关也可能无关</li>
</ol>
<p><br></p>
<h3 id="方差-标准误"><a href="#方差-标准误" class="headerlink" title="方差/标准误"></a>方差/标准误</h3><p><img src="/Blog/intro/expect_value_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>W-E(W): W到均值/中心的距离/偏差</p>
<p>(W-E(W))^2: W到均值/中心的距离/偏差 的平方</p>
<p>E{(W-E(W))^2}: 期望/平均 到距离的平方</p>
<p><br></p>
<p>例如:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">X</th>
<th style="text-align:center">0</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P(X)</td>
<td style="text-align:center">1/8</td>
<td style="text-align:center">3/8</td>
<td style="text-align:center">3/8</td>
<td style="text-align:center">1/8</td>
</tr>
</tbody>
</table>
</div>
<p>E(X) = 1.5</p>
<p><img src="/Blog/intro/expect_value_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="方差的性质"><a href="#方差的性质" class="headerlink" title="方差的性质"></a>方差的性质</h3><p><img src="/Blog/intro/expect_value_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="伯努利试验"><a href="#伯努利试验" class="headerlink" title="伯努利试验"></a>伯努利试验</h2><p><img src="/Blog/intro/bernoulli_trials.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/bernoulli_trials_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/bernoulli_trials_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/bernoulli_trials_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="抽样"><a href="#抽样" class="headerlink" title="抽样"></a>抽样</h2><p>The procedure of systematically acquiring and recording information about every member of the given target population - census (系统地获取和记录有关给定目标人群的每个成员的信息的过程-census)</p>
<p><strong>如果选择样本的方法是偏向于某些群体的, 那么这个样本是biased: 例如: 自愿相应的调查通常都是有倾向的</strong></p>
<ul>
<li><p>方便抽样(Convenience sampling) : <strong>非随机抽样</strong>, 是一种为配合研究主题而由调查者于特定的时间和特定社区的某一位置上，随意选择回答者的非概率抽样方法</p>
</li>
<li><p>判断抽样 (Judgement sampling) : <strong>非随机抽样</strong>, 研究人员依其自己对所要选择的回答者的判断，只拣那些最适于该项研究目的者.</p>
</li>
<li>配额抽样(<em>Quota</em> <em>Sampling</em>) :  <strong>非随机抽样</strong>, 指调查人员将调查总体样本按一定标志分类或分层，确定各类（层）单位的样本数额，在配额内任意抽选样本的抽样方式</li>
<li>雪球抽样 (Snowball sampling) : <strong>非随机抽样</strong>滚雪球抽样是指先随机选择一些被访者并对其实施访问，再请他们提供另外一些属于所研究目标总体的调查对象，根据所形成的线索选择此后的调查对象</li>
</ul>
<h3 id="简单随机抽样-Simple-Random-Samples"><a href="#简单随机抽样-Simple-Random-Samples" class="headerlink" title="简单随机抽样: Simple Random Samples"></a>简单随机抽样: Simple Random Samples</h3><p>Simple Random Samples means drawing at random <strong>without</strong> replacement</p>
<p>without replacement: 取完之后不放回</p>
<p>with replacement: 取完之后放回</p>
<p>例如从1, 2, 3, 4中随机取3个数</p>
<p>without replacement: 4 choose 3 = 4</p>
<p>with replacement: 4^3 = 64</p>
<p>使用Simple Random Samples, 总体中所有的个体都有同等的机会被选中, 同样大小的样本被选中的机会也是相同的 </p>
<p><br></p>
<h3 id="分层抽样-stratified-random-sampling"><a href="#分层抽样-stratified-random-sampling" class="headerlink" title="分层抽样-stratified random sampling"></a>分层抽样-stratified random sampling</h3><p>分层随机抽样，又称类型随机抽样，它是先将总体各单位按一定标准分成各种类型（或层）；然后根据各类型单位数与总体单位数的比例，确定从各类型中抽取样本单位的数量；最后，按照随机原则从各类型中抽取样本。</p>
<p>比如，我们要了解某市400个国营企业的生产经营情况，决定采取类型随机抽样法抽取20个企业作为样本进行调查，其具体做法是：首先，将这400个企业按产业（也可按行政区划、盈利情况、规模大小等）分为三类，假定第一产业40个，第二产业200个，第三产业160个。然后，按各类企业在总体中的比重，确定各类企业抽取样本单位的数量。其中，第一产业的企业占总体10%，按比例应抽样本企业2个；按同样方法计算，第二产业中应抽样本企业10个，第三产业中应抽样本企业8个。最后，采用简单随机抽样或等距随机抽样方法，从各类企业中抽出上述数量的样本单位。</p>
<p><br></p>
<h3 id="系统随机抽样"><a href="#系统随机抽样" class="headerlink" title="系统随机抽样"></a>系统随机抽样</h3><p>系统随机抽样也称机械随机抽样或等距随机抽样，即将总体单位按某一标志(如时间)排序，然后按一定间隔来随机抽取样本单位。例如，要从100件产品中抽取10件组成样本，首先将100件产品按某一标志排序，顺序编号为1～100；然后用抽签或查随机数表的方法确定1～10号中入选样本的编号(假定为4号)；然后按等距原则依次确定入选样本的产品编号为14、24、34、44、54、64、74、84、94；最后由编号为4、14、24、34、44、54、64、74、84、94的10件产品组成样本。</p>
<p><br></p>
<blockquote>
<p>简单随机抽样的个体和系统随机抽样的个体被抽取几率是相同的, </p>
<p>如果总体容量为p, 样本容量为s, 则每一个个体被抽取的概率为s/p</p>
<p>简单随机抽样: (p-1 choose s-1) / (p choose s) = s / p</p>
<p>系统随机抽样:  1 / (p/s) = s / p</p>
<p>但是简单随机抽样中所有样本的抽取概率都是一样的, 而系统随机抽样不是</p>
</blockquote>
<p><br></p>
<p><br></p>
<h2 id="抽样分布"><a href="#抽样分布" class="headerlink" title="抽样分布"></a>抽样分布</h2><p><strong>参数和统计量的定义:</strong></p>
<p>参数(parameter): 一个描述总体(population)的数, 通常是未知的.</p>
<p>统计量(statistic): 通过样本计算出来的值, 我们会用样本的统计量来推测总体的参数</p>
<p><br></p>
<p>例如: 一个箱子中有1, 1, 2, 4 这4个球, make n draw <strong>with replacement</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Possible Value</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">4</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">How often</td>
<td style="text-align:center">2</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">How likely</td>
<td style="text-align:center">50%</td>
<td style="text-align:center">25%</td>
<td style="text-align:center">25%</td>
</tr>
</tbody>
</table>
</div>
<p>假设我们 make 3 draw (2, 2, 1), 这就是一个样本(sample)</p>
<p>sample max = max(2, 2, 1) = 2</p>
<p>sample total = 2+2+1 = 5</p>
<p>sample mean = sample total / n = 5/3</p>
<p><br></p>
<p>当n=1时, Sample Total = X1+X2…+Xn = X1</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Total</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">4</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">p[Total]</td>
<td style="text-align:center">50%</td>
<td style="text-align:center">25%</td>
<td style="text-align:center">25%</td>
</tr>
</tbody>
</table>
</div>
<p>conclusion: When sample size is one, the sample distribution is the same as the population distribution</p>
<p><br></p>
<p>当n=2时, Sample Total = X1+X2…+Xn = X1+X2</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Total</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>8</th>
</tr>
</thead>
<tbody>
<tr>
<td>p[Total]</td>
<td>4/16</td>
<td>4/16</td>
<td>1/16</td>
<td>4/16</td>
<td>2/16</td>
<td>1/16</td>
</tr>
</tbody>
</table>
</div>
<p>P[Total = 2] = P[X1+X2=2] = P[X1 = 1 and X2 = 1] = P(1, 1) = 2/4 * 2/4 = 4/16</p>
<p>P[Total = 3] = P(1, 2) + P(2, 1) = 2/4 <em> 1/4 + 1/4 </em> 2/4 = 4/16</p>
<p>… …</p>
<p>P[Total = 8] = P(4, 4) = 1/16</p>
<p>\<Comments> : A legitimate probability distribution for a discrete random variable W:</p>
<ol>
<li>for all possible w, p(w) &gt;= 0</li>
<li>Σ<sub>all w</sub> P(w) = 1</li>
</ol>
<p><br></p>
<p>在n=2的情况下, 说sample total = 2 等价于说sample mean=1</p>
<p>P(total = 2) = P(AVG<sub>x</sub> = 1) 二者是等价的</p>
<p>即在 n=2 的情况下</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Total</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
</tr>
</thead>
<tbody>
<tr>
<td>AVG<sub>x</sub></td>
<td>1</td>
<td>1.5</td>
<td>2</td>
<td>2.5</td>
<td>3</td>
</tr>
<tr>
<td>p[Total]</td>
<td>4/16</td>
<td>4/16</td>
<td>1/16</td>
<td>4/16</td>
<td>2/16</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<p>问题: 求P[2 &lt;= AVG<sub>x</sub> &lt;= 3] 当n=25时.</p>
<p>P[2 &lt;= AVG<sub>x</sub> &lt;= 3]  = P[50 &lt;= total &lt;= 75] = P[total=50] + P[total=51] … + P[total=75]</p>
<p><img src="/Blog/intro/clt.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>很显然, 当样本容量很大时, 计算一个统计量的样本分布会变得非常复杂</p>
<p><br></p>
<h2 id="中心极限定理-Central-Limit-Theorem"><a href="#中心极限定理-Central-Limit-Theorem" class="headerlink" title="中心极限定理(Central Limit Theorem)"></a>中心极限定理(Central Limit Theorem)</h2><p>Given {X1, X2, X3, …, Xn} is a sequence of <strong>independently and identically distributed</strong><br><strong>random variables</strong>(或者说 simple random sample) with common mean <strong>E(X1) = μ</strong> and common variance <strong>V(X1) = σ^2.</strong></p>
<p><img src="/Blog/intro/clt_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>如果X不服从伯努利分布:</p>
<p><img src="/Blog/intro/clt_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>如果X服从伯努利分布:</p>
<p><img src="/Blog/intro/clt_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>回到原来的问题: 求P[2 &lt;= AVG<sub>x</sub> &lt;= 3] 当n=25时.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Total</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">4</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">p[Total]</td>
<td style="text-align:center">50%</td>
<td style="text-align:center">25%</td>
<td style="text-align:center">25%</td>
</tr>
</tbody>
</table>
</div>
<p>E(X) = 1 <em> 50% + 2 </em> 25% + 4 * 25% = 2</p>
<p>V(X) = (1-2)^2 <em> 50% + (2-2)^2 </em> 25% + (4-2)^2 * 25% = 1.5</p>
<p>μ = 2, σ^2=1.5</p>
<p>而AVG<sub>x</sub>~N(μ, σ^2/n)</p>
<p>现在就可以把x转为z值</p>
<p><img src="/Blog/intro/clt_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>也可以使用total来计算 Total~N(nμ, n * σ^2)</p>
<p><img src="/Blog/intro/clt_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="统计推断-statistical-inferences"><a href="#统计推断-statistical-inferences" class="headerlink" title="统计推断(statistical inferences)"></a>统计推断(statistical inferences)</h2><p>使用样本的数据推断总体的参数</p>
<p>分为: 点估计, 区间估计, 假设检验 三个部分</p>
<p><br></p>
<p>例子: 抛100次硬币, 观察到40次正面朝上, 是否是一枚公平的硬币</p>
<h3 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h3><p>用AVG<sub>x</sub> 来估计π, 即用sample% 估计 population%</p>
<p>40/100 = 0.4</p>
<p>即我们猜测硬币证明朝上的概率为0.4.</p>
<p>但是显然, 这种方法的准确性低.</p>
<p><br></p>
<h3 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h3><p>因此相比于估计一个点, 我们改为估计一个区间(置信区间)</p>
<p>我们估计(AVG<sub>x</sub>-h, AVG<sub>x</sub>+h) 有一定可能性包含我们想猜测的参数 π或μ (population%, 或 population mean)</p>
<p>可能性通常取99%, 95%, 90%</p>
<p>h被称为Margin of Error</p>
<p><br></p>
<p>假设使用95%的置信区间</p>
<p>AVG<sub>x</sub>~N[E(AVG<sub>x</sub>), V(AVG<sub>x</sub>)]</p>
<p><img src="/Blog/intro/clt_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_9.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_10.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_11.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_12.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_13.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="Wald-CI-AC-interval-二项分布的置信区间"><a href="#Wald-CI-AC-interval-二项分布的置信区间" class="headerlink" title="Wald CI, AC-interval(二项分布的置信区间)"></a>Wald CI, AC-interval(二项分布的置信区间)</h3><p>Proportion, Probability, Prevalence在这里说的都是一个东西</p>
<p>求区间的方式:</p>
<script type="math/tex; mode=display">
(\bar X - z^ * \frac \sigma {\sqrt n}, \bar X + z^ * \frac \sigma {\sqrt n})</script><p>然而在二项分布中我们是不知道$\sigma$的, 因为二项分布中var(X) = p(1-p). 知道总体方差就相当于知道总体均值.</p>
<p>因此我们的信息只有样本均值($\hat p=\bar X$)和样本方差.</p>
<p><img src="/Blog/intro/waldci.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>因此我们使用Wald CI.</p>
<p><img src="/Blog/intro/waldci_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><img src="/Blog/intro/2wdci.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h4 id="Wald-CI的缺点"><a href="#Wald-CI的缺点" class="headerlink" title="Wald CI的缺点:"></a>Wald CI的缺点:</h4><p><img src="/Blog/intro/waldci_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/waldci_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/waldci_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/waldci_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>一个简单的解决方法就是添加假数据 (fake data).</p>
<p>我们添加4个数据, 2个成功的数据2个失败的数据. 这样得到的区间(A-C interval)比Wald interval更好</p>
<p>example:</p>
<p>原本n=1000, p = 3/1000</p>
<p>添加4个数据后, $\widetilde n = 1004, \widetilde p = 5/1004$</p>
<p>此时根据$\widetilde n, \widetilde p$计算的区间更准确</p>
<p><br></p>
<p>为什么添加4个数据? 这取决于alpha.</p>
<h4 id="general-Agresti-Coull-interval"><a href="#general-Agresti-Coull-interval" class="headerlink" title="general Agresti-Coull interval"></a>general Agresti-Coull interval</h4><p><img src="/Blog/intro/waldci_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>example:</p>
<p>原本n=1000, p = 3/1000</p>
<p><img src="/Blog/intro/waldci_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>r code</p>
<figure class="highlight r"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><pre><code class="hljs R"><span class="hljs-comment">########## BRCA Example</span><br><br><span class="hljs-comment">#Install binGroup package once using install.packages(&quot;binGroup&quot;)</span><br>library<span class="hljs-punctuation">(</span>binGroup<span class="hljs-punctuation">)</span><br><br><span class="hljs-comment">#Define sample size and number of successes in the sample (real, not fake!):</span><br>n<span class="hljs-operator">=</span><span class="hljs-number">1000</span><br>nsuccesses<span class="hljs-operator">=</span><span class="hljs-number">3</span><br><br><span class="hljs-comment">#95% Wald CI for p -- not recommended!</span><br>binWald<span class="hljs-punctuation">(</span>n<span class="hljs-punctuation">,</span>nsuccesses<span class="hljs-punctuation">,</span>conf.level<span class="hljs-operator">=</span><span class="hljs-number">0.95</span><span class="hljs-punctuation">)</span> <br><br><span class="hljs-comment">#99% Agresti-Coull CI for p:</span><br>binAC<span class="hljs-punctuation">(</span>n<span class="hljs-punctuation">,</span>nsuccesses<span class="hljs-punctuation">,</span>conf.level<span class="hljs-operator">=</span><span class="hljs-number">0.99</span><span class="hljs-punctuation">)</span> <br></code></pre></td></tr></table></figure>
<p><br></p>
<p>对于2-sample 也是一样</p>
<p><img src="/Blog/intro/2acci.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>假设我们要添加4个fake data.</p>
<p>np 和 nv 就各要+2. </p>
<p><br></p>
<p><br></p>
<h3 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h3><p>核心思想: 假设一件事情为真, 判断当前情况即更极端的情况发生的概率</p>
<p>例如: 一对情侣, 男生99%次上街都会看其他的女生, 假设这个男生爱他的女朋友, 那么99%次上街都会看其他的女生的概率就非常低, 属于近乎不可能发生的事件, 但这样一个事件却发生了, 说明假设错误, 即这个男生不爱他的女朋友</p>
<p><br></p>
<p>同样的道理, 抛100次硬币40次正面朝上, 假设这枚硬币是公平的, 即证明朝上的概率为50%, 判断40次及以下正面朝上的概率</p>
<p>即Type I error: p[Type I error] = p[ reject H0|under H0 is True ]</p>
<p>如果概率小于阈值(通常选择5% 或 1%), 则认为是小概率事件, 拒绝零假设.</p>
<p>具体步骤:</p>
<blockquote>
<p><strong>\<step 1></strong> </p>
<p>H0 : π = 1/2 (即证明朝上的概率为50%)</p>
<p>Ha : π != 1/2 (证明朝上的概率不为50%)</p>
<p><strong>\<step 2></strong></p>
<p>选 α = 5%, 即进行20次实验, 才会出现一次40次或更极端正面朝上</p>
<p><strong>\<step 3></strong></p>
<p><img src="/Blog/intro/hyposis_testing.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><strong>\<step 4></strong></p>
<p><img src="/Blog/intro/hyposis_testing_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
</blockquote>
<p><br></p>
<h4 id="Hypothesis-Testing-The-2nd-approach"><a href="#Hypothesis-Testing-The-2nd-approach" class="headerlink" title="Hypothesis Testing - The 2nd approach"></a>Hypothesis Testing - The 2nd approach</h4><p>除了上面的这个方法, 还有第二种计算方式</p>
<p><img src="/Blog/intro/hyposis_testing_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h4 id="Hypothesis-Testing-P-Value-approach"><a href="#Hypothesis-Testing-P-Value-approach" class="headerlink" title="Hypothesis Testing - P-Value approach"></a>Hypothesis Testing - P-Value approach</h4><p>第三种计算方式, 计算P值(可能性) 和 α 比较</p>
<p><strong>\<step 1></strong></p>
<p>H0(Null Hypothesis) : the coin is fair</p>
<p>Ha(Alternative Hypothesis) : H0 is not true </p>
<p>注意这里Ha有三种选择, π &gt; 1/2, π &lt; 1/2 (这两个称为 one-side alternative), π != 1/2(包含π &gt; 1/2, π &lt; 1/2, 称为2-side alternative)</p>
<blockquote>
<p>注意:</p>
<ol>
<li><p>我们推测的是总体的参数而不是样本的数据, H0: π = 1/2, 而不是 AVG_x = 1/2, 因为当有样本数据时AVG_x就是一个固定的常量</p>
</li>
<li><p>Ha选择那个是基于research interest, 而不是基于收集到的数据不能因为AVG_x &lt; 1/2就选择Ha:π &lt; 1/2</p>
</li>
<li>H0要包含等于, 即不能是H0:π != 1/2 , Ha:π = 1/2. 必须是H0:π = 1/2 , Ha:π != 1/2</li>
</ol>
</blockquote>
<p><strong>\<step 2></strong></p>
<p>选 α = 5%</p>
<p><strong>\<step 3></strong></p>
<p>用sample%(AVG_x)去推测population%(π)</p>
<p>AVG_x = 40/100 = 0.4</p>
<p><strong>\<step 4></strong></p>
<p>计算p值</p>
<p><img src="/Blog/intro/hyposis_testing_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>p=4.56% &lt; 5%</p>
<p>因此拒绝H0</p>
<p><strong>注意</strong>: 在假设检验中, 我们不说接受H0, 而是说不拒绝H0, 保留H0, 或者拒绝H0失败</p>
<p>因为有可能硬币不是1/2的概率而是51/100的概率, 他们很相似, 但却不一样.</p>
<p><strong>注意:</strong> 双尾检验的p值是单尾检验时的二倍</p>
<p><br></p>
<p><br></p>
<h3 id="Hypothesis-test-of-a-difference-in-Proportions"><a href="#Hypothesis-test-of-a-difference-in-Proportions" class="headerlink" title="Hypothesis test of a difference in Proportions"></a>Hypothesis test of a difference in Proportions</h3><p><img src="/Blog/intro/hypothesis_diff_proportion.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/hypothesis_diff_proportion_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<script type="math/tex; mode=display">
\hat p_0 = \frac {p_1n_1+p_2n_2}{n_1+n_2}</script><p><img src="/Blog/intro/hypothesis_diff_proportion_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h3 id="统计功效-Power"><a href="#统计功效-Power" class="headerlink" title="统计功效(Power)"></a>统计功效(Power)</h3><p>在假设检验中有两类错误</p>
<p>P(type I error) = P(reject H0 | H0 is true)</p>
<p>P(type II error) = P(Fail to reject H0 | H0 is false)</p>
<p>而power就是不犯二类错误的概率(Type 2 error)</p>
<p>power = 1 - P(type 2 error)</p>
<p><img src="/Blog/intro/power_of_a_test.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/power_of_a_test_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>power受到α和n(sample size)的影响</p>
<p><strong>如果增大α</strong></p>
<p><img src="/Blog/intro/power_of_a_test_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><strong>如果增大n</strong></p>
<p><img src="/Blog/intro/power_of_a_test_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/power_of_a_test_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h4 id="直观的理解"><a href="#直观的理解" class="headerlink" title="直观的理解"></a>直观的理解</h4><p><img src="/Blog/intro/power_of_a_test_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>如果μ=0置信区间是(-3.14, 3.14), 然而实际的μ为4, 那么-3.14到3.14这个范围的值不会拒绝H0(二类错误), 绿色的部分就是统计功效, 其实还有小于-3.14的那一部分, 但面积太少就忽略不计了</p>
<p><br></p>
<p><br></p>
<h4 id="Power的计算公式"><a href="#Power的计算公式" class="headerlink" title="Power的计算公式"></a>Power的计算公式</h4><p>虽然上面的计算方式可行, 但是太过繁琐.</p>
<p>Power的意义是: under H0 is false(Ha is true), the probability to reject H0.</p>
<p><img src="/Blog/intro/power_calculate_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/power_calculate.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>双尾的证明过程</p>
<p><img src="/Blog/intro/power_calculate_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>单尾的证明和这个类似. 双尾相当于两个α/2的单尾.</p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/power_calculate_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/power_calculate_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/power_calculate_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<blockquote>
<p>为什么这里用qnorm(0.2), 因为我们算的是Z&gt;=c的面积有0.8的情况, 也就是Z&lt;c 的面积= 0.2的情况, 而qnorm(0.2) 就是计算Z&lt;c的面积=0.2时的c的值</p>
</blockquote>
<p><br></p>
<p><br></p>
<h4 id="二项分布的power"><a href="#二项分布的power" class="headerlink" title="二项分布的power"></a>二项分布的power</h4><p>二项分布的CI是不准确的. 因此求二项分布power的方法也有所不同.</p>
<p><img src="/Blog/intro/b_power.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h4 id="2-sample-paired-t-test-power"><a href="#2-sample-paired-t-test-power" class="headerlink" title="2-sample paired t test power"></a>2-sample paired t test power</h4><p><img src="/Blog/intro/paired_t_power.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>注意此时两个变量是dependent, 所以variance的计算要注意:</p>
<script type="math/tex; mode=display">
\sigma_D^2 = Var[Y_{iA}-Y_{i_B}] \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \</script><script type="math/tex; mode=display">
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ =Var[Y_{iA}]+Var[Y_{i_B}]-Cov[Y_{iA},Y_{i_B}]</script><p><br></p>
<h4 id="2-sample-independent-t-test-power-方差相等"><a href="#2-sample-independent-t-test-power-方差相等" class="headerlink" title="2-sample independent t test power(方差相等)"></a>2-sample independent t test power(方差相等)</h4><p><img src="/Blog/intro/paired_t_power_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/paired_t_power_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><img src="/Blog/intro/paired_t_power_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="t-分布"><a href="#t-分布" class="headerlink" title="t 分布"></a>t 分布</h2><p>在假设检验时, 我们上面举的例子都是服从二项分布的, 即要么成功(success) 要么失败(fail)</p>
<p>抛硬币就是要么正面朝上要么反面朝上, 因此我们知道它的方差, 而二项分布的方差就是 π(1-π)</p>
<p>而在计算Margin of error和置信区间时, 是需要使用到总体的方差的.</p>
<p><img src="/Blog/intro/t_pro.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>然而在非二项分布的情况下, 即大多数情况下, 我们并不清楚<strong>总体的方差</strong>, 因此我们可以使用<strong>样本的方差</strong>代替</p>
<p><img src="/Blog/intro/t_pro_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="t分布的性质"><a href="#t分布的性质" class="headerlink" title="t分布的性质"></a>t分布的性质</h3><p>如果{X1, X2…Xn} 是来自<strong>正态总体</strong>(normal population)的<strong>简单随机抽样</strong>(SRS), 那么</p>
<p><img src="/Blog/intro/t_pro_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>t分布也是对称单峰的分布, 且自由度(degree of freedom)越大越接近正态分布</p>
<p><img src="/Blog/intro/t_distribution_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<h3 id="自由度"><a href="#自由度" class="headerlink" title="自由度"></a>自由度</h3><p>{X1, X2, X3} 是iid(不相关的)随机变量, 那么df = 3</p>
<p>但是{X1 - AVG_X, X2 - AVG_X, X3 - AVG_X} 的自由度只有2,因为</p>
<p>(X1 - AVG_X)+(X2 - AVG_X)+(X3 - AVG_X) = 0</p>
<p>如果X1 - AVG_X=5, X2 - AVG_X=6, 那么X3 - AVG_X只有可能为-11</p>
<p><br></p>
<p>例子:</p>
<p><img src="/Blog/intro/t_pro_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="2-sample-dependent-t-Procedure"><a href="#2-sample-dependent-t-Procedure" class="headerlink" title="2-sample(dependent) t Procedure"></a>2-sample(dependent) t Procedure</h2><p>也被称为 matched pairs t procedure</p>
<p>例子: 现有期中考试和期末考试的成绩, 问期中到期末这段时间的学习是否使得成绩有所提高?</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Before(X)</th>
<th style="text-align:center">69</th>
<th style="text-align:center">54</th>
<th style="text-align:center">82</th>
<th style="text-align:center">67</th>
<th style="text-align:center">60</th>
<th style="text-align:center">73</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>After(Y)</strong></td>
<td style="text-align:center">73</td>
<td style="text-align:center">50</td>
<td style="text-align:center">83</td>
<td style="text-align:center">78</td>
<td style="text-align:center">56</td>
<td style="text-align:center">74</td>
</tr>
<tr>
<td style="text-align:center"><strong>Difference(D=Y-X)</strong></td>
<td style="text-align:center">4</td>
<td style="text-align:center">-4</td>
<td style="text-align:center">1</td>
<td style="text-align:center">11</td>
<td style="text-align:center">-4</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
</div>
<p>X 和 Y 是相关的变量, 但我们可以把这两个变量整合称为一个变量</p>
<p><strong>\<step 1></strong></p>
<p>H0 : μ<sub>d</sub> = (μ<sub>y</sub> - μ<sub>x</sub>) = 0</p>
<p>Ha : μ<sub>d</sub> &gt; 0</p>
<p><strong>\<step 2></strong></p>
<p>choose α = 5%</p>
<p><strong>\<step 3></strong></p>
<p>由于不知道总体方差, 所以使用t分布及样本方差</p>
<p>t的自由度为6-1 = 5</p>
<p><strong>\<step 4></strong></p>
<p>计算p-value, p-value = p[Test statistic behaves at least as extreme as the observe d value | H0 is true] = p[mean_D(总体均值) &gt; mean_d(1.5, 样本均值)|μ<sub>d</sub> = 0]</p>
<p><img src="/Blog/intro/matched_t_pro.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><strong>\<step 5></strong></p>
<p>结论: fail to reject H0, the collected evidence are not significant enough to claim there is an improvement</p>
<blockquote>
<p>X 和 Y 相关, 问X和Y是否有显著差异, 把两个变量结合为一个变量D=Y-X再用t分布计算概率</p>
</blockquote>
<p><br></p>
<p><br></p>
<h2 id="2-sample-independent-t-Procedure-方差不等"><a href="#2-sample-independent-t-Procedure-方差不等" class="headerlink" title="2-sample(independent) t Procedure(方差不等)"></a>2-sample(independent) t Procedure(方差不等)</h2><blockquote>
<p>X 和 Y 不相关, 问X和Y是否有显著差异</p>
</blockquote>
<p>一个学者认为阅读活动能提升阅读的能力, 于是他让21个人参与阅读活动(treatment group), 23个人不参与活动(control group), 并在8周后进行测试</p>
<p><br></p>
<p>感兴趣的变量: X 和 Y</p>
<p>X = treatment group 的测试成绩</p>
<p>Y = control group 的测试成绩</p>
<p><br></p>
<p>前置条件</p>
<p>{X1, X2…X21}是来自正态总体的简单随机抽样 (X1~N(μ<sub>x</sub>, σ^2<sub>x</sub>))</p>
<p>{Y1, Y2…Y23}是来自正态总体的简单随机抽样 (Y1~N(μ<sub>Y</sub>, σ^2<sub>Y</sub>))</p>
<p>X, Y是不相关的</p>
<p><br></p>
<p><img src="/Blog/intro/matched_t_pro_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>通过计算求得:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>Group</th>
<th>size(n)</th>
<th>sample_mean</th>
<th>sample SD</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>Treatment</td>
<td>21(nx)</td>
<td>51.48(AVG<sub>x</sub>)</td>
<td>11.01(S<sub>x</sub>)</td>
</tr>
<tr>
<td>Y</td>
<td>Control</td>
<td>23(ny)</td>
<td>41.52(AVG<sub>Y</sub>)</td>
<td>17.15(S<sub>Y</sub>)</td>
</tr>
</tbody>
</table>
</div>
<p><strong>\<step 1></strong></p>
<p>H0 : μ<sub>x</sub> = μ<sub>y</sub>, (μ<sub>x</sub> - μ<sub>y</sub> = 0)</p>
<p>Ha : μ<sub>x</sub> - μ<sub>y</sub> &gt; 0 (the difference is real, treatment method is better)</p>
<p><strong>\<step 2></strong></p>
<p>choose α = 5%</p>
<p><strong>\<step 3></strong></p>
<p>test statistics used </p>
<p><img src="/Blog/intro/matched_t_pro_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>拒绝H0如果p-value &lt; α = 5%</p>
<p><strong>\<comments on Sampling Distribution of X\_bar Y\_bar></strong></p>
<p><img src="/Blog/intro/matched_t_pro_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/matched_t_pro_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br>因此:</p>
<p><img src="/Blog/intro/matched_t_pro_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>首先先计算期望值</p>
<p><img src="/Blog/intro/matched_t_pro_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>在计算标准误/方差, 由于X, Y无关</p>
<p><img src="/Blog/intro/matched_t_pro_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><img src="/Blog/intro/matched_t_pro_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>ν是t的自由度, 它有两种计算方法</p>
<p><img src="/Blog/intro/matched_t_pro_9.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>第二种方法准确度更高, 常用于计算机工程中计算自由度, 但二者差异不大</p>
<p><br></p>
<p><strong>\<step 4></strong></p>
<p>这里自由度选择21-1=20</p>
<p><img src="/Blog/intro/matched_t_pro_10.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/matched_t_pro_11.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><strong>\<step 4 第二版></strong></p>
<p>另一种方法是计算<strong>单侧置信区间</strong></p>
<p><img src="/Blog/intro/matched_t_pro_12.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>[0.97, 18.95] 是置信区间, 不包含0, 所以reject H0</p>
<p>即: 进行阅读活动确实帮助学生提高阅读能力</p>
<p><br></p>
<p><br></p>
<h2 id="2-sample-t-test-independent-方差相等"><a href="#2-sample-t-test-independent-方差相等" class="headerlink" title="2-sample t test (independent)(方差相等)"></a>2-sample t test (independent)(方差相等)</h2><p>前置条件</p>
<p><img src="/Blog/intro/2-t-e.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><img src="/Blog/intro/2-t-e_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>由于$\sigma$未知, 所以替换为 s (样本标准差)</p>
<p>而样本方差的计算公式为</p>
<script type="math/tex; mode=display">
s^2=\frac {(n_x-1)s_x^2+(n_y-1)s_y^2}{n_x+n_y-2}</script><p>可以将 $n_x-1$ 和 $n_y-1$ 理解为权值, 就是求 $s_x, s_y$的加权平均值.</p>
<p>此时 $T\sim t_{n_x+n_y-2}$. </p>
<p><br></p>
<p><br></p>
<h2 id="非参数检验-One-Way-Chi-square-test"><a href="#非参数检验-One-Way-Chi-square-test" class="headerlink" title="非参数检验: One Way Chi-square test"></a>非参数检验: One Way Chi-square test</h2><p>从一个例子出发:</p>
<p>假设教授的期末试卷50道题的答案如下(称为<strong>f<sub>o</sub></strong>), 问教授是否倾向于让题目设置为某一个选项</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Correct answer</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr>
<td>Observed frequencies</td>
<td>12</td>
<td>14</td>
<td>9</td>
<td>5</td>
<td>10</td>
</tr>
</tbody>
</table>
</div>
<p>H0: (Null hypothesis) The instructor shows <strong>no</strong> tendency to assign any particular correct response from A to E (教授没有倾向)</p>
<p>Ha:(Research hypothesis) The instructor shows tendency to assign any particular correct response from A to E (教授有倾向)</p>
<p>因此如果教授没有倾向, 我们期望的答案的分布应该如下(称为<strong>f<sub>e</sub></strong>)</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Correct answer</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr>
<td>Observed frequencies</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>10</td>
</tr>
</tbody>
</table>
</div>
<p><strong>\<step 1></strong></p>
<p>H0: (Null hypothesis) The instructor shows <strong>no</strong> tendency to assign any particular correct response from A to E (教授没有倾向)</p>
<p>Ha:(Research hypothesis) The instructor shows tendency to assign any particular correct response from A to E (教授有倾向)</p>
<p><strong>\<step 2></strong></p>
<p>Choose α = 5%</p>
<p><strong>\<step 3></strong></p>
<p>使用统计量的选取: 卡方分布</p>
<p><img src="/Blog/intro/chi_square_n.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>当卡方的值过大时拒绝H0</p>
<blockquote>
<p>思想: </p>
<p>如果H0为真, 则<strong>f<sub>o</sub></strong>应该接近<strong>f<sub>e</sub></strong></p>
<p>因此<strong>f<sub>o</sub></strong> - <strong>f<sub>e</sub></strong> 接近0, <strong>f<sub>o</sub></strong> - <strong>f<sub>e</sub></strong>的平方接近0</p>
<p>因此这个统计量应该非常小, 如果太大了就要拒绝H0</p>
<p><img src="/Blog/intro/chi_square_n.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>卡方分布的几条性质</p>
<p>卡方分布的概率密度函数图:</p>
<p><img src="/Blog/intro/chi-square-distribution_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>卡方分布的曲线是右偏(right skewed)的</p>
<p>每个卡方分布的曲线都和一个自由度相关</p>
<p>增加自由度卡方分布的曲线会变得更加对称</p>
</blockquote>
<p><strong>\<step 4></strong></p>
<p><img src="/Blog/intro/chi_square_n_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>df = k-1 = 5-1 = 4</p>
<p>卡方分布在自由度为4时单尾5%的拒绝域为 [9.488, inf)</p>
<p>而根据样本得到的卡方值为4.6, 并没有落在拒绝域内, 所以保留H0</p>
<p><br></p>
<p><br></p>
<h2 id="非参数检验-Two-Way-Chi-square-test"><a href="#非参数检验-Two-Way-Chi-square-test" class="headerlink" title="非参数检验: Two Way Chi-square test"></a>非参数检验: Two Way Chi-square test</h2><p><img src="/Blog/intro/chi_square_n_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/chi_square_n_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="F分布"><a href="#F分布" class="headerlink" title="F分布"></a>F分布</h2><p>如果U服从自由度为v1的卡方分布, V服从自由度为v2的卡方分布</p>
<p><img src="/Blog/intro/f_dis.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/f_dis_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>同样是一个服从标准正态分布的总体, 通过这个总体可以得到一些统计量, U服从自由度为n1的卡方分布, V服从自由度为n2的卡方分布</p>
<p><img src="/Blog/intro/f_distribution.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>基于U和V构造新的统计量F</p>
<p><img src="/Blog/intro/f_distribution_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="F分布的概率密度函数图"><a href="#F分布的概率密度函数图" class="headerlink" title="F分布的概率密度函数图"></a>F分布的概率密度函数图</h3><p>首先固定n2为40, 去变换n1</p>
<p><img src="/Blog/intro/f_distribution_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>随着n1的不断变小, 图形变得越来越矮, 越来越胖, 并且其概率最大值所对应的F值也越来越向左偏移</p>
<p><br></p>
<p>固定n1为20, 变化n2, 一次递减10</p>
<p><img src="/Blog/intro/f_distribution_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>随着n2递减, 图形变得越来越矮, 相对的也胖了一些, 但变换程度没有左侧的明显</p>
<p><br></p>
<h3 id="t分布和F分布"><a href="#t分布和F分布" class="headerlink" title="t分布和F分布"></a>t分布和F分布</h3><p>如果T服从自由度为v的t分布, 则:</p>
<p><img src="/Blog/intro/f_dis_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="来自正态总体的样本和F分布"><a href="#来自正态总体的样本和F分布" class="headerlink" title="来自正态总体的样本和F分布"></a>来自正态总体的样本和F分布</h3><p>如果有2个无关的来自正态分布的随机样本, 样本容量分布为n1, n2, </p>
<p><img src="/Blog/intro/f_dis_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="单因素方差分析One-Way-Analysis-of-Variance-ANOVA"><a href="#单因素方差分析One-Way-Analysis-of-Variance-ANOVA" class="headerlink" title="单因素方差分析One-Way Analysis of Variance (ANOVA):"></a>单因素方差分析One-Way Analysis of Variance (ANOVA):</h2><p>前面讲过对一个总体均值进行假设检验, 以及对两个总体的均值进行假设检验</p>
<p>方差分析则是用来实现在多于两个均值的情况下的假设检验</p>
<p><br></p>
<h3 id="t检验对比方差分析"><a href="#t检验对比方差分析" class="headerlink" title="t检验对比方差分析"></a>t检验对比方差分析</h3><p><img src="/Blog/intro/t_anova.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="方差分析的核心"><a href="#方差分析的核心" class="headerlink" title="方差分析的核心"></a>方差分析的核心</h3><p>对因变量的总变化进行划分, 把它分成<strong>自变量引起的变化</strong>(可以解释的变化)和<strong>其他因素引起的变化</strong>(无法解释的变化)</p>
<p><img src="/Blog/intro/t_anova_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>二者的比值正好是一个F统计量, 服从F分布</p>
<p><img src="/Blog/intro/t_anova_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>我们只进行单尾检验(只关心右尾), 因为如果是左尾就说明自变量引起的变化远远小于其他因素引起的变化, 因此我们不认为自变量可以解释因变量</p>
<p>而<strong>自变量引起的变化</strong>和<strong>其他因素引起的变化</strong>都是使用方差进行刻画的, 因此称为<strong>方差分析</strong></p>
<p><br></p>
<h3 id="从一个例子出发"><a href="#从一个例子出发" class="headerlink" title="从一个例子出发"></a>从一个例子出发</h3><p>一个学者认为结婚时长和结婚次数的关系, 他收集的样本数据如下:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>First Marriage (X1)</th>
<th>Second Marriage (X2)</th>
<th>Third Marriage (X3)</th>
</tr>
</thead>
<tbody>
<tr>
<td>8.50</td>
<td>7.50</td>
<td>2.75</td>
</tr>
<tr>
<td>9.00</td>
<td>4.75</td>
<td>4.00</td>
</tr>
<tr>
<td>6.75</td>
<td>3.75</td>
<td>1.50</td>
</tr>
<tr>
<td>8.50</td>
<td>6.50</td>
<td>3.75</td>
</tr>
<tr>
<td>9.50</td>
<td>5.00</td>
<td>3.50</td>
</tr>
</tbody>
</table>
</div>
<p>当我们把这些数值看作一个总体, 就可以求出<strong>总平均</strong></p>
<p>总平均 X_bar = 5.68</p>
<p>每一个组再计算一下平均值: </p>
<p>X1_bar = 8.45,    X2_bar = 5.50,    X3_bar=3.10</p>
<p><br></p>
<p>有了这些平均值就可以衡量变化了</p>
<p>总变化(SST Sum of Squares Total) = 所有的值到总平均距离的平方</p>
<p><img src="/Blog/intro/anova_sst.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/sst_anova.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>自变量引起的变化(SSG Sum of Squares Group)(组间变化/效应平方和)</p>
<p><img src="/Blog/intro/ssg_anova.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>X_j_bar 和总平均之间的差距我们认为是代表第j组的效应</p>
<p>此外乘以第j组的样本容量, 相当于给差的平方一个<strong>权重</strong>, 因为X_j_bar是基于这么多样本算出来的</p>
<p>对所有组进行这样计算在加和得到的就是组间变化</p>
<p><img src="/Blog/intro/anova_ssg.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>其他因素引起的变化(SSE Sum of Squares Error)(组内变化/误差平方和)</p>
<p><img src="/Blog/intro/anova_sse.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>这就是每组的方差乘以自由度</p>
<p><img src="/Blog/intro/anova_sse_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>即每组数据围绕组内均值的变化程度</p>
<p>比如说第一组5个人, 都是第一次结婚, 所以它们之间的变化不是因为结婚次数导致的, 而是由其他因素导致的</p>
<p>然而当我们求出了SST和SSG就可以直接用SST-SSG求出SSE</p>
<p>SST = SSG+SSE</p>
<p><br></p>
<p>然而我们并不是直接用SSG除以SSE</p>
<p>而是先求出 MSG (Mean square of Group) 和 MSE  (Mean square of Error) 即用SSG 和SSE除以各自的自由度</p>
<p>SSG 的自由度为k-1, 即组数-1</p>
<p>SSE 的自由度为n-k, 即总数-组数</p>
<p>为什么是n-k? 因为如果是求第j组内方差, 那么自由度应该是n_j-1</p>
<p>一共有k组, 即(n_1-1)+(n_2-1)… = n-k</p>
<p><br></p>
<p><img src="/Blog/intro/anova_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Source of variation</th>
<th>Sum of Square (SS)</th>
<th>df</th>
<th>Mean of Square (MS)</th>
<th>F</th>
</tr>
</thead>
<tbody>
<tr>
<td>Between Group</td>
<td>71.80833</td>
<td>2</td>
<td>35.90</td>
<td>24.98</td>
</tr>
<tr>
<td>Within Group</td>
<td>17.25</td>
<td>12</td>
<td>1.4375</td>
<td></td>
</tr>
<tr>
<td>Total</td>
<td>89.58</td>
<td>14</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>F(2, 12)的5%的拒绝域为[3.88, inf)</p>
<p>而24.98落在其中, 所以拒绝H0</p>
<p>方差分析的H0一直是所有组的均值相等</p>
<p>拒绝H0即某两组的均值不等</p>
<p><br></p>
<p><br></p>
<h2 id="Inference-for-the-difference-of-two-Proportions"><a href="#Inference-for-the-difference-of-two-Proportions" class="headerlink" title="Inference for the difference of two Proportions"></a>Inference for the difference of two Proportions</h2><p><img src="/Blog/intro/inf_2_prop.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/inf_2_prop_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/inf_2_prop_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/inf_2_prop_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h2 id="数据之间的关系"><a href="#数据之间的关系" class="headerlink" title="数据之间的关系"></a>数据之间的关系</h2><p>当有一组数据(X1, Y1)…(Xn, Yn)</p>
<p>我们想学习X, Y之间的关系</p>
<p><img src="/Blog/intro/data_relation_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_9.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_10.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/data_relation_11.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h2 id="线性回归-Linear-Regression"><a href="#线性回归-Linear-Regression" class="headerlink" title="线性回归(Linear Regression)"></a>线性回归(Linear Regression)</h2><h3 id="方差-vs-协方差"><a href="#方差-vs-协方差" class="headerlink" title="方差 vs 协方差"></a>方差 vs 协方差</h3><p><img src="/Blog/intro/coverance.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>Cov(X, X) = Var(X)</p>
<p>例如:</p>
<p><img src="/Blog/intro/coverance_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>然而当我们看到7.94, 我们应该如何判断强弱, 正负?</p>
<p>我们很难从7.94这个数字上判断这些信息, 因为我们不知道协方差变化的范围(最小值和最大值是谁), 所以我们无法判断7.94代表的是很强的关系还是很弱的关系以及它的方向</p>
<p>再看一个例子</p>
<p><img src="/Blog/intro/coverance_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>这组数只是把上组数据乘以10得到的</p>
<p>因此这组数据x, y的关系的强度和方向应该和上组数据一样</p>
<p>再用协方差公式进行计算</p>
<p><img src="/Blog/intro/coverance_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>同样我们也无法判断强弱, 正负</p>
<p>显然794 &gt; 7.94 , 但这不代表前者关系强度更大</p>
<p>也就是说协方差和数据严格相关, 即使关系没有变化, 但数值的变化会导致协方差的变化</p>
<p><br></p>
<h3 id="协方差-vs-相关系数-correlation-coefficient"><a href="#协方差-vs-相关系数-correlation-coefficient" class="headerlink" title="协方差 vs 相关系数(correlation coefficient)"></a>协方差 vs 相关系数(correlation coefficient)</h3><p><img src="/Blog/intro/coe_cor.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>r相当于对协方差进行了一下标准化, 这样的标准化使得r具有一些很好的性质</p>
<p><br></p>
<h3 id="相关-Correlation"><a href="#相关-Correlation" class="headerlink" title="相关(Correlation)"></a>相关(Correlation)</h3><p>相关指的是两个变量之间的关系, 这关系我们通常使用相关系数进行反映</p>
<p><img src="/Blog/intro/correlation.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>经过把Covariance进行标准化操作后, 他们的相关系数变成一样的了</p>
<p><img src="/Blog/intro/correlation_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/correlation_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>让r = 0 代表没有线性关系, 但不代表没有不关系</p>
<p>r=1: 完美线性正相关, r=-1:完美线性负相关</p>
<p><img src="/Blog/intro/correlation_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>r没有单位, 不受变量平移伸缩的影响</p>
<p><br></p>
<h3 id="一元线性回归-Simple-linear-regression"><a href="#一元线性回归-Simple-linear-regression" class="headerlink" title="一元线性回归(Simple linear regression)"></a>一元线性回归(Simple linear regression)</h3><p><img src="/Blog/intro/simple_linear_regression.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>在散点图中,要找一条最佳拟合直线, 使得所有点到这条线距离的平方和最小</p>
<p><img src="/Blog/intro/simple_linear_regression_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>y_hat就是对x的估计值, y是实际的值, 我们认为它是在这条拟合直线的基础上增加了一个随机偏移量(残差), 这个残差服从正态分布</p>
<p><img src="/Blog/intro/simple_linear_regression_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/simple_linear_regression_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>矩阵求解的方法可以移步到线性代数, 里面讲解了最小二乘用矩阵的求法</p>
<p><br></p>
<p>这里用求导的方法来求最小值:</p>
<p>取J关于β0, β1 的偏导数, 并令他们等于0, 求未知数</p>
<p><img src="/Blog/intro/simple_linear_regression_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/simple_linear_regression_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/simple_linear_regression_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/simple_linear_regression_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/simple_linear_regression_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<blockquote>
<p>所有过(X_bar, Y_bar)的预测线的残差和都为0</p>
<p>为什么回归线是最好的预测线? 因为它有着最小的残差平方和</p>
</blockquote>
<h3 id="残差图-Residual-Plot"><a href="#残差图-Residual-Plot" class="headerlink" title="残差图(Residual Plot)"></a>残差图(Residual Plot)</h3><p>记录所有x对应的残差, y - y_hat, </p>
<p><img src="/Blog/intro/simple_linear_regression_9.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/r_plot.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>好的残差图:</p>
<p><img src="/Blog/intro/r_plot_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="极端值对线性回归的影响"><a href="#极端值对线性回归的影响" class="headerlink" title="极端值对线性回归的影响"></a>极端值对线性回归的影响</h3><p><img src="/Blog/intro/r_plot_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="线性回归的假设检验"><a href="#线性回归的假设检验" class="headerlink" title="线性回归的假设检验"></a>线性回归的假设检验</h3><p><img src="/Blog/intro/reg_hypo_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_9.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_10.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_11.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_12.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_13.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_14.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""><br><img src="/Blog/intro/reg_hypo_15.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h1 id="Stat270"><a href="#Stat270" class="headerlink" title="Stat270"></a>Stat270</h1><h2 id="集合论"><a href="#集合论" class="headerlink" title="集合论"></a>集合论</h2><h3 id="conditional-probability"><a href="#conditional-probability" class="headerlink" title="conditional probability"></a>conditional probability</h3><script type="math/tex; mode=display">
P(A|B)=\frac {P(A\bigcap B)} {P(B)}, P(B)>0</script><p>P(A|B)指的是在B为真的情况下, 事件A发生的概率</p>
<p><br></p>
<h3 id="Law-of-Total-Probability"><a href="#Law-of-Total-Probability" class="headerlink" title="Law of Total Probability"></a>Law of Total Probability</h3><p>if events B<sub>1</sub>, B<sub>2</sub>,…B<sub>k</sub> form a <strong>partition</strong> of S</p>
<script type="math/tex; mode=display">
\bigcup_{i=1}^KB_i=S\ \ and \ \ \bigcap_{i=1}^KB_i=\empty</script><p>Then</p>
<script type="math/tex; mode=display">
P(A)=P(\bigcup_{i=1}^K(AB_i)) = \sum_{i=1}^KP(AB_i) = \sum_{i=1}^KP(A|B_i)P(B_i)</script><p><img src="/Blog/intro/ltp.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="Randomized-Response"><a href="#Randomized-Response" class="headerlink" title="Randomized Response"></a>Randomized Response</h3><p>扔2次硬币, 如果第二次正面朝上, 则回答第一次是否是正面朝上(Yes/No), 如果是背面回答一个敏感的问题. 计算这个问题的概率</p>
<p><img src="/Blog/intro/random_response.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<script type="math/tex; mode=display">
P(Y)=P(Y|H_2)P(H_2) +P(Y|T_2)P(T_2)</script><script type="math/tex; mode=display">
= \frac 12(\frac 12)+p*(\frac 12)\ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \  \</script><p>so</p>
<script type="math/tex; mode=display">
p=2[P(Y)-\frac 14]</script><p><br></p>
<h3 id="Bayes’s-Theorem-贝叶斯定理"><a href="#Bayes’s-Theorem-贝叶斯定理" class="headerlink" title="Bayes’s Theorem(贝叶斯定理)"></a>Bayes’s Theorem(贝叶斯定理)</h3><p>if events B<sub>1</sub>, B<sub>2</sub>,…B<sub>k</sub> form a <strong>partition</strong> of S</p>
<script type="math/tex; mode=display">
\bigcup_{i=1}^KB_i=S\ \ and \ \ \bigcap_{i=1}^KB_i=\empty</script><p>Then:</p>
<script type="math/tex; mode=display">
P(B_i|A)=\frac {P(AB_i)} {P(A)}</script><script type="math/tex; mode=display">
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  =\frac {P(A|B_i)P(B_i)}{\sum_{j=1}^K P(A|B_j)P(B_j)}</script><p><br></p>
<p>例子:</p>
<p>有3个门, 其中一个门的后面有汽车, 玩家选一扇门, 之后主持人会从另外两扇门中把没有车的那一扇门打开, 此时玩家有一次换门的机会, 问换还是不换?</p>
<p>假设:</p>
<ul>
<li>C<sub>1</sub>代表事件: 车在第一扇门后面</li>
<li>C<sub>2</sub>代表事件: 车在第二扇门后面</li>
<li>C<sub>3</sub>代表事件: 车在第三扇门后面</li>
</ul>
<p>假设玩家选择第一扇门, 同时假设车不在第二扇门的后面</p>
<p>计算如果主持人打开第二扇门(D<sub>2</sub>), 车在第三扇门后(C<sub>3</sub>)的概率</p>
<p><img src="/Blog/intro/openthedoor.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>还有一种思路: bobo提供的, 就是如果第一次没选中, 换门则必定能得到车. 而第一次没选中的概率是2/3</p>
<p><br></p>
<h2 id="independence"><a href="#independence" class="headerlink" title="independence"></a>independence</h2><p>如果两个事件A and B是independent, 当且仅当</p>
<script type="math/tex; mode=display">
P(AB)=P(A)P(B)</script><p>等价的, 假设P(B) &gt; 0, A和B是independent 当且仅当</p>
<script type="math/tex; mode=display">
P(A|B)=P(A)\ and\ P(B|A)=P(B)</script><p>A 和 B 是independent 如果B的发生不会影响A发生的概率, 反之亦然</p>
<p><strong>要证明A和B是independent必须使用上面两个公式中的一个</strong></p>
<p><br></p>
<p>例子:</p>
<p>12% 的人吸烟, 0.8%的人既吸烟又有肺炎, 0.2%的人不吸烟却有肺炎</p>
<ol>
<li>求得肺炎的概率</li>
<li>吸烟和肺炎是否无关</li>
</ol>
<p>P(A)=12% 吸烟, P(B) 有肺炎</p>
<p><img src="/Blog/intro/smoker_prob.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>所以根据定义, 吸烟和肺炎相关. 或者用另一个定义</p>
<script type="math/tex; mode=display">
P(B|A)=\frac {P(AB)} {P(A)}=\frac {0.008}{0.12}=0.067 \ne 0.001=P(B)</script><p><br></p>
<h2 id="Conditional-probability"><a href="#Conditional-probability" class="headerlink" title="Conditional probability"></a>Conditional probability</h2><p>Let A be the event that someone tests positive for the disease.</p>
<p>Let B be the event that someone actually has the disease.</p>
<p>Then:</p>
<p><strong>Detection rate : P(A|B)</strong></p>
<p><strong>False-positive rate : P(A|B’)</strong></p>
<p><strong>False-negative rate: P(A’|B)</strong></p>
<p><strong>Positive predictive value : P(B|A)</strong></p>
<p><strong>Negative predictive value: P(B’|A’)</strong></p>
<p><img src="/Blog/intro/condition_prob.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h2 id="PMF"><a href="#PMF" class="headerlink" title="PMF"></a>PMF</h2><p>probably mass function, 有时候也称为Probably distribution function(不过二者有区别, pmf只能表示离散变量的分布, pdf却可以表示离散和连续变量的分布)</p>
<p><br></p>
<p>常用的表达方式P(X=x) 或 f<sub>X</sub>(x)</p>
<p><br></p>
<p>pmf是一个普通的函数, 没有任何随机</p>
<p><img src="/Blog/intro/pmf_270.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>有时pmf有closed forms, 例如</p>
<script type="math/tex; mode=display">
P(X=x)= {5 \choose x}0.5^{0.5}, x=0,1,...5</script><p><br></p>
<p>pmf的性质</p>
<script type="math/tex; mode=display">
f_X(x)\ge 0, \forall x</script><script type="math/tex; mode=display">
\sum_x f_X(x)=1</script><p>如果要证明一个函数是pmf, 就是要证明它满足上面两条性质</p>
<p><img src="/Blog/intro/pmf_270_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>A probability is the probability of an event</p>
<p>DO write statement such as </p>
<ul>
<li>P(E) (where E is an event)</li>
<li>P(X=x) (where x is a realization of the random variable X)</li>
</ul>
<p><br></p>
<p>Do Not write statements such as</p>
<ul>
<li>P(X) (where X is a random variable)</li>
<li>P(x) (where x is a realization of the rv X)</li>
</ul>
<p><br></p>
<h2 id="Geometric-Distribution-几何分布"><a href="#Geometric-Distribution-几何分布" class="headerlink" title="Geometric Distribution (几何分布)"></a>Geometric Distribution (几何分布)</h2><p>几何分布（Geometric distribution）是离散型概率分布。其中一种定义为：在n次伯努利试验中，试验k次才得到第一次成功的机率。</p>
<p>let X be the number of failures that occur before the first success.</p>
<p>P(X = 0) = p</p>
<p>P(X = 1) = p(1-p)</p>
<p>P(X = 2) = p(1-p)<sup>2</sup></p>
<p>P(X = x) = p(1-p)<sup>x</sup>, x = 0, 1, 2…</p>
<p>X is called a geometric(p) random variable</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs R">x<span class="hljs-operator">&lt;-</span><span class="hljs-number">0</span><span class="hljs-operator">:</span><span class="hljs-number">10</span><br>barplot<span class="hljs-punctuation">(</span>dgeom<span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">,</span> <span class="hljs-number">0.2</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> names.arg<span class="hljs-operator">=</span>x<span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure>
<p><img src="/Blog/intro/geometric_dis.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>证明几何分布是pmf</p>
<ol>
<li>首先几何分布中的每一项都大于0</li>
<li>证明所有项之和为1</li>
</ol>
<script type="math/tex; mode=display">
\sum_{x=0}^\infin p_X(x)=\sum_{x=0}^\infin (1-p)^xp</script><script type="math/tex; mode=display">
=p+p(1-p)+p(1-p)^2...p(1-p)^{\infin}</script><script type="math/tex; mode=display">
=p(\frac {1}{1-(1-p)})=1</script><blockquote>
<script type="math/tex; mode=display">
a+ar+ar^2+\cdots=\sum_{k=0}^\infin ar^k=\frac a{1-r}, for\ |r|<1</script><p>in our case we have a=p, and r=1-p</p>
</blockquote>
<p>它是一个pmf</p>
<p><br></p>
<h2 id="Poisson-Distribution-泊松分布"><a href="#Poisson-Distribution-泊松分布" class="headerlink" title="Poisson Distribution(泊松分布)"></a>Poisson Distribution(泊松分布)</h2><p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html">阮一峰-泊松分布</a></p>
<p>泊松分布(Poisson distribution) 的概率密度函数(pmf)为</p>
<script type="math/tex; mode=display">
f_X(x)=\frac {e^{-\lambda}{\lambda^x}} {x!}, for\  \lambda>0\ and\ x=0,1,2...</script><blockquote>
<p>通常<strong>单位时间</strong>内事件发生<strong>λ次</strong>, P(X=x)求的是事件在<strong>单位时间</strong>发生<strong>x次的概率</strong></p>
</blockquote>
<p>lambda is called the <strong>mean parameter</strong></p>
<p>often used to describe unconstrained count data</p>
<p><br></p>
<p>让X是20分钟投篮进球的数量</p>
<p>通常20分钟我能进12个球</p>
<p>One probability model that <strong>might</strong> be appropriate for X is the Poisson(12) distribution</p>
<p>注意: No upper bound on the number of baskets I score!</p>
<script type="math/tex; mode=display">
P(X=10)=\frac {e^{-12}12^{10}}{10!}=0.105</script><p>Poisson(12) pmf:</p>
<p><img src="/Blog/intro/possion_dis.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs R">x<span class="hljs-operator">&lt;-</span><span class="hljs-number">0</span><span class="hljs-operator">:</span><span class="hljs-number">30</span><br>barplot<span class="hljs-punctuation">(</span>dpois<span class="hljs-punctuation">(</span>x<span class="hljs-punctuation">,</span> <span class="hljs-number">12</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">,</span> names.arg<span class="hljs-operator">=</span>x<span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure>
<p><br></p>
<p>证明: Possion分布是pmf</p>
<ol>
<li>各项都大于0</li>
<li>证明所有项之和为1</li>
</ol>
<p><img src="/Blog/intro/possion_dis_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>泊松分布的期望值:</p>
<p><img src="/Blog/intro/possion_dis_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>同样根据泰勒展开, 最后的两项抵消, 只剩下lambda.</p>
<p>所以泊松分布的期望值是lambda</p>
<p><br></p>
<p><br></p>
<h2 id="cumulative-distribution-function-累计分布函数"><a href="#cumulative-distribution-function-累计分布函数" class="headerlink" title="cumulative distribution function(累计分布函数)"></a>cumulative distribution function(累计分布函数)</h2><p>简称cdf, 定义如下</p>
<p><img src="/Blog/intro/cdf.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>pdf(x) 指的是 X=x的概率, cdf是X&lt;=x的概率</p>
<p><img src="/Blog/intro/distribution_function_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>左图就是pdf, 右图时cdf(但我不喜欢上图的名称, 累计分布函数这个名称更直观)</p>
<p><br></p>
<p>因此当x趋近于无穷时, cdf(x)就等于所有pdf(x)的和, 也就是1</p>
<p><img src="/Blog/intro/cdf_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>因为pdf(x)的每一项都大于0, 所以cdf不会下降</p>
<p><br></p>
<p>R语言中的函数</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>pdf</th>
<th>cdf</th>
</tr>
</thead>
<tbody>
<tr>
<td>dbinom</td>
<td>pbinom</td>
</tr>
<tr>
<td>dgeom</td>
<td>pgeom</td>
</tr>
<tr>
<td>dpois</td>
<td>ppois</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<p><br></p>
<h2 id="泊松过程-Poisson-Processes"><a href="#泊松过程-Poisson-Processes" class="headerlink" title="泊松过程 (Poisson Processes)"></a>泊松过程 (Poisson Processes)</h2><p>Possion distributed rv has pmf</p>
<script type="math/tex; mode=display">
f_X(x)=\frac {e^{-\lambda}{\lambda^x}} {x!}</script><p>for lambda &gt; 0 and x=0, 1, 2…</p>
<ul>
<li>lambda is called the <strong>mean parameter</strong></li>
<li>Often used to describe unconstrained count data(<strong>no maximum</strong>)</li>
</ul>
<blockquote>
<script type="math/tex; mode=display">
p(x,t)=\frac {e^{-\lambda t}{(\lambda t)^x}} {x!}</script><p>单位时间内事件通常发生λ次, p(x, t)求的是t个单位时间内, 发生x次的概率</p>
</blockquote>
<p><br></p>
<p>Consider a type of event that recurs randomly over time</p>
<p>考虑一种周期性随机发生的事件</p>
<p>例如: 天气变冷, 手机系统更新…</p>
<p>Poisson distribution can sometimes be used to describe the <strong>number of events</strong> occurring <strong>in a given time interval</strong></p>
<p>泊松分布能用于描述<strong>给定时间范围</strong>内<strong>事件发生的次数</strong></p>
<p><br></p>
<p>例子:</p>
<p>孩子们每分钟哭喊一次</p>
<p>让X<sub>(t1, t2)</sub>表示在(t1, t2)时间范围内, 小孩哭喊的次数</p>
<p><img src="/Blog/intro/poisson_int.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<blockquote>
<p>非常重要:</p>
<p><img src="/Blog/intro/poisson_int_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
</blockquote>
<p>Under these assumptions X<sub>(t1, t2)</sub> is Poisson (λ(t2-t1)) distributed</p>
<p>λ is the <strong>arrival rate</strong> of events</p>
<p>We say that X<sub>(t1, t2)</sub> follows a <strong>Poisson process</strong></p>
<p><br></p>
<h3 id="Proof"><a href="#Proof" class="headerlink" title="Proof"></a>Proof</h3><p>proof that X<sub>(0,t)</sub>~Possion(λt)</p>
<p><img src="/Blog/intro/poisson_int_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>so:</p>
<p><img src="/Blog/intro/poisson_int_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/poisson_int_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>Example: </p>
<p>Find the probability that I hear at least 20 screams between 6:00 and 6:30 am</p>
<ul>
<li>λ = 1 (rate is 1 <strong>scream per min</strong>)</li>
<li>Δt = 30 min</li>
</ul>
<p><img src="/Blog/intro/poisson_int_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>Example:</p>
<p>Find the probability that I hear 5 screams between 6 and 6:05 am and at least 1 scream between 6:05 and 6:10am</p>
<p><img src="/Blog/intro/poisson_int_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a>指数分布</h2><p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html">阮一峰-泊松分布</a> 这里也讲了指数分布的概念, 而且推导的很细致</p>
<p>X has an <strong>exponential distribution</strong> with <strong>rate parameter</strong> λ &gt; 0 if, for x &gt; 0: cdf is </p>
<script type="math/tex; mode=display">
F_X(x)=P(X\le x)=1-e^{-\lambda x}</script><script type="math/tex; mode=display">
=1-p(0,t)</script><p>usually use notation: X~exp(λ)</p>
<p><br></p>
<p>Example:</p>
<p>每开车2km就会撞死1个动物</p>
<p>问开4km的车撞死动物的概率是多少?</p>
<ul>
<li>λ=1, 单位时间就是2km(虽然不是时间, 但可以替换理解)</li>
<li>开车4km就是走了两个单位时间. t=2</li>
</ul>
<p>P(X&lt;=4) = F<sub>X</sub>(4) = 1-e<sup>-1*2</sup> = 0.865, 或者用R语言</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs R">pexp<span class="hljs-punctuation">(</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2</span><span class="hljs-punctuation">)</span><br></code></pre></td></tr></table></figure>
<p><br></p>
<p>Example:</p>
<p>问从5km开到10km才撞死动物的概率是多少?</p>
<p>首先0-5km没有事件发生 所以概率为 e<sup>-2.5</sup></p>
<p>5km-10km事件发生, 所以概率为1-e<sup>-2.5</sup></p>
<p>两者independent, 所以结果就是二者相乘</p>
<script type="math/tex; mode=display">
e^{-2.5}*(1-e^{-2.5})=0.075</script><blockquote>
<p>另一种解法:</p>
<script type="math/tex; mode=display">
P(2.5<X\le 5)=P(X\le5)-P(\le 2.5)</script><script type="math/tex; mode=display">
=(1-e^{-5})-(1-e^{-2.5})=0.075</script></blockquote>
<h3 id="Memoryless-property"><a href="#Memoryless-property" class="headerlink" title="Memoryless property"></a>Memoryless property</h3><p><img src="/Blog/intro/poisson_int_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<blockquote>
<p>指数分布是唯一一个适用Memoryless property的连续型分布</p>
</blockquote>
<p>example:</p>
<p>如果我们开车10km, 看见3个死去的动物. 问接下来至少走1km后才看到死去动物的概率</p>
<p>A = 开车10 km 看见3个死去的动物</p>
<p>B = 开车1km没看见尸体</p>
<p>P(A+B|A) = P(B) = e<sup>-0.5</sup></p>
<p><br></p>
<p><br></p>
<h2 id="Probability-Density-Function-PDF"><a href="#Probability-Density-Function-PDF" class="headerlink" title="Probability Density Function(PDF)"></a>Probability Density Function(PDF)</h2><p><strong>Probability Density Function(PDF)</strong> 或者 <strong>density</strong> 和pmf类似, 只不过是作用在连续型变量上</p>
<p>The pdf, f<sub>X</sub>(x) of a rv X is a function such that for all a &lt; b,</p>
<script type="math/tex; mode=display">
P(a\le X\le b)=\int_a^bf_X(x)dx</script><p>如果cdf可导, 则pdf是cdf的导数</p>
<p><br></p>
<h3 id="properties-of-pdfs"><a href="#properties-of-pdfs" class="headerlink" title="properties of pdfs:"></a>properties of pdfs:</h3><p><img src="/Blog/intro/pdf_prop.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>和pmf不同的是, <strong>densities are not probability</strong></p>
<p>We can have f<sub>X</sub>(x) &gt; 1 for some value of x.</p>
<p><br></p>
<p><img src="/Blog/intro/pdf_prop_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="Exponential-pdf"><a href="#Exponential-pdf" class="headerlink" title="Exponential pdf"></a>Exponential pdf</h3><p>If X has an <strong>exponential distribution</strong> with rate λ &gt; 0, then the cdf of X is</p>
<p><img src="/Blog/intro/pdf_prop_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>In this case the cdf is continuous so the pdf is </p>
<script type="math/tex; mode=display">
f_X(x)=\frac d {dx}F_X(x)=\lambda e^{-\lambda x},x\ge 0</script><p><br></p>
<p><img src="/Blog/intro/pdf_prop_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>这看起来有点矛盾:</p>
<p>假设我的身高为x, 同时身高的函数是连续的. P(X=x)=0.</p>
<p>这是因为 P(A) = 0 does <strong>not</strong> imply that the event A never happens.</p>
<p><br></p>
<p><br></p>
<h2 id="Uniform-Distribution"><a href="#Uniform-Distribution" class="headerlink" title="Uniform Distribution"></a>Uniform Distribution</h2><p>A rv X has <strong>uniform(a, b)</strong> distribution if its pdf is</p>
<p><img src="/Blog/intro/pdf_prop_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="standard-uniform"><a href="#standard-uniform" class="headerlink" title="standard uniform"></a>standard uniform</h3><p>Uniform(0, 1) (standard uniform)</p>
<p><img src="/Blog/intro/standard_uniform.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example</p>
<p><img src="/Blog/intro/standard_uniform_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h2 id="Gamma-Distribution"><a href="#Gamma-Distribution" class="headerlink" title="Gamma Distribution"></a>Gamma Distribution</h2><p>A rv X has the <strong>gamma(α, β)</strong> distribution if its pdf is</p>
<script type="math/tex; mode=display">
f_X(x)=\frac {\beta^\alpha x^{\alpha-1}e^{-\beta x}}{Γ(\alpha)}</script><p>for x, α,  β &gt; 0</p>
<p>α is called the <strong>shape</strong> parameter and β is called the <strong>scale</strong> parameter</p>
<p>Γ() is gamma function.</p>
<p><img src="/Blog/intro/gamma_dis.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example</p>
<p><img src="/Blog/intro/gamma_dis_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/gamma_dis_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="Special-Case-of-the-Gamma-Distribution"><a href="#Special-Case-of-the-Gamma-Distribution" class="headerlink" title="Special Case of the Gamma Distribution"></a>Special Case of the Gamma Distribution</h3><p><img src="/Blog/intro/gamma_dis_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="连续型随机变量的期望值和方差"><a href="#连续型随机变量的期望值和方差" class="headerlink" title="连续型随机变量的期望值和方差"></a>连续型随机变量的期望值和方差</h2><h3 id="期望值-1"><a href="#期望值-1" class="headerlink" title="期望值"></a>期望值</h3><p>和离散型随机变量的期望值一样, 连续型随机变量的期望值也决定了它的中心(centrality)</p>
<p>对于一个pdf为f<sub>X</sub>(x)的连续型随机变量X, 它的期望值为</p>
<script type="math/tex; mode=display">
E[X]=\int_\inf^\inf xf_X(x)dx</script><p>类似地, for a function of X, g(x),</p>
<script type="math/tex; mode=display">
E[g(x)]=\int_\inf^\inf g(x)f_X(x)dx</script><p><br></p>
<h3 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h3><p>对于一个pdf为f<sub>X</sub>(x)的连续型随机变量X, 它的方差为</p>
<script type="math/tex; mode=display">
Var[X]=\int_\inf^\inf (x-E[X])^2f_X(x)dx</script><script type="math/tex; mode=display">
=E[X^2]-(E[X])^2</script><p>Standard deviation of X is the square root of variance</p>
<p><br></p>
<p>Cauchy distribution的期望值</p>
<script type="math/tex; mode=display">
f_X(x)=\frac 1 {\pi(1+x^2)}</script><p><img src="/Blog/intro/cdis.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>实际上这个分布没有期望值</p>
<p><br></p>
<p><br></p>
<h2 id="Quantiles-and-Percentiles"><a href="#Quantiles-and-Percentiles" class="headerlink" title="Quantiles and Percentiles"></a>Quantiles and Percentiles</h2><p>We have seen <strong>sample</strong> percentiles/quantiles</p>
<p>We can also define <strong>population</strong> percentiles/quantiles</p>
<p><br></p>
<p>Let <em>p</em> be any number between 0 and 100</p>
<p>If X is a rv with cdf F<sub>X</sub>(x) then the <strong>pth quanantile</strong> is defined as</p>
<script type="math/tex; mode=display">
\eta_p=F_X^{-1}(p/100)</script><div class="table-container">
<table>
<thead>
<tr>
<th>25 th percentile</th>
<th>F<sub>X</sub><sup>-1</sup>(0.25)</th>
</tr>
</thead>
<tbody>
<tr>
<td>50 th percentile</td>
<td>F<sub>X</sub><sup>-1</sup>(0.50)</td>
</tr>
<tr>
<td>75 th percentile</td>
<td>F<sub>X</sub><sup>-1</sup>(0.75)</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<p>例如求 Exponential(0.05)的期望, 50th, 95th percentile</p>
<p><img src="/Blog/intro/expon_per.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="联合离散分布-Joint-Discrete-Distributions"><a href="#联合离散分布-Joint-Discrete-Distributions" class="headerlink" title="联合离散分布 Joint Discrete Distributions"></a>联合离散分布 Joint Discrete Distributions</h2><h3 id="Joint-pmf"><a href="#Joint-pmf" class="headerlink" title="Joint pmf"></a>Joint pmf</h3><p>有两个随机变量 X and Y, the <strong>joint pmf</strong> of X and Y is</p>
<script type="math/tex; mode=display">
f_{XY}(x, y)=P(X=x,Y=y)</script><p>The joint distribution of 2 rv’s is called <strong>bivariate distribution</strong></p>
<blockquote>
<p>Definition extends to any number of rv’s</p>
<p>eg. if Z is a third discrete rv, the joint pmf of X,Y,Z is</p>
<script type="math/tex; mode=display">
f_{XYZ}(x, y,z)=P(X=x,Y=y,Z=z)</script></blockquote>
<p><br></p>
<p>Joint pmfs 的性质</p>
<p><img src="/Blog/intro/joint_pmf.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="Multinomial-Distribution"><a href="#Multinomial-Distribution" class="headerlink" title="Multinomial Distribution"></a>Multinomial Distribution</h3><p><img src="/Blog/intro/multinomial_dis.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>有一组数据, 数据可以分为K个类别, θ<sub>k</sub>代表第k个类别被选中的概率</p>
<script type="math/tex; mode=display">
\sum_{k=1}^K\theta_k=1</script><p>我们从中随机选n个元素</p>
<p>让每个类别被选中的元素个数为X<sub>k</sub>, k=1,2…K</p>
<p>那么X<sub>k</sub>服从 <strong>multinomial distribution</strong></p>
<p><br></p>
<p><img src="/Blog/intro/multinomial_dis_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<script type="math/tex; mode=display">
\frac {n!}{x_1!\cdots x_K!}</script><p>代表从第1组中选x1个元素, 第二组选x2个元素…总共有多少中可能性.</p>
<blockquote>
<p>证明:</p>
<p>从n个数据分为k组的可能为:</p>
<script type="math/tex; mode=display">
{n \choose x_1} {n-x_1 \choose x_2}\cdots{n-x_1-x_2\cdots x_k\choose x_k}</script><script type="math/tex; mode=display">
=\frac {n!}{x_1!(n-x_1)!}\cdot \frac {(n-x_1)!}{x_2!(n-x_1-x_2)!}\cdots \frac {(n-x_1-x_2\cdots x_k)!}{x_k!(n-n)!}</script><script type="math/tex; mode=display">
=\frac {n!}{x_1!\cdots x_K!}</script></blockquote>
<p>再乘以每一组的概率得到的就是pmf</p>
<p><br></p>
<p><br></p>
<p>example:</p>
<p>班级有225个学生, 55个CS专业, 103个Stat专业, 67个其余专业.</p>
<p>选10个学生回答问题, <strong>with replacement</strong>(为了保持类别的概率不变, 不然如果选择一个学生后就不再选他, 那么概率就变动了)</p>
<p>让X1, X2, X3分别为CS, Stat, Other 专业被选择的的学生个数</p>
<p><img src="/Blog/intro/multinomial_dis_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h3 id="Joint-cdfs"><a href="#Joint-cdfs" class="headerlink" title="Joint cdfs"></a>Joint cdfs</h3><p>两个随机变量 X, Y的 joint cdf 为</p>
<script type="math/tex; mode=display">
F_{XY}(x,y)=P(X\le x,Y\le y)</script><p>对更多变量也是一样的</p>
<script type="math/tex; mode=display">
F_{XYZ}(x,y,z)=P(X\le x,Y\le y,Z\le z)</script><p><br></p>
<p>joint cdfs 的性质</p>
<p><img src="/Blog/intro/multinomial_dis_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example:</p>
<p>掷两次骰子</p>
<p>joint pmf 为:</p>
<script type="math/tex; mode=display">
f_{X1,X_2}(x_1,x_2)=\frac 1{36}, x_1,x_2=1,...6</script><p><img src="/Blog/intro/multinomial_dis_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="边缘分布函数-Marginal-pmfs"><a href="#边缘分布函数-Marginal-pmfs" class="headerlink" title="边缘分布函数 Marginal pmfs"></a>边缘分布函数 Marginal pmfs</h2><p>如果我们有一个有m个随机变量的joint pmf, 但是我们希望得到其中d个随机变量的joint pmf</p>
<p>If we sum the pmf over the range of m-d of the rv’s, we will obtain the joint pmf of the remaining d rv’s</p>
<p><br></p>
<p>example:</p>
<p>IPS Prenatal Genetic Screening for Down Syndrome</p>
<p><img src="/Blog/intro/multinomial_dis_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>通过joint cdf 计算 Marginal cdf</p>
<p><img src="/Blog/intro/multinomial_dis_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>例子:</p>
<p>扔三次硬币, X为正面朝上的次数, Y为一次游戏的收入</p>
<ul>
<li>如果第一次正面朝上发生在第一次抛硬币的情况下, 赢1元</li>
<li>如果第一次正面朝上发生在第二次抛硬币的情况下, 赢2元</li>
<li>如果第一次正面朝上发生在第三次抛硬币的情况下, 赢3元</li>
<li>如果没有正面朝上, 输1元</li>
</ul>
<p><img src="/Blog/intro/multinomial_dis_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/multinomial_dis_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>marginal <strong>pmf</strong> of X:</p>
<p><img src="/Blog/intro/multinomial_dis_9.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>marginal cdf of Y:</p>
<p><img src="/Blog/intro/multinomial_dis_10.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="联合连续分布-Joint-Continuous-Distribution"><a href="#联合连续分布-Joint-Continuous-Distribution" class="headerlink" title="联合连续分布 Joint Continuous Distribution"></a>联合连续分布 Joint Continuous Distribution</h2><p>对于两个连续型随机变量X, Y. <strong>joint cdf</strong> of X and Y is defined as:</p>
<script type="math/tex; mode=display">
F_{XY}(x,y)=P(X\le x,Y\le y)</script><blockquote>
<p>Definition extends to any numbers of rv’s</p>
<script type="math/tex; mode=display">
F_{XYZ}(x,y,z)=P(X\le x,Y\le y,Z\le z)</script></blockquote>
<p><br></p>
<p>Joint cdf的性质</p>
<p><img src="/Blog/intro/multinomial_dis_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><img src="/Blog/intro/joint_cdf_c.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/joint_cdf_c_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="Joint-pdfs-for-Continuous-rv"><a href="#Joint-pdfs-for-Continuous-rv" class="headerlink" title="Joint pdfs for Continuous rv"></a>Joint pdfs for Continuous rv</h3><p>两个连续型随机变量X,Y, the <strong>joint pdf</strong> of X and Y is a function f<sub>XY</sub>(x,y), satisfying:</p>
<script type="math/tex; mode=display">
P((X,Y)\in A)=\int\int_Af_{XY}(x,y)dx\ dy</script><p>for all sets A in R2</p>
<p><br></p>
<p>If the joint cdf is differentiable, then the joint pdf is the derivative of the joint cdf</p>
<p><br></p>
<h4 id="properties-of-Joint-pdfs"><a href="#properties-of-Joint-pdfs" class="headerlink" title="properties of Joint pdfs"></a>properties of Joint pdfs</h4><p><img src="/Blog/intro/joint_cdf_c_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="计算Joint-pdf-from-Joint-cdf"><a href="#计算Joint-pdf-from-Joint-cdf" class="headerlink" title="计算Joint pdf from Joint cdf"></a>计算Joint pdf from Joint cdf</h3><p><img src="/Blog/intro/joint_cdf_c_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="计算Joint-cdf-from-Joint-pdf"><a href="#计算Joint-cdf-from-Joint-pdf" class="headerlink" title="计算Joint cdf from Joint pdf"></a>计算Joint cdf from Joint pdf</h3><p><img src="/Blog/intro/joint_cdf_c_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h2 id="Marginal-pdfs"><a href="#Marginal-pdfs" class="headerlink" title="Marginal pdfs"></a>Marginal pdfs</h2><p><img src="/Blog/intro/joint_cdf_c_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/joint_cdf_c_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/joint_cdf_c_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="Conditional-Distributions"><a href="#Conditional-Distributions" class="headerlink" title="Conditional Distributions"></a>Conditional Distributions</h2><h3 id="Conditional-pdf"><a href="#Conditional-pdf" class="headerlink" title="Conditional pdf:"></a>Conditional pdf:</h3><p>如果我们观察到一个随机变量的值, Y=y, 那么第二个随机变量X的conditional pmf/pdf为:</p>
<script type="math/tex; mode=display">
f_{X|Y}(x|y)=\frac {f_{XY}(x,y)}{f_Y(y)}</script><p>assume f<sub>Y</sub>(y) &gt; 0</p>
<blockquote>
<p>f<sub>XY</sub>(x,y) is pmf if X and Y are discrete and pdfs if X and Y are continuous</p>
</blockquote>
<p>定义可以拓展到有更多随机变量的情况</p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/conditional_dis.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p> <img src="/Blog/intro/conditional_dis_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/conditional_dis_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h3 id="Conditional-cdf"><a href="#Conditional-cdf" class="headerlink" title="Conditional cdf"></a>Conditional cdf</h3><p><img src="/Blog/intro/conditional_dis_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="Extension-of-the-Law-of-Total-Probability"><a href="#Extension-of-the-Law-of-Total-Probability" class="headerlink" title="Extension of the Law of Total Probability"></a>Extension of the Law of Total Probability</h3><p>pmfs:</p>
<p><img src="/Blog/intro/conditional_dis_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>pdfs:</p>
<p><img src="/Blog/intro/conditional_dis_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>Waiting for a Bus at Rush Hour</p>
<p><img src="/Blog/intro/conditional_dis_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/conditional_dis_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="Covariance"><a href="#Covariance" class="headerlink" title="Covariance"></a>Covariance</h2><p><img src="/Blog/intro/Covariance_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/Covariance_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="Independence"><a href="#Independence" class="headerlink" title="Independence"></a>Independence</h2><p>定义:</p>
<p><img src="/Blog/intro/Covariance_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/Covariance_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/Covariance_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="Covariance-and-Independence"><a href="#Covariance-and-Independence" class="headerlink" title="Covariance and Independence"></a>Covariance and Independence</h3><p>如果X, Y independent, 则Cov(X,Y)=0</p>
<p><img src="/Blog/intro/Covariance_9.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h2 id="Bivariate-Normal-Density"><a href="#Bivariate-Normal-Density" class="headerlink" title="Bivariate Normal Density"></a>Bivariate Normal Density</h2><p><img src="/Blog/intro/Covariance_10.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_11.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example problems:</p>
<p><img src="/Blog/intro/Covariance_12.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_13.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_14.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_15.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_16.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_17.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_18.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/Covariance_19.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h2 id="Expectation-and-variance-of-sums-of-random-variables"><a href="#Expectation-and-variance-of-sums-of-random-variables" class="headerlink" title="Expectation and variance of sums of random variables"></a>Expectation and variance of sums of random variables</h2><h3 id="Expectation"><a href="#Expectation" class="headerlink" title="Expectation"></a>Expectation</h3><p>E[X+Y] = E[X] + E[Y]</p>
<p>if a<sub>i</sub> are constants,</p>
<script type="math/tex; mode=display">
E\ [a_0+\sum_ia_iX_i]=a_0+\sum_ia_iE[X_i]</script><p><br></p>
<p>example:</p>
<ul>
<li>Let X1 be the mark on midterm 1</li>
<li>Let X2 be the mark on midterm 1</li>
<li>Let Y be the mark on the final</li>
</ul>
<p>overall mark is</p>
<script type="math/tex; mode=display">
M=0.25X_1+0.25X_2+0.5Y</script><p>Then</p>
<script type="math/tex; mode=display">
E[M]=0.25E[X_1]+0.25E[X_2]+0.5E[Y]</script><p>The expectation doesn’t depends on the whether X1, X2, Y are independent.</p>
<p><br></p>
<p>proof:</p>
<p><img src="/Blog/intro/expect_2v.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h3 id="Variance-of-sums-Independence-case"><a href="#Variance-of-sums-Independence-case" class="headerlink" title="Variance of sums - Independence case"></a>Variance of sums - Independence case</h3><p>If X and Y are independent</p>
<script type="math/tex; mode=display">
Var[X+Y]=Var[X]+Var[Y]</script><p><img src="/Blog/intro/expect_2v_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h3 id="Variance-of-sums-dependence-case"><a href="#Variance-of-sums-dependence-case" class="headerlink" title="Variance of sums - dependence case"></a>Variance of sums - dependence case</h3><script type="math/tex; mode=display">
Var[X+Y]=Var[X]+Var[Y]+2Cov[X,Y]</script><p><img src="/Blog/intro/expect_2v_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>proof:</p>
<p><img src="/Blog/intro/expect_2v_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/expect_2v_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/expect_2v_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/expect_2v_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/expect_2v_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/expect_2v_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>注意 r = cor(Y1, Y2) / ( sd<sub>Y1</sub> * sd<sub>Y2</sub> )</p>
<p><br></p>
<p><br></p>
<h2 id="Central-Limit-Theorem"><a href="#Central-Limit-Theorem" class="headerlink" title="Central Limit Theorem"></a>Central Limit Theorem</h2><p>Expectation Variance and Distribution</p>
<h3 id="Averages-of-iid-Random-Variables"><a href="#Averages-of-iid-Random-Variables" class="headerlink" title="Averages of iid Random Variables"></a>Averages of iid Random Variables</h3><p>随机变量是iid(independent, identically and distributed) if they are independent, each with the same distribution.</p>
<p>The <strong>average</strong> of a collection of iid rv’s is commonly of interest(利益) in statistical contexts</p>
<p><br></p>
<p><img src="/Blog/intro/clt_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<blockquote>
<p>Linear combinations of normally distributed rv’s are normally distributed.</p>
</blockquote>
<p>如果Y1,…Yn 是iid, 并且服从N(μ, σ<sup>2</sup>), 则Y_bar ~ N(μ, σ<sup>2</sup>/n)</p>
<p><br></p>
<p>Example:</p>
<p><img src="/Blog/intro/iid_clt.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/iid_clt_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/iid_clt_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/iid_clt_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<h3 id="CLT"><a href="#CLT" class="headerlink" title="CLT"></a>CLT</h3><p><img src="/Blog/intro/iid_clt_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/iid_clt_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>example:</p>
<p><img src="/Blog/intro/iid_clt_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/iid_clt_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/iid_clt_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/iid_clt_9.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/iid_clt_10.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/iid_clt_11.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>example:</p>
<p><img src="/Blog/intro/clt_ex_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_ex_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_ex_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_ex_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_ex_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_ex_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/clt_ex_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>
<p><br></p>
<h2 id="贝叶斯统计-Bayesian-Statistic"><a href="#贝叶斯统计-Bayesian-Statistic" class="headerlink" title="贝叶斯统计(Bayesian Statistic)"></a>贝叶斯统计(Bayesian Statistic)</h2><p><img src="/Blog/intro/bs.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>频率论统计的流程是:</p>
<ol>
<li>根据问题提出假设$H_0, H_A$</li>
<li>假设 $H_0$ 为真, 计算当前情况可能发生的概率</li>
<li>根据这个概率进行决策</li>
</ol>
<p><br></p>
<p>而贝叶斯统计的流程是:</p>
<ol>
<li>根据问题提出假设 $H_1, H_2\cdots H_n$(可以有多个假设, 且假设的地位对等, 不像$H_0, H_A$那样是对立的)</li>
<li>根据收集到的证据(数据) 判断在当前证据下每一个假设为真的概率</li>
<li>根据这个概率进行决策</li>
</ol>
<p><br></p>
<p>而这个概率怎么求? 使用贝叶斯定理</p>
<p>if events B<sub>1</sub>, B<sub>2</sub>,…B<sub>k</sub> form a <strong>partition</strong> of S</p>
<script type="math/tex; mode=display">
\bigcup_{i=1}^KB_i=S\ \ and \ \ \bigcap_{i=1}^KB_i=\empty</script><p>Then:</p>
<script type="math/tex; mode=display">
P(B_i|A)=\frac {P(AB_i)} {P(A)}</script><script type="math/tex; mode=display">
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  =\frac {P(A|B_i)P(B_i)}{\sum_{j=1}^K P(A|B_j)P(B_j)}</script><p><br></p>
<p><br></p>
<h3 id="贝叶斯推断"><a href="#贝叶斯推断" class="headerlink" title="贝叶斯推断"></a>贝叶斯推断</h3><p><img src="/Blog/intro/bs_1.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>首先把样本空间分成两部分, 两部分交集为空, 并集为整个样本空间</p>
<p>对于每一个假设提出一个它为 true 的可能性的概率: $P(H_1), P(H_2)$</p>
<p><img src="/Blog/intro/bs_2.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>这个概率和频率论框架下的概率不同, 这个概率可以是主观信念</p>
<p>也叫做<strong>先验概率(Prior probability)</strong></p>
<p>这个概率取决于每个人的观点, 例如一个人认为明天有 $20\%$ 可能下雨, 而另一个人认为有$50\%$的可能下雨(可以根据喜好或经验决定这个概率)</p>
<p>接下来收集数据, 求出在 $H_1, H_2$ 为真的情况下看到当前数据的概率</p>
<p>在某个假设下看到当前数据的概率叫做 Likelihood (似然)</p>
<p><img src="/Blog/intro/bs_3.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>接下来就可以通过贝叶斯公式得到在当前数据为真的情况下$H_1, H_2$ 为真的概率, 这个概率就叫做<strong>后验概率(Posterior probability)</strong></p>
<p><img src="/Blog/intro/bs_4.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>之后可以继续进行测试, 第二次测试要用第一次测试的后验概率作为先验概率. (主观的信念在证据的面前得到更新) 这叫做贝叶斯更新</p>
<p><img src="/Blog/intro/bs_5.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p>这样就形成了一个循环, 不断通过证据更新概率. 这样即使最开始概率有偏差, 它也会逐渐接近真相.</p>
<p><br></p>
<p>举一个例子</p>
<p><img src="/Blog/intro/bs_6.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/bs_22.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>第一次迭代</p>
<p><img src="/Blog/intro/bs_7.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>假设到此为止, 我们会选择HIV</p>
<p><br></p>
<p>第二次迭代</p>
<p>把后验概率替换为先验概率</p>
<p><img src="/Blog/intro/bs_8.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>然而真正作决策时可能要考虑选错的损失. 此时就要对每个假设计算一下损失, 比较哪个损失更小.</p>
<p><br></p>
<p><br></p>
<h3 id="贝叶斯因子-Bayes-Factor"><a href="#贝叶斯因子-Bayes-Factor" class="headerlink" title="贝叶斯因子(Bayes Factor)"></a>贝叶斯因子(Bayes Factor)</h3><p><img src="/Blog/intro/bs_9.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>上个例子中就可以得到这样两个因子</p>
<p><img src="/Blog/intro/bs_10.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>怎么解读它们?</p>
<p><img src="/Blog/intro/bs_11.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="Odds-和-Odds-ratio"><a href="#Odds-和-Odds-ratio" class="headerlink" title="Odds 和 Odds ratio"></a>Odds 和 Odds ratio</h3><p><img src="/Blog/intro/bs_12.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>0.147 说明 HIV 不太可能发生</p>
<p>2.252 说明 HIV 有可能发生</p>
<p>odds ratio = 15.4 告诉我们: 当我们进行一次检测, 并且结果是阳性以后HIV发生的可能性是收集证据前HIV发生可能性的15.4倍</p>
<p><br></p>
<p><br></p>
<p>另一个例子:</p>
<p>假设研究问题: 治疗高血压的新药是否有效</p>
<p>方法: 让高血压患者复用新药一段时间, 然后检查高血压症状是否有所改善</p>
<p>使用症状得到改善的患者占总患者数的比例来近似代表新药的有效程度</p>
<p>数据: 100人复用新药, 78人症状有所改善</p>
<p><img src="/Blog/intro/bs_13.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/bs_14.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/bs_15.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><img src="/Blog/intro/bs_16.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<h3 id="先验概率的选择对后验概率的影响"><a href="#先验概率的选择对后验概率的影响" class="headerlink" title="先验概率的选择对后验概率的影响"></a>先验概率的选择对后验概率的影响</h3><p><img src="/Blog/intro/bs_17.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>这个图中, 后验概率和likelihood是一样的. 而如果我们换一个先验概率</p>
<p><img src="/Blog/intro/bs_18.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>后验概率是先验概率和 likelihood 的综合.</p>
<p><br></p>
<h3 id="样本容量对后验概率的影响"><a href="#样本容量对后验概率的影响" class="headerlink" title="样本容量对后验概率的影响"></a>样本容量对后验概率的影响</h3><p><img src="/Blog/intro/bs_19.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p>大样本降低了不确定性, 给出了一个更精准的范围, 可以看出大样本量, 只有6个点明显大于0.1, 而在小样本中则有很多点</p>
<p><br></p>
<h3 id="置信区间-credible-interval"><a href="#置信区间-credible-interval" class="headerlink" title="置信区间(credible interval)"></a>置信区间(credible interval)</h3><p>使用<strong>拒绝采样(rejection sampling)</strong> 方法从后验概率分布中抽样, 然后计算分位数以得到置信区间</p>
<p><br></p>
<h4 id="拒绝采样"><a href="#拒绝采样" class="headerlink" title="拒绝采样"></a>拒绝采样</h4><p>抽样次数: n = 100, 000</p>
<ul>
<li>x 代表 $p_{respond}$</li>
<li><p>y 代表 $p_{respond}$ 的后验概率</p>
<p><img src="/Blog/intro/bs_20.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
</li>
</ul>
<p><img src="/Blog/intro/bs_21.PNG" srcset="/Blog/img/loading.gif" lazyload alt=""></p>
<p><br></p>
<p><br></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/Blog/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/Blog/tags/%E6%95%B0%E5%AD%A6/">数学</a>
                    
                      <a class="hover-with-bg" href="/Blog/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">统计学</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/Blog/2020/04/10/machine-learning/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">python3入门机器学习(1)</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/Blog/2020/03/06/play-with-linear-algebra-4/">
                        <span class="hidden-mobile">线性代数补充知识</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/Blog/js/events.js" ></script>
<script  src="/Blog/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/Blog/js/local-search.js" ></script>



  
    <script  src="/Blog/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/Blog/js/boot.js" ></script>


</body>
</html>
