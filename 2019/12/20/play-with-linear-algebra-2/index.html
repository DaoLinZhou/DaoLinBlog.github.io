

<!DOCTYPE html>
<html lang="" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/Blog/img/favicon.png">
  <link rel="icon" href="/Blog/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Daolin">
  <meta name="keywords" content="">
  
    <meta name="description" content="专为程序员设计的线性代数-学习笔记(2)">
<meta property="og:type" content="article">
<meta property="og:title" content="&lt;专为程序员设计的线性代数&gt;学习笔记(2)">
<meta property="og:url" content="https://daolinzhou.github.io/Blog/2019/12/20/play-with-linear-algebra-2/index.html">
<meta property="og:site_name" content="Daolin&#39;s Repository">
<meta property="og:description" content="专为程序员设计的线性代数-学习笔记(2)">
<meta property="og:locale">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/unlinear_system.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_system.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/3d_linear_system.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/Elimination_method.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/Elimination_method_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_system_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_system_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_system_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/argument_metrix_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/gaosi_example.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/gaosi_method_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/gaosi_method_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/gaosi_method_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/gaosi_method_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/gaosi_method_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/no_solution_lineasr_system_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/many_solution_linear_system.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/many_solution_linear_system_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/solution_nums_linear_sys.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/floor_matrix.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/rref_example.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/not_rref_example.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/solution_form.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/solution_form_ex_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/solution_form_ex_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_10.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_11.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/functions_linear_st_12.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/general_gauss_jordan_elimination.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/general_gauss_jordan_elimination_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/solution_linear_system.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/pri_col.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/pri_col_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/relation_col_pri.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/relation_col_pri_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/find_solution_linear_sys.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/primary_matrix_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/primary_matrix_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/primary_matrix_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/primary_matrix_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_10.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_11.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_12.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_13.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_14.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_14.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_13.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_unin_L.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_10.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_11.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_matrix_L_U_12.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/step_find_inv_mat_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_not_matrix.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_not_matrix_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_not_matrix_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_not_matrix_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/LU_not_matrix_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_product_with_vector_c.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/understand_matrix_product_vector_col.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_10.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_10_res.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_11.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_12.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_13.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/PLUP_matrix_14.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/mem_basic_operator_vector.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_10.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_11.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_12.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_13.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_15.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_14.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_16.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_17.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/why_inv_matrix_important_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_11.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_10.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_11.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_12.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_13.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_14.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_15.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_10.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_16.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_17.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_18.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_19.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_20.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_21.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_111.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_13.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/generate_space.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_13.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/generate_space_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/generate_space_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/generate_space_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation_16.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/generate_space_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/generate_space_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/generate_space_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/inverse_matrix_linear_relation.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/generate_space_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/proof_basis_unique.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/ojilide_space.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/def_vector_operation.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/ten_rules_for_vec_space.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/what_is_vector_space.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/what_is_vector_space_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/what_is_vector_space_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/what_is_vector_space_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/what_is_vector_space_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/vector_subspace.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/vector_subspace_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/important_rule_subspace.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/important_rule_subspace_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/important_rule_subspace_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/ten_rules_for_vec_space_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/ten_rules_for_vec_space_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/ten_rules_for_vec_space_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/proof_subspace.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/direct_understand_subspace.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_example.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_example_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_example_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_algebra_dim_def.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/space_basics.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/subspace_dim.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/subspace_dim_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/property_space_base_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/subspace_dim_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/subspace_dim_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/subspace_dim_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/problem_from_prev.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/problem_from_prev_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/linear_combin_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/problem_from_prev_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/problem_from_prev_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/line_space.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/line_space_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/line_space_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/line_space_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/line_space_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/line_space_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/col_space.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/col_space_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/col_space_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/col_space_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/col_space_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/col_space_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/col_space_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_rank_rev.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/rref.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/rref_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/rref_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/rref_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/rref_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/rank.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/square_rank.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/matrix_properity.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/properties_for_squear.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/harmong_matrix.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/zero_space_proof_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/zero_space_proof_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/zero_space_proof_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/zero_space_proof_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/zero_space_proof_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_1.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_2.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_3.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_4.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_5.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_6.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_7.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_8.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/base_null_space_9.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/4_subspace.PNG">
<meta property="og:image" content="https://daolinzhou.github.io/Blog/Blog/intro/left_null_space.PNG">
<meta property="article:published_time" content="2019-12-20T09:11:18.000Z">
<meta property="article:modified_time" content="2020-03-21T21:26:36.441Z">
<meta property="article:author" content="Daolin">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="线性代数">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://daolinzhou.github.io/Blog/Blog/intro/unlinear_system.PNG">
  
  
  <title>&lt;专为程序员设计的线性代数&gt;学习笔记(2) - Daolin&#39;s Repository</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/Blog/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"daolinzhou.github.io","root":"/Blog/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/Blog/local-search.xml"};
  </script>
  <script  src="/Blog/js/utils.js" ></script>
  <script  src="/Blog/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 6.1.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/Blog/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blog/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/Blog/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="&lt;专为程序员设计的线性代数&gt;学习笔记(2)">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2019-12-20 01:11" pubdate>
        December 20, 2019 am
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      29k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      244 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">&lt;专为程序员设计的线性代数&gt;学习笔记(2)</h1>
            
            <div class="markdown-body">
              <p>专为程序员设计的线性代数-学习笔记(2)</p>
<span id="more"></span>

<h1 id="线性系统"><a href="#线性系统" class="headerlink" title="线性系统"></a>线性系统</h1><p>之前介绍过看待矩阵的4种视角, 其中一个非常重要的视角就是: <strong>把矩阵看作是对于一个系统的描述(线性系统)</strong></p>
<p>这一章就会介绍当把矩阵看作是对线性系统的描述之后, 我们如何用矩阵解决线性系统的相关问题</p>
<br>

<h2 id="线性系统与消元法"><a href="#线性系统与消元法" class="headerlink" title="线性系统与消元法"></a>线性系统与消元法</h2><h3 id="线性系统-1"><a href="#线性系统-1" class="headerlink" title="线性系统"></a>线性系统</h3><p>什么是线性系统? 就是线性方程组.</p>
<figure class="highlight apache"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs apache"> <span class="hljs-attribute">x</span> + <span class="hljs-number">2</span>y = <span class="hljs-number">5</span><br><span class="hljs-attribute">3x</span> + <span class="hljs-number">4</span>y = <span class="hljs-number">6</span><br></code></pre></td></tr></table></figure>

<p>线性系统的核心是<strong>线性</strong>二字. </p>
<p>什么是线性? 未知数只能是<strong>一次方</strong>项</p>
<p>非线性方程:  </p>
<ul>
<li>x^2 - 1 &#x3D; 0 (x是二次方项)</li>
<li>root(z) - 4 &#x3D; 0 (z是1&#x2F;2次方项)</li>
<li>sin(x) &#x3D; pi (x不是一次方, 它被sin符号包裹, 已经不是多项式函数而是三角函数)</li>
</ul>
<p>它们的函数图像如果绘制出来都是<strong>曲线</strong>的形状</p>
<p><img src="/Blog/Blog/intro/unlinear_system.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>而线性方程在二维坐标系中都表示的是一条<strong>直线</strong></p>
<p><img src="/Blog/Blog/intro/linear_system.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>在高中进一步拓展解析几何的概念, 如果有三个(以上)未知数, 只要所有未知数都是<strong>一次项</strong>, 也是满足<strong>线性</strong>这个条件的</p>
<br>

<p>例如: x + y + 2z &#x3D; 0</p>
<p>不过如果把这个式子绘制在三维坐标系中, 它表示的是一个<strong>平面</strong></p>
<p><img src="/Blog/Blog/intro/3d_linear_system.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>这样一个平面我们也将其称之为<strong>线性</strong>, 也就是说这里我们所说的线性是<strong>广义</strong>地线性的含义, 它不意味着式子表示出来一定是空间中的一条直线</p>
<p>若干个这样的线性方程组合在一起就是<strong>线性系统</strong></p>
<br>

<p>研究线性系统最重要的一个原因就是<strong>要解决这个线性系统</strong></p>
<p>就是要解线性方程组, 虽然看起来只是一个计算问题, 但随着深入我们就会发现这个计算本身是非常有意义的</p>
<p>不仅仅是我们可以把生活中实际的问题给建模成这样线性系统的样子, 与此同时, 我们解决线性系统还能解决线性代数这个领域内部的一些抽象的数学问题</p>
<br>

<h3 id="消元法"><a href="#消元法" class="headerlink" title="消元法"></a>消元法</h3><p>基本思想就是如果系统中有n个未知数, 我们可以想办法消去一个未知数, 让它有n-1个未知数, 重复这个过程</p>
<p><img src="/Blog/Blog/intro/Elimination_method.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>更为复杂一点</p>
<p><img src="/Blog/Blog/intro/Elimination_method_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>总结一个消元的过程中我们会进行哪些操作:</p>
<ol>
<li>一个方程的左右两边同时乘以一个常数</li>
<li>一个方程加 ( 减 ) 另一个方程</li>
<li>交换两个方程的位置</li>
</ol>
<p>通过这三个基本操作, 就可以不断地改变线性方程组, 从而达到消元的目的, 最终得到线性系统的解</p>
<br>

<br>

<h2 id="高斯消元法"><a href="#高斯消元法" class="headerlink" title="高斯消元法"></a>高斯消元法</h2><h3 id="增广矩阵"><a href="#增广矩阵" class="headerlink" title="增广矩阵"></a>增广矩阵</h3><p>之前说过可以使用矩阵代表矩阵系统, 相应的也可以使用基于矩阵的操作来解决线性系统相关的问题</p>
<p><img src="/Blog/Blog/intro/linear_system_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>可以表达如下, 且由此推导出矩阵和向量相乘相应的意义</p>
<p><img src="/Blog/Blog/intro/linear_system_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>在解决线性系统相关的问题时, 我们可以更进一步, 直接扔掉未知数, 而把<strong>系数矩阵</strong>和<strong>结果列向量</strong>合在一起</p>
<p><img src="/Blog/Blog/intro/linear_system_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>(x, y, z) 这个列向量并没有为我们提供任何有意义的信息, 叫他们xyz也可以, abc也可以… 就是三个未知数, 特意用符号表示他们意义是不大的</p>
<br>

<p>唯一的意义就是<strong>告诉我们线性系统中有几个未知数</strong></p>
<p>然而, 线性系统中有几个未知数也隐藏在系数矩阵中, 这个线性系统的<strong>列数</strong>就代表了有几个未知数</p>
<p>完全可以用这样的矩阵进行表示, 我们将这样的矩阵称为: <strong>增广矩阵(argument matrix)</strong></p>
<p><img src="/Blog/Blog/intro/argument_metrix.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>这个增广矩阵中的每一行完全对应了线性方程组中的一个方程</p>
<p>像原先解方程一样, 第二个方程减去第一个方程乘以三(消去第二个方程中的x), 可以直接这样表示</p>
<p><img src="/Blog/Blog/intro/argument_metrix_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>同理消去第三个方程中的x, (3) - (1) * 2</p>
<p><img src="/Blog/Blog/intro/argument_metrix_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>下一步就是把第三行的y给消去, 即让增广矩阵中第三行第二个元素变为0</p>
<p>(2) + (3)</p>
<p><img src="/Blog/Blog/intro/argument_metrix_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>等式两边同时除以-15</p>
<p><img src="/Blog/Blog/intro/argument_metrix_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>总结一下</p>
<p><img src="/Blog/Blog/intro/argument_metrix_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>之前说对线性方程组进行求解的三个基本的操作</p>
<ol>
<li>一个方程的左右两边同时乘以一个常数</li>
<li>一个方程加 ( 减 ) 另一个方程</li>
<li>交换两个方程的位置</li>
</ol>
<p>现在一旦使用增广矩阵表示线性系统时, 这三个操作都可以转化成在矩阵上的基本操作</p>
<ol>
<li>矩阵的某一行乘以一个常数</li>
<li>矩阵的一行加 (减) 另外一行</li>
<li>交换矩阵的两行</li>
</ol>
<br>

<p>通过这三个基本操作就可以把一个矩阵变成这个样子(倒三角)</p>
<p><img src="/Blog/Blog/intro/argument_metrix_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>只要变成这个样子就可以通过最后一行得到最后一个未知数的解</p>
<p>把这个解带到前面一行, 得到第二个未知数的解…</p>
<br>

<p>有三个未知数, 相应的我们就有三个方程, 如果有n个未知数, 就应该有n个方程</p>
<p><strong>对于有n个未知数的方程组来说, 它有唯一的解的非常重要的前提条件: 至少要有n个方程</strong></p>
<br>

<h3 id="高斯消元法-1"><a href="#高斯消元法-1" class="headerlink" title="高斯消元法"></a>高斯消元法</h3><p>再回头看消元的过程</p>
<p><img src="/Blog/Blog/intro/argument_metrix_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>当为(2), (3)消去第一个未知数时, 以(1)的第一个未知数为基准, (2) - 3 * (1),  (3) - 2 * (1), 通常我们将其称之为<strong>主元&#x2F;首元(pivot)</strong></p>
<p><img src="/Blog/Blog/intro/argument_metrix_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>同理当要对第三行消去一个元(把第三行第二个元素变成0), 此时以第二行的第二个元素为基准, 消去第三行的第三个元素, 对于第二行的这个元素, 也可以称为主元</p>
<p><img src="/Blog/Blog/intro/argument_metrix_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>同理第三行唯一的元素就是第三行的主元</p>
<br>

<p>消元首先确定当前行的主元是谁, 可以发现第 i 行的主元就是第 i 个元素</p>
<p>消元的过程就是每次那第 i 行的第 i 个元素当作<strong>主元</strong>, 把主元<strong>化为1</strong>, 之后其他行就可以使用矩阵的基本操作把相应的这个位置<strong>化为0</strong>, 整个过程以此类推, 就可以把整个矩阵化为这种形状</p>
<p><img src="/Blog/Blog/intro/argument_metrix_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这种消元的过程就叫<strong>高斯消元法</strong></p>
<p>注意: 由于要把主元化为1, 所以<strong>主元不能为0</strong></p>
<br>

<p>例子: </p>
<p><img src="/Blog/Blog/intro/gaosi_example.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="高斯-约旦消元法"><a href="#高斯-约旦消元法" class="headerlink" title="高斯-约旦消元法"></a>高斯-约旦消元法</h2><p><img src="/Blog/Blog/intro/gaosi_method_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>把主元化为1, 主元下面的所有元素化为0</p>
<p>当最后求出最后一个元素的解之后, 就可以用过回代把所有的解都求出来</p>
<br>

<p>能否直接看出来前二个未知数是多少呢?</p>
<p>可以, 只要继续进行矩阵的那些基本操作就好了</p>
<br>

<p>(2) + 10 * (3) 把第二行的最后一个元素化为0</p>
<p><img src="/Blog/Blog/intro/gaosi_method_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>以最后一行的主元为基准, 倒着把上一行主元位置的值化为0, </p>
<p>相当于倒着再进行一次高斯消元</p>
<br>

<p>同样的, 可以消去第一行的第三个未知数</p>
<p>(1) - 4 * (3)</p>
<p><img src="/Blog/Blog/intro/gaosi_method_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>最后(1) - 2 * (2)</p>
<p><img src="/Blog/Blog/intro/gaosi_method_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>此时就可以看出整个线性系统的解</p>
<p><img src="/Blog/Blog/intro/gaosi_method_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这个方法就是在<strong>高斯消元法</strong>的基础上, 再进行一次<strong>逆序地消元</strong></p>
<p>把前面的方程中, 除了主元以外的其他未知数给消去</p>
<p>这个方法就被称作<strong>高斯-约旦消元法 Gauss-Jordan Elimination</strong></p>
<br>

<p>再整理一遍整体的步骤:</p>
<ul>
<li>前向过程 (从上到下) (让每一行的未知数越来越少)<ul>
<li>选择最上的主元, 化为1</li>
<li>主元下面的所有行减去主元所在行的某个倍数, 使得主元下面所有元素都为0</li>
</ul>
</li>
<li>后向过程(从下到上) (是否有后向过程是高斯消元法和高斯约旦消元法的最大区别)<ul>
<li>选择最下的主元</li>
<li>主元上面的所有行减去主元所在行的某个倍数, 使得主元上面所有元素都为0</li>
</ul>
</li>
</ul>
<br>

<h2 id="行最简形式和线性方程组解的结构"><a href="#行最简形式和线性方程组解的结构" class="headerlink" title="行最简形式和线性方程组解的结构"></a>行最简形式和线性方程组解的结构</h2><h3 id="线性方程组解的结构"><a href="#线性方程组解的结构" class="headerlink" title="线性方程组解的结构"></a>线性方程组解的结构</h3><p>在之前使用**高斯-约旦消元法(Gauss-Jordan Elimination)**时, 我们都默认线性方程组是有唯一解的</p>
<p>然而, 当我们面对一个线性系统的模型时, 这些线性系统还有可能<strong>没有解</strong> 或者 <strong>有无数个解</strong></p>
<br>

<p>无解的例子: </p>
<p><img src="/Blog/Blog/intro/no_solution_lineasr_system_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>无数解的例子:</p>
<p>先进行高斯消元</p>
<p><img src="/Blog/Blog/intro/many_solution_linear_system.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>再进行约旦消元: 从最后一个主元开始反向消元, 但最后一个主元再第二行, 所以(1) - 2 * (2)</p>
<p><img src="/Blog/Blog/intro/many_solution_linear_system_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>整理成方程组的形式就是:</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs makefile">- x - 7z = 0<br>y + 5z = 0<br><br><span class="hljs-section">即:</span><br><br>x = -7z<br>y = -5z<br></code></pre></td></tr></table></figure>

<p>这意味着z任意取值, 都能得到一组x, y, z, 满足方程组</p>
<p>方程组有无数组解</p>
<br>

<p>这三种情况分别对应: <strong>有唯一解, 无解, 有无数组解</strong></p>
<p><img src="/Blog/Blog/intro/solution_nums_linear_sys.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="行最简形式"><a href="#行最简形式" class="headerlink" title="行最简形式"></a>行最简形式</h3><p>之前我们对<strong>增广矩阵</strong>进行消元的过程(即高斯消元的过程), 其实是把增广矩阵变换成<strong>阶梯型矩阵</strong></p>
<p><img src="/Blog/Blog/intro/floor_matrix.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>当一个矩阵满足这三个条件(即我们执行高斯-元旦消元法之后得到的矩阵)</p>
<ol>
<li>阶梯型矩阵</li>
<li>非零行的第一个元素(主元) 为1</li>
<li>主元所在列的其他元素均为0</li>
</ol>
<p>我们称这样的矩阵为<strong>行最简形式 (reduced row echelon form (RREF))</strong></p>
<br>

<p>为什么要引入这个概念? </p>
<p>因为无论是求解方程组, 还是看线性方程组解的结构, 其实都是通过行<strong>最简形式</strong>来看的</p>
<p><img src="/Blog/Blog/intro/rref_example.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><img src="/Blog/Blog/intro/not_rref_example.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>第一个矩阵第二行的首元所在列的其他元素有不为0的存在</p>
<p>第二个矩阵不是阶梯型</p>
<p>第三个矩阵的非零行在全零行的下面 (阶梯矩阵要求全零行在矩阵的最下面)</p>
<br>

<p>若要判断增广矩阵的解的格式, 首先要用高斯约旦消元法把矩阵化为<strong>行最简形式</strong></p>
<p><img src="/Blog/Blog/intro/solution_form.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><strong>方程组有唯一解: 非零行的个数 &#x3D; 未知数的个数</strong></p>
<p><strong>方程组无解</strong>: <strong>系数矩阵的非零行 &lt; 行最简形式的非零行</strong>, 即系数矩阵中有一个零行, 它所对应的结果不为0(矛盾, 无解)</p>
<p><strong>方程组有无数解</strong>: <strong>非零行的个数 &lt; 未知数的个数</strong></p>
<br>

<p>例子:</p>
<p><img src="/Blog/Blog/intro/solution_form_ex_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>非零行个数 &lt; 未知数个数, 所以有无数解</p>
<br>

<p><img src="/Blog/Blog/intro/solution_form_ex_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>非零行个数等于未知数的个数, 有唯一解</p>
<br>

<h2 id="直观理解线性方程组解的结构"><a href="#直观理解线性方程组解的结构" class="headerlink" title="直观理解线性方程组解的结构"></a>直观理解线性方程组解的结构</h2><p>n个未知数有n个方程, 才<strong>可能</strong>有唯一解</p>
<p>每一个方程相当于一个约束条件</p>
<p><img src="/Blog/Blog/intro/functions_linear_st.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>如果一个方程有三个未知数, 它所表示的就是三维空间中的一个平面</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>那么现在, 如果有三个未知数, 但是有两个方程</p>
<p>如果两个平面相交, 它们相交的地方是一条直线</p>
<p>这一条线上的所有点, 同时满足这两个方程</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>但如果两个平面平行, 则无解</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>如果三个三元方程联立, 同时第三个平面和前两个平面相交的直线再次相交, 才可能会产生唯一的一个点, 这个点就是这个三元方程组的唯一解</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>如果是这样相交, 相交的地方依然是一条直线, 则会有无数个解</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>同样三个平面有可能没有交点, 即没有解</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>当方程的个数大于未知数的个数时, 很大的可能, 方程组是无解的</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>虽然这三条线两两相交, 但他们没有交于一点,</p>
<p>只有第三条线穿过前两条线的交点, 它们才有解</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>当方程数多于未知数的个数时, 其实我们是有<strong>多余的约束</strong>, 这会使得方程组<strong>高概率</strong>没有解</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><strong>对于行最简形式, 系数矩阵的非零行不可能大于未知数的个数</strong></p>
<p>对于有n个未知数的矩阵, 行最简形式最多有n个<strong>首元</strong>, 即n列, 这意味着最多只能有3行</p>
<p>由于不可能存在非零行的个数<strong>大于</strong>未知数的个数这种情况, 所以上面表格可以化简为: </p>
<p><img src="/Blog/Blog/intro/functions_linear_st_10.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>我们假设方程组中没有矛盾(即不可能无解)</p>
<p>那么当: <strong>行最简形式的非零行个数 &#x3D; 未知数个数</strong></p>
<p>当系数矩阵的非零行等于未知数时, 此时这一部分非零行一定是<strong>单位矩阵</strong></p>
<p>例如: </p>
<p><img src="/Blog/Blog/intro/functions_linear_st_11.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>于是整个表格就可以化简为这样:</p>
<p><img src="/Blog/Blog/intro/functions_linear_st_12.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="更一般化的高斯-约旦消元法"><a href="#更一般化的高斯-约旦消元法" class="headerlink" title="更一般化的高斯-约旦消元法"></a>更一般化的高斯-约旦消元法</h2><p>之前进行高斯约旦消元法时所使用的对象都是n个方程对应n个未知数</p>
<br>

<p>回忆一下 高斯-约旦消元法(<strong>Gauss-Jordan Elimination</strong>)</p>
<ol>
<li>前向过程 (从上到下)<ol>
<li>选择最上的主元, 化为1</li>
<li>主元下面的所有行减去主元所在行的某个倍数, 使得主元下面所有元素都为0</li>
</ol>
</li>
<li>后向过程 (从下到上)<ol>
<li>选择最下的主元</li>
<li>主元上面的所有行减去主元所在行的某个倍数, 使得主元上面所有元素都为0</li>
</ol>
</li>
</ol>
<p>如果未知数和方程数不匹配, 我们也要严格遵守这本步骤</p>
<br>

<p>例子:</p>
<p>前向消元</p>
<p><img src="/Blog/Blog/intro/general_gauss_jordan_elimination.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>后向消元</p>
<p><img src="/Blog/Blog/intro/general_gauss_jordan_elimination_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>很显然, 没有矛盾的行, 所以方程组一定有解,</p>
<p>未知数个数 &gt; 非零行个数, 所以有无穷多解</p>
<p>我们可以把行最简形式转化为方程组</p>
<p><img src="/Blog/Blog/intro/solution_linear_system.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>把方程组转化为主元在左, 其余项在右的形式</p>
<p>w, 和y任意取值, 都会生成一个解</p>
<br>

<p>和先前普通的高斯约旦消元法相比, 不同之处在于: <strong>选取的主元不一定在第i行第i列的位置</strong>, 因此并不一定每一列都有主元</p>
<p>此时我们称含有主元的列叫<strong>主元列</strong>, 而不含有主元的列叫<strong>自由列</strong></p>
<p><img src="/Blog/Blog/intro/pri_col.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>可以看到, 我们最后写出方程组的等号左边都是主元列所代表的未知数</p>
<p>更进一步可以写成这种形式</p>
<p><img src="/Blog/Blog/intro/pri_col_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>没有未知数的组成一列, 包含未知数y的组成一列, 包含w的组成一列</p>
<p>而这些系数组成的列在行最简形式中的表现为(<strong>自由列</strong>)</p>
<p><img src="/Blog/Blog/intro/relation_col_pri.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因为要从等号左边移到等号右边, 所以要取反</p>
<br>

<p>另一个例子</p>
<p><img src="/Blog/Blog/intro/relation_col_pri_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>明显出现矛盾, 所以无解</p>
<br>

<br>

<h2 id="齐次线性方程组"><a href="#齐次线性方程组" class="headerlink" title="齐次线性方程组"></a>齐次线性方程组</h2><p>只要方程组等号右边的值<strong>全部</strong>为0, 我们就成这个方程组为<strong>齐次线性方程组</strong>, 反之, 只要有一个值非零, 那就称之为<strong>非齐次线性方程组</strong></p>
<figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs llvm">-<span class="hljs-keyword">x</span> + <span class="hljs-number">2</span>y + <span class="hljs-number">3</span>z <span class="hljs-operator">=</span> <span class="hljs-number">0</span><br><span class="hljs-keyword">x</span> - <span class="hljs-number">4</span>y - <span class="hljs-number">13</span>z <span class="hljs-operator">=</span> <span class="hljs-number">0</span><br><span class="hljs-number">-3</span><span class="hljs-keyword">x</span> + <span class="hljs-number">5</span>y + <span class="hljs-number">4</span>z <span class="hljs-operator">=</span> <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

<p>齐次线性方程组只是一个概念, 求解它和求解普通的线性方程组是没有任何区别的</p>
<p><img src="/Blog/Blog/intro/find_solution_linear_sys.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>齐次线性方程组一定是有解的, 所有未知数都为0一定是一个解</p>
<p>至于判断是否有无穷多解, 则和之前一样化为行最简形式进行判断</p>
<br>

<p>齐次线性方程组在线性代数中有着特殊的意义, 尤其是学完”空间”之后</p>
<br>

<br>

<h1 id="初等矩阵和矩阵的可逆性"><a href="#初等矩阵和矩阵的可逆性" class="headerlink" title="初等矩阵和矩阵的可逆性"></a>初等矩阵和矩阵的可逆性</h1><h2 id="线性系统与矩阵的逆"><a href="#线性系统与矩阵的逆" class="headerlink" title="线性系统与矩阵的逆"></a>线性系统与矩阵的逆</h2><p><img src="/Blog/Blog/intro/inverse_matrix.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>只有方阵才有逆</p>
<p>假设矩阵A有逆矩阵, 如何求解?</p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>之后就变成了线性系统求解</p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而我们知道, 如果这个线性系统有解, 则一定可以转化为单位矩阵这样的形式</p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>其实这两个增广矩阵的系数是相同的, 区别只是结果向量, 而<strong>高斯约旦消元法就是对系数矩阵进行操作</strong>, 而右侧的结果向量的变换是根据系数矩阵的变化而进行变化的</p>
<p>因此我们可以不分别处理这两个增广矩阵, 因此我们可以这样写</p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>虚线右侧的两列就代表两个不同的结果列向量</p>
<p>我们直接对这个增广矩阵的<strong>系数矩阵</strong>进行化简就好了</p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>对于这种结构, <strong>不可能有无数解</strong>, 因为右侧是一个单位矩阵, 即每一列只有一个元素, 所以无论如何加减都不可能出现<strong>全零行</strong></p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>就像之前证明过的一样, 如果一个方阵有逆矩阵, 它的逆矩阵一定为1</p>
<br>

<p>但这种结构可能是无解的, 此时该矩阵是没有逆矩阵的</p>
<p>何时无解? <strong>系数矩阵</strong>化为行最简形式时有<strong>0行</strong>, 虽然<strong>增广矩阵</strong>不可能出现全零行, 但系数矩阵可能有0行, 而由于没有全零行, 所以此行对于结果向量中的元素非零, 零等于非零产生矛盾所以无解</p>
<br>

<p>而对于矩阵的逆有一个性质: <strong>如果方阵A有右逆B, 则B也是A的左逆, 即B是A的逆</strong>, 日后我们会证明它</p>
<br>

<br>

<h2 id="初等矩阵"><a href="#初等矩阵" class="headerlink" title="初等矩阵"></a>初等矩阵</h2><p>我们解一个<strong>线性系统</strong>的过程就是对表示这个线性系统的<strong>增广矩阵</strong>进行以下三种基本的矩阵操作:</p>
<ul>
<li>矩阵的某一行乘以一个常数</li>
<li>矩阵的一行加减另一行</li>
<li>交换矩阵的两行</li>
</ul>
<p>而这三种操作依旧是在矩阵中针对**特定的元素(特定的一行)**进行操作</p>
<p>但是在之前我们就说过, <strong>矩阵可以表示变换</strong>: 例如矩阵T乘以表示点集的矩阵A, 就将A中所表示的点转换为另外一些点 </p>
<p>而这种操作是在针对<strong>矩阵级别</strong>进行操作</p>
<p><strong>矩阵级别的操作: 若想对矩阵A进行变化, 之间左乘一个变换矩阵就好了, 而不是在矩阵A中对逐一的元素进行操作</strong></p>
<br>

<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而我们对线性系统求解的三个基本操作是否也可以使用矩阵来表示呢?</p>
<p>即我们能否找到一个矩阵E使得: E * A &#x3D; A’     (A为表示线性系统的矩阵)</p>
<p>如果我们能找到, 那么对增广矩阵进行的基本操作本质上就是不断<strong>左乘</strong>这些矩阵E, 这样我们就把<strong>矩阵的基本操作</strong>转化为了<strong>矩阵的乘法操作</strong></p>
<br>

<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>首先我们可以很容易找到一个矩阵**(单位矩阵)**, 这个矩阵乘以另外一个矩阵得到的结果还是原矩阵</p>
<p>这里我们同样可以把单位矩阵理解为变换矩阵, 只不过这个变换矩阵对右乘的矩阵没有做任何变换</p>
<br>

<p>回忆一下为什么单位矩阵乘以一个矩阵会得到原先的矩阵, 以下图为例:</p>
<p>这里称被变换的矩阵为矩阵A</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>按照矩阵乘法的定义</p>
<p>结果矩阵的第一行第一列的值是 <strong>单位矩阵的第一行点乘矩阵A的第一列</strong></p>
<p>由于第一行只有第一个元素是1, 其余元素都是0, 所以最后我们只留下了矩阵A中第一列的第一个元素: a</p>
<p>b, c同理</p>
<p>对于第二行只有第二个元素的值为1, 所以点乘矩阵A的每一列之后, 只留下了矩阵A中每一列的第二个元素, 即: d, e, f</p>
<p>以此类推</p>
<br>

<h3 id="矩阵的某一行乘以一个常数"><a href="#矩阵的某一行乘以一个常数" class="headerlink" title="矩阵的某一行乘以一个常数"></a>矩阵的某一行乘以一个常数</h3><p>而对于矩阵的基本操作, 我们可以让某一行取乘以一个常数</p>
<p>假设让第一行乘以k, 那么通过刚才的分析, 变换矩阵就应该长这样:</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="让矩阵的一行加-减-另一行"><a href="#让矩阵的一行加-减-另一行" class="headerlink" title="让矩阵的一行加(减)另一行"></a>让矩阵的一行加(减)另一行</h3><p>假设我们要第三行加上第一行</p>
<p>为什么在单位矩阵上得到的结果就是原来的g, h, i</p>
<p>一位对于单位矩阵来说, 第三行乘以矩阵A中的每一列, 对于这一列来说, 前面的两个元素在单位矩阵中对应的都是0, 只有第三个元素所对应的系数为1, 所以每一列都只剩下第三个元素, 最终组合成了原来的第三行</p>
<p>现在我们希望第三行除了自身的那个元素, 还要加上第一个元素, 显然变换矩阵应为:</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>而如果是第一行减去第三行则是</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>同理若是第二行减去p倍的第三行则是</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="交换矩阵的两行"><a href="#交换矩阵的两行" class="headerlink" title="交换矩阵的两行"></a>交换矩阵的两行</h3><p>例如: 交换矩阵的2, 3行</p>
<p>根据先前的分析, 当单位矩阵第二行点乘矩阵A的每一列时, 只保留第三个元素, 而第三行点乘A的每一列时只保留第二个元素, 因此:</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>也可以理解为把原来的单位矩阵的第二行和第三行进行交换, 因为单位矩阵第二行点乘A的每一列的结果是结果就是矩阵中的第二行</p>
<br>

<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>我们对结果矩阵的变换都可以转化为对单位矩阵的变换</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="正儿八经的形式化概念"><a href="#正儿八经的形式化概念" class="headerlink" title="正儿八经的形式化概念"></a>正儿八经的形式化概念</h3><p>之前我们一直称这三种操作是<strong>矩阵的基本操作</strong>, 实际上它有一个正儿八经的名字: <strong>矩阵的初等变换</strong></p>
<p>而这些对应矩阵初等变换的<strong>变换矩阵</strong>我们称之为: <strong>初等矩阵</strong></p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><strong>初等矩阵: 对单位矩阵进行一次初等变换得到的结果矩阵</strong></p>
<p>通常记作E</p>
<br>

<p>回忆: 使用Gauss-Jordan消元法把矩阵化为行最简形式的过程:</p>
<p>使用矩阵的初等变换把增广矩阵化为行最简形式</p>
<p>而现在我们就可以使用新的概念: </p>
<p>对增广矩阵进行矩阵的初等变换, 而每一个初等变换都对应了一个变换矩阵E, 即: </p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>行最简形式的缩写就是: <strong>rref</strong></p>
<p>了解了初等矩阵就可以转而从矩阵运算的视角来理解Gauss-Jordan消元法了, 即: <strong>和一系列的初等矩阵进行一系列的乘法运算</strong></p>
<br>

<br>

<h2 id="从初等矩阵到矩阵的逆"><a href="#从初等矩阵到矩阵的逆" class="headerlink" title="从初等矩阵到矩阵的逆"></a>从初等矩阵到矩阵的逆</h2><p><img src="/Blog/Blog/intro/primary_matrix_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>初等矩阵对单位矩阵进行一次初等变换得到的</p>
<p>因为初等变换有三种, 所以初等矩阵就有三种形态</p>
<br>

<p><strong>初等矩阵一定是可逆的</strong></p>
<p>因为初等变换是可逆的, 所以初等矩阵是可逆的</p>
<p><img src="/Blog/Blog/intro/primary_matrix_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>例如: </p>
<p>E1表示把一个矩阵的第一行都乘以k倍</p>
<p>E2表示把一个矩阵的第一行都乘以1&#x2F;k倍</p>
<p>这两个初等矩阵所表示的初等变换<strong>互为逆操作</strong>, 当然这么说并不是非常严谨, 我们并没有<strong>从矩阵的逆的定义出发</strong>来推导出二者真的是互为矩阵的逆的关系</p>
<p>但这也非常简单:</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs gcode">我们把E<span class="hljs-number">1</span>看作是E<span class="hljs-number">2</span>的变化矩阵<br>E<span class="hljs-number">1</span>表达的意思是让E<span class="hljs-number">2</span>的第<span class="hljs-number">1</span>行乘以k倍<br>因此E<span class="hljs-number">2</span>的第一行变为 k * <span class="hljs-comment">(1/k, 0, 0)</span> = <span class="hljs-comment">(1, 0, 0)</span><br>E<span class="hljs-number">1</span> * E<span class="hljs-number">2</span> = I<br>同理也可以证明<br>E<span class="hljs-number">2</span> * E<span class="hljs-number">1</span> = I<br>因此 E<span class="hljs-number">1</span> 和 E<span class="hljs-number">2</span> 互为逆矩阵<br>我们根本不用进行计算, 只要根据初等矩阵表示的意义出发就好<br></code></pre></td></tr></table></figure>

<br>

<p><img src="/Blog/Blog/intro/primary_matrix_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>再看这个初等矩阵, 上面矩阵的含义是让第二行减去p倍的第三行, 而下面矩阵的含义是让第二行加上p倍的第三行, 它们也互为逆</p>
<br>

<p><img src="/Blog/Blog/intro/primary_matrix_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这个矩阵表达的意思就是交换第二行和第三行, 我们若想变换回去, 只要再互换一次就好了, 因此这个矩阵的逆矩阵就是自身</p>
<br>

<p>之前我们也说Gauss-Jordan消元法可以理解为寻找一系列初等矩阵, 使得:</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><strong>如果矩阵A可逆</strong>(假设为2 * 2), 回忆之前的分析: </p>
<p>那么把矩阵A和同等大小的单位矩阵拼接起来形成的增广矩阵一定<strong>有解</strong></p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_10.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而<strong>系数矩阵</strong>化为行最简形式有0行则<strong>无解</strong></p>
<p>而有解就说明不可能存在0行</p>
<p>而对于左侧的矩阵A, 我们要求它的逆矩阵, 显然A是一个方阵, 它的行最简形式每一行一定是非零行, 因此A的行最简形式一定是单位矩阵I的形式</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_11.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>也就是说如果A可逆, 则存在一系列E, 使得</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>既然是这样的式子, 我们就可以左右同时右乘A的逆</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_12.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>根据结合律, 解得:</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_13.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因此我们完全可以把它简化为这样</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_14.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>把A和I粘贴在一起, 对这个增广矩阵, 基于左侧的A, 把它转化为行最简形式, 进行矩阵的初等变换. E1…Ep</p>
<p>而这些初等变换同时也会作用在I上</p>
<p>当我们把左侧的A化为I之后, 相应的右侧的I就化为了A的逆</p>
<br>

<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_14.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而这个式子就相当于下面两个式子</p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/matrix_trans_find_linear_sys_sol_13.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>红色箭头就是这一系列初等变换的过程</p>
<br>

<p>这和我们之前求解矩阵的逆的方法是<strong>一致</strong>的, 只不过我们解决这个问题的视角不同</p>
<p>我们之前将求解矩阵逆的问题转换为求解线性系统的问题</p>
<p>而这一章, 我们把求解矩阵逆的问题和初等变换联系在了一起</p>
<p>在后续介绍LU分解时会再次用到这个方法.</p>
<br>

<br>

<h2 id="为什么矩阵的逆这么重要"><a href="#为什么矩阵的逆这么重要" class="headerlink" title="为什么矩阵的逆这么重要"></a>为什么矩阵的逆这么重要</h2><h3 id="计算功能"><a href="#计算功能" class="headerlink" title="计算功能"></a>计算功能</h3><p>首先对于矩阵的逆来说, 它有一个非常重要的计算功能</p>
<p>线性系统本身是一个应用非常广泛的<strong>描述世界, 描述问题的方式</strong>, 我们可以把很多问题都抽象为: Ax &#x3D; b 这样的一个式子, 而如果A可逆</p>
<p><img src="/Blog/Blog/intro/why_inv_matrix_important.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>然而求解矩阵的逆和求解一个线性系统的时间复杂度是差不多的, 如果细究甚至可能<strong>求解矩阵的逆</strong>的操作会稍微耗时一些</p>
<p>但是如果在多次求解线性系统, 在A不变, b会变的情况下, 只要求解一次矩阵的逆, 就可以用A的逆乘以b得到结果, 大大加快了计算速度</p>
<br>

<h3 id="矩阵的逆和很多重要的命题连接在了一起"><a href="#矩阵的逆和很多重要的命题连接在了一起" class="headerlink" title="矩阵的逆和很多重要的命题连接在了一起"></a>矩阵的逆和很多重要的命题连接在了一起</h3><ol>
<li>方阵A(只有方阵才有逆), 如果矩阵A可逆, 即A是非奇异矩阵</li>
<li>对于一个线性系统, Ax &#x3D; 0 (齐次线性方程组) 只有唯一解, 即x &#x3D; 0, 因为rref(A) &#x3D; I, 所以这个线性方程组只有唯一解, 对于齐次线性方程组, 它的唯一解就是0</li>
<li>rref(A) &#x3D; I, A的行最简形式等于单位矩阵</li>
<li>A可以表示为一系列初等矩阵的乘积</li>
</ol>
<p>这4个命题是等价的, 随便抽出一个就可以推导出其他三个结论</p>
<p>若要证明这4个命题等价, 我们要</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gcode">通过 <span class="hljs-comment">(1)</span> 推导 <span class="hljs-comment">(2)</span><br>通过 <span class="hljs-comment">(2)</span> 推导 <span class="hljs-comment">(3)</span><br>通过 <span class="hljs-comment">(3)</span> 推导 <span class="hljs-comment">(4)</span><br>通过 <span class="hljs-comment">(4)</span> 推导 <span class="hljs-comment">(1)</span><br></code></pre></td></tr></table></figure>

<p><img src="/Blog/Blog/intro/why_inv_matrix_important_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<h4 id="通过-1-推导-2"><a href="#通过-1-推导-2" class="headerlink" title="通过 (1) 推导 (2)"></a>通过 (1) 推导 (2)</h4><p>矩阵A可逆 &#x3D;&#x3D;&gt; 线性系统Ax&#x3D;0只有唯一解</p>
<p><img src="/Blog/Blog/intro/why_inv_matrix_important_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h4 id="通过-2-推导-3"><a href="#通过-2-推导-3" class="headerlink" title="通过 (2) 推导 (3)"></a>通过 (2) 推导 (3)</h4><p>线性系统Ax&#x3D;0只有一个解, x&#x3D;0 &#x3D;&#x3D;&gt; rref(A) &#x3D; I</p>
<p>假设A为n*n的矩阵</p>
<p>Ax &#x3D; 0有唯一解, 则有n个未知数, 且rref(A)有n个非零行</p>
<p>根据行最简形式定义: rref(A) &#x3D; I</p>
<br>

<h4 id="通过-3-推导-4"><a href="#通过-3-推导-4" class="headerlink" title="通过 (3) 推导 (4)"></a>通过 (3) 推导 (4)</h4><p>rref(A) &#x3D; I &#x3D;&#x3D;&gt; A可以表示成一系列初等矩阵的乘积</p>
<p>之前说过, 把A化为行最简形式的过程相当于寻找到一些列初等矩阵对A进行左乘, 而现在已知行最简形式等于I</p>
<p><img src="/Blog/Blog/intro/why_inv_matrix_important_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>初等矩阵的逆矩阵还是初等矩阵</p>
<br>

<h4 id="通过-4-推导-1"><a href="#通过-4-推导-1" class="headerlink" title="通过 (4) 推导 (1)"></a>通过 (4) 推导 (1)</h4><p>A可以表示成一系列初等矩阵的乘积 &#x3D;&#x3D;&gt; A可逆</p>
<p><img src="/Blog/Blog/intro/why_inv_matrix_important_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>同样我们还可以证明Ax &#x3D; b有唯一解</p>
<p><img src="/Blog/Blog/intro/why_inv_matrix_important_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>更进一步, 当我们说这几个命题是等价的时, 也就意味着这五个命题的反命题也是等价的</p>
<p><img src="/Blog/Blog/intro/why_inv_matrix_important_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>例如: </p>
<p><img src="/Blog/Blog/intro/why_inv_matrix_important_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因为</p>
<p><img src="/Blog/Blog/intro/why_inv_matrix_important_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因为右边不可能有0, 所以如果左边出现零行一定矛盾</p>
<br>

<br>

<h2 id="矩阵的LU分解"><a href="#矩阵的LU分解" class="headerlink" title="矩阵的LU分解"></a>矩阵的LU分解</h2><h3 id="什么是矩阵的分解"><a href="#什么是矩阵的分解" class="headerlink" title="什么是矩阵的分解"></a>什么是矩阵的分解</h3><p>数的分解: 对于任意一个整数, 我们可以把它分解成若干个素数乘积的形式</p>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs tap">质因数分解<br>66 =<span class="hljs-number"> 2 </span>*<span class="hljs-number"> 3 </span>* 11<br></code></pre></td></tr></table></figure>

<p>拓展到矩阵: 一个矩阵也可以分解成几个矩阵乘积的形式</p>
<br>

<p>我们将学习几种不同的矩阵分解的方式, <strong>矩阵分解有不同的目的</strong></p>
<p>矩阵的LU分解, 是以<strong>提高计算效率</strong>为目的</p>
<p>LU分解不算线性代数原理部分的内容</p>
<p>学习LU分解并不能提高对线性代数的理解, 它只是为了高效计算而进行的一种数值分析的方式而已, 一些教材不包含这个话题</p>
<p>LU分解是初等矩阵非常好的应用</p>
<br>

<h3 id="什么是矩阵的LU分解"><a href="#什么是矩阵的LU分解" class="headerlink" title="什么是矩阵的LU分解"></a>什么是矩阵的LU分解</h3><p>将矩阵A分解为 <strong>A&#x3D;LU</strong> 的形式, L, U分别为两个矩阵</p>
<ul>
<li>L: 代表Lower Triangle Matrix(下三角矩阵)</li>
<li>U: 代表Upper Triangle Matrix(上三角矩阵)</li>
</ul>
<p>以方阵为例, 什么是下三角矩阵和上三角矩阵</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>下三角矩阵: 对角线上面的所有元素都为0</p>
<p>上三角矩阵: 对角线下面的所有元素都为0</p>
<p>更为准确地将, 对于我们要实现的算法, L的部分是这个样子</p>
<p><img src="/Blog/Blog/intro/LU_matrix_unin_L.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>我们称这样的下三角矩阵为<strong>单位下三角矩阵</strong></p>
<p>LU分解我们通常把一个矩阵分解为<strong>单位下三角矩阵乘以上三角矩阵(不保证是单位)</strong></p>
<br>

<p>回忆高斯消元的过程</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>高斯消元法的过程, 就是通过初等变换, <strong>把一个矩阵变成上三角矩阵</strong></p>
<p>初等变换和初等矩阵是等价的, 因此我们可以写成这个样子</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>如果要把左边的式子化回成A (把一系列初等矩阵消去)</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因此, 等式可以化为</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而我们希望化作 <strong>A &#x3D; LU</strong> 的形式</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>如果<strong>一切顺利的话</strong>(有条件的, 不是所有矩阵都可以进行LU分解), 这些初等矩阵的逆乘积会组成一个下三角矩阵</p>
<p>为什么这些初等矩阵的逆的乘积恰好组成一个下三角矩阵?</p>
<p>举个例子:</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>第二行减去4倍的第一行, 对应的初等矩阵的<strong>逆</strong>就是加上四倍的第一行</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>接下来让第三行减去三倍的第一行</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>逆过来就是加上三倍的第一行:</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>之后让第三行减去三倍的第二行, 得到这样的矩阵</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_10.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>现在初等矩阵的逆的乘积就是</p>
<p><img src="/Blog/Blog/intro/LU_matrix_L_U_11.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<blockquote>
<p>为什么这里的第三行不是(15, 3, 1) 而是(3, 3, 1)</p>
<p>即 需要先逆第三步，再逆第二步，再逆第一步。 </p>
<p>那是因为我们计算逆矩阵的乘积是反过来的,  真正反向计算的时候，所操作的那一行和上面一行做运算时，上面一行只有对应位置是1，不会影响其他的元素 </p>
<p> 但是，这个运算法则，在我们拓展LU分解的时候，就不管用了。课程后续会介绍矩阵的PLU分解，你就会看到，需要变动L的时候：） </p>
</blockquote>
<br>

<p><img src="/Blog/Blog/intro/LU_matrix_L_U_12.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>高斯消元的过程就是把主对角线下面的所有元素变为0, 因此所做的操作是下面的某一行减去上面某一行的某倍, 而把这样的初等变换给逆过来, 相应的就是下面的某一行加上同样倍数的上面某一行. 这样的逆过程对应的逆矩阵就是在单位矩阵的基础上在单位矩阵下面的位置填上相应的倍数的元素</p>
<p>注意, 这个过程中, 主对角线的元素是不变的, 因为<strong>主元的位置并不归一</strong>, 所以我们得到的下三角矩阵是<strong>单位下三角矩阵</strong></p>
<br>

<p>我们之所以顺利地完成这个过程, 是因为对A进行高斯消元的过程中, 只涉及某一行减去多少倍的另外一行, 而不需要交换两行的位置</p>
<p>矩阵可以进行LU分解的条件: 对A进行高斯消元的过程, <strong>不需要交换两行的位置</strong></p>
<h3 id="为什么进行LU分解"><a href="#为什么进行LU分解" class="headerlink" title="为什么进行LU分解"></a>为什么进行LU分解</h3><p>在解Ax&#x3D;b的过程中(求解线性系统), </p>
<p>LU分解大概时间复杂度: O(0.5n^3)</p>
<p>此时线性系统可以化为: LUx &#x3D; b</p>
<p>设 Ux &#x3D; y</p>
<p>Ly &#x3D; b</p>
<p>已知L和b, 就可以求出y, 大概需要O(n^2)</p>
<p>Ux &#x3D; y</p>
<p>U和y是已知的, 就可以求出x, 大概需要O(n^2) </p>
<p>因此在解Ax&#x3D;b的过程中, LU分解时间复杂度大概为: O(0.5n^3) + 2 * O(n^2)</p>
<br>

<p>对比求解矩阵的逆: O(2*n^3) + O(n^2)</p>
<p><img src="/Blog/Blog/intro/step_find_inv_mat_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>先把左侧矩阵下面所有元素化为0, 再把上面所有元素化为0, 这是O(2*n^3)的操作</p>
<p>x &#x3D; A的逆 * b, 这个操作大概要 O(n^2)</p>
<br>

<br>

<h2 id="非方阵的LU分解-矩阵的LDU分解和PLU分解"><a href="#非方阵的LU分解-矩阵的LDU分解和PLU分解" class="headerlink" title="非方阵的LU分解, 矩阵的LDU分解和PLU分解"></a>非方阵的LU分解, 矩阵的LDU分解和PLU分解</h2><p>LU分解也可以作用于非方阵</p>
<p><img src="/Blog/Blog/intro/LU_not_matrix.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>此时L依然是一个方阵, 而U则是和A同形状的矩阵</p>
<p>而它的分解过程是完全一样的, 即对长方阵进行高斯消元法, 同时记录下三角矩阵而已</p>
<br>

<p>如果A是高比宽大的矩阵, 则稍微不一样一些</p>
<p><img src="/Blog/Blog/intro/LU_not_matrix_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>此时L是和A形的矩阵, 而U则是方阵</p>
<p>这里如果把U化为单位上三角矩阵更容易一些, 因为它是从单位矩阵进行变化得来的</p>
<br>

<h3 id="LDU分解"><a href="#LDU分解" class="headerlink" title="LDU分解"></a>LDU分解</h3><p>而如果我们想把U化为单位上三角矩阵, 则可以把U再进行一次分解, 例如:</p>
<p><img src="/Blog/Blog/intro/LU_not_matrix_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>分解出对角矩阵D, D只有对角线上是有值的其余都为零</p>
<p><img src="/Blog/Blog/intro/LU_not_matrix_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这样U的对角线上所有的元素都变为了1</p>
<p>此时A &#x3D; LDU</p>
<br>

<h3 id="PLU分解"><a href="#PLU分解" class="headerlink" title="PLU分解"></a>PLU分解</h3><p>之前也说过, 进行LU分解的前提是: 高斯消元的过程中, 没有行交换操作</p>
<p>因为如果有行交换操作, 下三角矩阵也要进行行交换操作</p>
<p>和LDU类似, 我们可以新分解一个矩阵, 让这个矩阵专门进行行交换操作, 而不去动矩阵L, 让它保持单位下三角矩阵</p>
<p><img src="/Blog/Blog/intro/LU_not_matrix_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>此时L依然是单位下三角矩阵, U是上三角矩阵, 但多了一个P, P是<strong>置换矩阵</strong>, 它所处理的事情, 就是行交换这一件事情</p>
<p>此时A &#x3D; PLU</p>
<p>LU分解要求太苛刻, 而PLU分解的要求宽松许多, 它允许行交换操作, 因此大多数矩阵都可以进行PLU分解, 但并不是所有矩阵都可以进行PLU分解</p>
<br>

<br>

<h2 id="矩阵的PLUP分解和再看矩阵的乘法"><a href="#矩阵的PLUP分解和再看矩阵的乘法" class="headerlink" title="矩阵的PLUP分解和再看矩阵的乘法"></a>矩阵的PLUP分解和再看矩阵的乘法</h2><p>例如这个矩阵, 第二列没有首元, 因此PLU算法也失效了</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>此时如果要继续进行高斯消元, 需要<strong>交换矩阵的两列(不属于矩阵的初等变换的一种, 所以不能使用初等矩阵表示)</strong></p>
<p>初等变换只能交换矩阵的两行</p>
<p><strong>左乘</strong>一个变换矩阵, 才能达到交换两行的目的</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>如果要交换矩阵的两列, 需要<strong>右乘</strong>以置换矩阵</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>把单位矩阵第二列和第三列交换了位置</p>
<p>因此可以把矩阵A表示为 A&#x3D;PLUP’</p>
<p>LU不变, P处理行交换操作, P’处理列交换操作, 这样这个分解就能适用于更多的矩阵了</p>
<blockquote>
<p>绝大多数课本并不对其进行讲解, 它本身的工程实用价值也并没有那么高</p>
</blockquote>
<br>

<p>但本小结的重点不是讲述如何交换矩阵的两列, 重点是:<strong>怎么理解这件事, 为什么交换行要左乘, 交换列要右乘</strong></p>
<br>

<h3 id="列交换"><a href="#列交换" class="headerlink" title="列交换"></a>列交换</h3><p><img src="/Blog/Blog/intro/PLUP_matrix_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>为什么右乘一个这样的置换矩阵可以有交换两列的效果</p>
<p>之前讲矩阵的乘法时, 讲过看待矩阵的乘法, 可以把后一个矩阵看作一列一列的</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这样我们可以把矩阵的乘法看作是矩阵乘以一个列向量, <strong>得到的列向量就是结果矩阵的一列</strong></p>
<p>宏观地来看:</p>
<p>结果矩阵中的每一列和顺序和红色矩阵没有关系, 蓝色列向量的顺序决定了结果矩阵列的顺序</p>
<br>

<p>微观地来看:</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而蓝色的列向量只有一个1, 其余全是0</p>
<p>这就意味着在红色的每一行中, 只取出这个位置所对应的元素, 其他的元素都为0, 如果蓝色向量第一个元素为1, 就意味着红色向量在每一行中只取出第一个元素, 结果就是第一列, 因此这个过程可以看作</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>当右乘置换矩阵第一列时, 这一列第一个元素为1, 就相当于在前面的矩阵中取出了第一列</p>
<p>当右乘置换矩阵第二列时, 这一列第三个元素为1, 就相当于在前面的矩阵中取出了第三列, 因此变成了结果矩阵的第二列</p>
<br>

<h3 id="行交换"><a href="#行交换" class="headerlink" title="行交换"></a>行交换</h3><p><img src="/Blog/Blog/intro/PLUP_matrix_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>为什么左乘变换矩阵能交换两行呢? 其实原理是一样的</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>宏观的来看, 结果矩阵每一行的顺序只和红色矩阵的每一行有关系, 因此交换红色矩阵的两行相应的结果矩阵的两行也会交换</p>
<br>

<p>微观的来看:</p>
<p>置换矩阵每一行也只有一个1, 一行乘以一个矩阵</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>红色向量只有一个位置为1, 就相当于取出蓝色矩阵的相应的一行</p>
<br>

<h3 id="重新看待矩阵乘法"><a href="#重新看待矩阵乘法" class="headerlink" title="重新看待矩阵乘法"></a>重新看待矩阵乘法</h3><p><img src="/Blog/Blog/intro/PLUP_matrix_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而其实这两个视角都是把前一个矩阵看作时一行一行的, 后一个矩阵看作是一列一列的</p>
<p>然而还有一种视角, 可以把前一个矩阵看作是一列一列的, 后一个矩阵看作时一行一行的</p>
<br>

<p>之前在将解矩阵和向量之间的乘法时介绍过, 矩阵和向量的乘法可以用列视角看待</p>
<p><img src="/Blog/Blog/intro/matrix_product_with_vector_c.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/understand_matrix_product_vector_col.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而在这个视角下</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>前面矩阵乘以一个列向量, 这个列向量中只有一个1, 相当于取出那个1对应位置的列向量</p>
<p>当左边矩阵乘以右边矩阵的第一列, 由于第一列只有第一个元素为1, 就相当于取出左边矩阵的第一列方在结果矩阵的第一列</p>
<p>当左边矩阵乘以右边矩阵的第二列, 由于第一列只有第三个元素为1, 就相当于取出左边矩阵的第三列方在结果矩阵的第二列</p>
<p>… …</p>
<br>

<p>推而广之, 将前一个矩阵化为一列一列地去乘以一个矩阵, 会发生什么</p>
<p>回忆以行视角看待矩阵的乘法</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_10.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>当第i行和第j列相乘, 就是结果矩阵中第i行第j列的那个<strong>元素</strong>, 注意这个元素不需要再进行任何运算, 可以直接放到结果矩阵中对应的位置</p>
<p>由于看起来不太方便, 我们把<strong>结果矩阵</strong>简写为一个式子</p>
<p>把ri的元素当作a, cj的元素当作b</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_10_res.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>如果我们把前一个矩阵想成是一列一列的, 而后一个矩阵想成是一行一行的</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_11.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>注意角标, 前一个矩阵有k列, 后一个矩阵有k行, 因为若想让矩阵乘法能够执行, 前一个矩阵的列数必须等于后一个矩阵的行数</p>
<p>然而, 无论我们用什么视角来看, 运算结果是不会变的</p>
<p>此时我们也可以把ai1b1j看作是, 把前面矩阵中第一列拿出来, 把后面矩阵中第一行拿出来, 一个列向量乘以一个行向量, 或者可以说一个m * 1的二维矩阵, 乘以一个1 * n的二维矩阵得到的结果 m * n 的矩阵中第 i 行第 j 列的元素</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_12.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而我们一共可以进行k次乘法, 结果矩阵就是这k次的结果矩阵之和</p>
<p><img src="/Blog/Blog/intro/PLUP_matrix_13.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><img src="/Blog/Blog/intro/PLUP_matrix_14.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h1 id="线性相关-线性无关和生成空间"><a href="#线性相关-线性无关和生成空间" class="headerlink" title="线性相关, 线性无关和生成空间"></a>线性相关, 线性无关和生成空间</h1><h2 id="线性组合"><a href="#线性组合" class="headerlink" title="线性组合"></a>线性组合</h2><p>回忆向量的两个最基本的运算: 向量加法 和 标量(数量)乘法</p>
<p><img src="/Blog/Blog/intro/mem_basic_operator_vector.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>为什么说它们是向量的两个最基本的运算?</p>
<p>因为这两个运算构建了线性代数中最重要的一个概念: <strong>线性组合</strong></p>
<br>

<h3 id="什么是线性组合"><a href="#什么是线性组合" class="headerlink" title="什么是线性组合"></a>什么是线性组合</h3><p><img src="/Blog/Blog/intro/linear.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>其实我们已经多次见过线性组合了</p>
<p><img src="/Blog/Blog/intro/linear_combin.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>对于任意一个向量, 我们可以将其看作是它所在维度的标准单位向量的一个<strong>线性组合</strong></p>
<br>

<p>还有当我们用列视角看待矩阵的乘法时</p>
<p><img src="/Blog/Blog/intro/linear_combin_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这个形式本身就是我们说的线性组合</p>
<p>矩阵和向量的乘法, 可以看作是矩阵的列向量的一个<strong>线性组合</strong></p>
<br>

<p>而其实上面二者可以连接起来</p>
<p>当我们把矩阵看作是空间</p>
<p><img src="/Blog/Blog/intro/linear_combin_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>它的x轴和y轴分别是(4, 1), (2, 3), 在这个空间中(2, 2)对应的点在标准坐标系视角下对应的点</p>
<p>而把这个乘法看作是:</p>
<p><img src="/Blog/Blog/intro/linear_combin_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而这个视角和我们看待坐标系的视角是一致的, 因为单位向量代表的就是所在空间的坐标轴</p>
<p>在(4, 1)这个轴上对应的值是2, 因此是(4, 1) * 2, 加上(2, 3) 这个轴乘以2</p>
<p><img src="/Blog/Blog/intro/linear_combin_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>在来一个例子:</p>
<p>无论是高斯消元法还是高斯约旦消元法, 最后的结果矩阵的每一行都是原先矩阵中行向量的线性组合</p>
<p><img src="/Blog/Blog/intro/linear_combin_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="线性相关和线性无关"><a href="#线性相关和线性无关" class="headerlink" title="线性相关和线性无关"></a>线性相关和线性无关</h2><p>线性相关和线性无关这两个概念是建立在线性组合的基础之上的</p>
<p><img src="/Blog/Blog/intro/linear_combin_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>在先前的例子中, 我们使用的是<strong>齐次线性方程组</strong></p>
<p>因此我们不对<strong>增广矩阵</strong>进行消元, 而是直接对<strong>系数矩阵</strong>进行消元也是可以的, 因为最后一列都是0, 无论如何进行初等变换依然为0, 而我们得到的第三行就是这样:</p>
<p><img src="/Blog/Blog/intro/linear_combin_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>即这三个向量的线性组合是零向量</p>
<p><img src="/Blog/Blog/intro/linear_combin_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>即线性组合定义中的k1, k2, k3为</p>
<p>k1 &#x3D; -7&#x2F;2,    k2 &#x3D; -1&#x2F;2,    k3 &#x3D; 1</p>
<p>相当于这三个系数放在三个向量的前面, 让这三个向量的结果变成零向量</p>
<p>另一个解就是 k1 &#x3D; k2 &#x3D; k3 &#x3D; 0, 结果依然为零向量</p>
<br>

<h3 id="线性相关的定义"><a href="#线性相关的定义" class="headerlink" title="线性相关的定义"></a>线性相关的定义</h3><p>由此我们可以引出线性相关的定义</p>
<p><img src="/Blog/Blog/intro/linear_combin_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>此时, 就可以把r1, r2移到等式右边</p>
<p><img src="/Blog/Blog/intro/linear_combin_10.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这就是线性相关的意思</p>
<p>由此也可以得出一个和线性相关等价的命题</p>
<p><img src="/Blog/Blog/intro/linear_combin_11.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>注意箭头对方向, 也就是说反过来也是可以的</p>
<br>

<h4 id="证明-x3D-gt"><a href="#证明-x3D-gt" class="headerlink" title="证明: &#x3D;&gt;"></a>证明: &#x3D;&gt;</h4><p><img src="/Blog/Blog/intro/linear_combin_12.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>如果所有向量线性相关, 并不代表<strong>所有向量</strong>可以写成其他向量的线性组合,</p>
<p>这个证明中最关键的一步是至少存在一个ki不为0</p>
<p>但如果某个ki为0, 它所对应的向量就不能写成其他向量的线性组合</p>
<br>

<h4 id="证明-lt-x3D"><a href="#证明-lt-x3D" class="headerlink" title="证明: &lt;&#x3D;"></a>证明: &lt;&#x3D;</h4><p><img src="/Blog/Blog/intro/linear_combin_13.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>ki一定不为0, 所以是线性相关的</p>
<br>

<p>理解这个命题可以帮助理解到底什么是线性相关</p>
<p>线性相关说白了就是说这些向量之间并不是独立的, 因为至少有一个向量可以用剩下的向量来线性表示出来</p>
<p>那么是否有一组向量, 任意一个向量都不能用其他的向量来表示出来吗, 换句话说, 如果想让这些若干个向量的线性组合最终等于0的话, 只有可能k全为0. 实际上这正是<strong>线性无关</strong>的定义</p>
<br>

<h3 id="线性无关"><a href="#线性无关" class="headerlink" title="线性无关"></a>线性无关</h3><p><img src="/Blog/Blog/intro/linear_combin_15.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>如果线性无关的话, 任何一个向量都不可以表示成其他向量的线性组合</p>
<p>当一组向量线性无关, 这就说明这组向量中, 任意一个向量都是非常重要的, 它不能被取代</p>
<br>

<p>例如:</p>
<p><img src="/Blog/Blog/intro/linear_combin_14.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这里x, y, z只能为0, 所以e1, e2, e3这三个向量是线性无关的</p>
<br>

<h4 id="证明-标准单位向量e1…en-线性无关"><a href="#证明-标准单位向量e1…en-线性无关" class="headerlink" title="证明: 标准单位向量e1…en 线性无关"></a>证明: 标准单位向量e1…en 线性无关</h4><p><img src="/Blog/Blog/intro/linear_combin_16.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这样等式右边的线性组合是可以计算出来的</p>
<p><img src="/Blog/Blog/intro/linear_combin_17.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>然而ei的第i个位置是1, 而等式右边的第i个位置是0, 所以等式是不可能成立的, 矛盾, 假设不成立</p>
<br>

<br>

<h2 id="矩阵的逆和线性相关-线性无关"><a href="#矩阵的逆和线性相关-线性无关" class="headerlink" title="矩阵的逆和线性相关, 线性无关"></a>矩阵的逆和线性相关, 线性无关</h2><h3 id="线性相关的重要性质"><a href="#线性相关的重要性质" class="headerlink" title="线性相关的重要性质"></a>线性相关的重要性质</h3><p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>例如: 4个三维向量一定线性相关</p>
<br>

<h3 id="从一个例子出发"><a href="#从一个例子出发" class="headerlink" title="从一个例子出发"></a>从一个例子出发</h3><p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>即:</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因此就变成看k1和k2是否只有唯一的零解, 如果有零解以外的解就说明这两个向量线性相关, 反之线性无关</p>
<p>因此我们可以把它们组成这样的一个线性系统, 就是从列的视角看矩阵乘法</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这样我们就把这个问题化成了线性系统的问题, 更为准确地说是齐次线性方程组的问题</p>
<p>对于这个问题我们之前花费很大篇幅探讨, 就是把这个矩阵化为行最简形式, 看它非零行的个数和未知数个数之间的关系</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>只有一个非零行, 但有两个未知数(两列), 即存在<strong>自由列</strong>, 则不止有一个解(不止有零解), 其他的解k1, k2肯定不全为0, 因此u和v线性相关</p>
<br>

<h3 id="更一般的如果有m个n维向量"><a href="#更一般的如果有m个n维向量" class="headerlink" title="更一般的如果有m个n维向量"></a>更一般的如果有m个n维向量</h3><p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因为 m &gt; n, 列数大于行数, 所以化为当系数矩阵化为最简形式, 肯定非零行小于列数</p>
<p>因此肯定有无数解, 而不仅仅有唯一解</p>
<br>

<h3 id="什么时候线性无关"><a href="#什么时候线性无关" class="headerlink" title="什么时候线性无关"></a>什么时候线性无关</h3><p>当化作行最简形式时, 非零行的个数等于列数</p>
<p>而回忆之前证明的多个等价的条件</p>
<p><img src="/Blog/Blog/intro/why_inv_matrix_important_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><strong>线性系统Ax&#x3D;0只有唯一解, x&#x3D;0</strong>, 而这个命题和其他命题都是等价的</p>
<p>换句话说, </p>
<ul>
<li>如果矩阵A可逆, 这m个向量就是线性无关的</li>
<li>如果行最简形式rref(A)是单位矩阵, 这m个向量就是线性无关的</li>
<li>A可以表示成一系列初等矩阵的乘积, 这m个向量就是线性无关的</li>
</ul>
<p>此时我们就把线性无关和之间诸多等价的命题联系在了一起</p>
<p>而矩阵可逆是其中最简单, 也最重要的一个性质, 因此许多课本中直接说:</p>
<p>用这m个向量当作矩阵的列向量组成矩阵A, 当矩阵A可逆时, 这m个向量就线性无关, 而可逆性是建立在方阵的基础上(只有方阵可逆), 所以这里隐含了m&#x3D;n</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>因此对于方阵A的等价命题的列表又可以增加一条</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而且这些命题的否命题也是等价的</p>
<br>

<br>

<h2 id="直观地理解线性相关和线性无关"><a href="#直观地理解线性相关和线性无关" class="headerlink" title="直观地理解线性相关和线性无关"></a>直观地理解线性相关和线性无关</h2><p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>若想更加深刻地理解这个性质, 一个非常关键的诀窍就是更加直观更加形象的理解什么是<strong>线性相关</strong></p>
<p>定义:</p>
<p><img src="/Blog/Blog/intro/linear_combin_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>更直观的表达</p>
<p><img src="/Blog/Blog/intro/linear_combin_11.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这也是线性相关, “相关”这两个字的意思</p>
<br>

<p>从另外一个角度, 从这些向量所<strong>表达的信息</strong>的角度来看</p>
<p>线性相关就意味着这组向量中信息是<strong>冗余</strong>的: <strong>至少有一个向量可以写作是其他向量的线性组合</strong>, 就说明这个向量并没有表达新的信息</p>
<p>反之线性无关意味着信息的<strong>完全不冗余</strong>, 每一个向量都是独立的, 一个向量是不能表达成其他向量的线性组合的形式的</p>
<br>

<h3 id="通过坐标系理解线性相关"><a href="#通过坐标系理解线性相关" class="headerlink" title="通过坐标系理解线性相关"></a>通过坐标系理解线性相关</h3><p>为什么在二维空间中, 如果有了第三个向量, 这三个向量就一定是线性相关</p>
<p>假设最开始, 二维平面中有这样两个向量</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>之后再在二维平面中随便取一个向量</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>根据之前的性质, 这三个向量一定是线性相关的</p>
<br>

<p>怎么理解这件事呢?</p>
<p>就是说不管w怎么取, 它都一定能表示成u和v这两个向量的线性组合</p>
<p>或者我们可以把u和v所在的直线画出来</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_10.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因此对于向量w, 从它末端的点出发, 一定可以做出和这两条线相平行的线</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_11.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因此就一定会和两条直线产生交点, 交点也可以看作时向量</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_12.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这两个<strong>蓝色的向量</strong>就是u和v这两个向量进行<strong>数量乘</strong>的结果, 因为他们和u v是在同方向的</p>
<p>而 w 是这两个蓝色向量相加的结果, 因为它是以蓝色向量为边的平行四边形的对角线</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_13.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>换句话说, w可以表示成 k1 * u+k2 * v</p>
<br>

<p>如果w不在uv的夹角中也一样</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_14.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>不过此时对于 w &#x3D; k1 * u+k2 * v, k2由于是在v的反方向, 所以是负值</p>
<p>同理, k1, k2 都为负数时:</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_15.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_10.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而其实我们这样绘制, <strong>就好像u和v这两个向量把我们二维平面分成了4部分</strong>, 非常像在平面直角坐标系中的x轴和y轴把整个二维平面分成了四部分</p>
<p><strong>对于u和v这两个向量好像也把这个二维平面, 以u和v这两个方向的形式分成了四个象限</strong></p>
<blockquote>
<p> 这个视角是非常正确的, 我们很快就会从这个视角出发, 引入空间的基这个概念</p>
</blockquote>
<br>

<p>这里取的u和v两个向量恰好是不共线的, 如果u和v共线事情就更简单了</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_16.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这意味着u和v两个向量本身就是线性相关的, 此时再加一个向量w, 这三个向量肯定是线性相关的</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_17.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>但此时w不能表示为u, v的线性组合, 但是: </p>
<p>u 可以表示为 u &#x3D; k1 * w + k2 * v , 只要 k1 取 0 就好了, 而u, v共线时, u一定可以等于某一个常数乘以v的</p>
<p>同样v可以表达为表达为w和u的线性组合, 同样k1取0</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_18.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>由此可以引出一个小的推论, 这个推论甚至可以说是废话</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_19.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_20.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因为前n个k不全为0, 所以k1到kn+1不全为0</p>
<br>

<h3 id="如果存在零向量"><a href="#如果存在零向量" class="headerlink" title="如果存在零向量"></a>如果存在零向量</h3><p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_21.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="相反的结论"><a href="#相反的结论" class="headerlink" title="相反的结论"></a>相反的结论</h3><p>在二维平面中, 两个向量不共线, 则这两个向量线性无关</p>
<p>在三维空间中, 三个向量不共面, 则这三个向量线性无关</p>
<p>核心主要还是理解一下</p>
<p><img src="/Blog/Blog/intro/linear_combin_111.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="生成空间"><a href="#生成空间" class="headerlink" title="生成空间"></a>生成空间</h2><p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_13.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>上一小节说过, 在一个二维空间中(平面), 随便选取两个向量(u和v), 只要这两个向量不共线, 那么任意一个第三个向量(w), 就都可以被u和v这两个向量表示出来.</p>
<p>换句话说, <strong>在这二维空间中的任何向量, 都可以表示为u和v的线性组合</strong></p>
<p>我们可以说:  <strong>u和v生成了整个二维空间</strong></p>
<br>

<p>推而广之, 在n维空间中, 我们也可以得到类似的定义</p>
<p><img src="/Blog/Blog/intro/generate_space.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_13.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>注意, u, v, w也可以生成整个二维空间, 因为在这个二维空间中任意一个向量也都可以写作这三个向量的</p>
<p>既然u, v已经生成了整个空间, 任意一个向量都能表达为u, v, w的线性组合, 只要w前的系数为0即可</p>
<p>因此即使在u, v, w 中再添加一个向量, 依然能表达整个空间</p>
<br>

<p>很自然地, 我们关心一个问题: <strong>最少需要几个向量生成二维空间?</strong></p>
<ul>
<li><p>首先肯定不是一个, 因为一个向量只能生成这条直线上的其他向量, 本质就是对向量进行缩放</p>
</li>
<li><p>其次肯定不是三个, 只要两个向量不共线, 其他向量可以表达成这两个向量的线性组合</p>
</li>
</ul>
<p>而其实我们有一个定理来描述这件事: <strong>在二维空间中, 三个向量一定是线性相关的</strong> (n维空间中, n+1个向量一定是线性相关的)</p>
<p>即三个向量中, 肯定有一个向量能表达为其他向量的线性组合, 这个向量就是多余的</p>
<p>答案就是: 至少需要<strong>两个向量</strong>来生成整个二维空间</p>
<p>对这个结论拓展一下就有了: <strong>对于一个n维空间, 至少需要n个向量才能够生成</strong></p>
<br>

<h3 id="证明-生成空间所需的最少向量"><a href="#证明-生成空间所需的最少向量" class="headerlink" title="证明: 生成空间所需的最少向量"></a>证明: 生成空间所需的最少向量</h3><p><img src="/Blog/Blog/intro/generate_space_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>根据我们的假设, 这个非齐次线性方程组应该是有解的</p>
<p><img src="/Blog/Blog/intro/generate_space_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>此时这个矩阵有n行m列, 根据我们假设 m &lt; n, 即行数大于列数</p>
<p>所以把这个矩阵化为<strong>行最简形式</strong>一定有零行</p>
<p>像这样:</p>
<p><img src="/Blog/Blog/intro/generate_space_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>然而我们不能保证un是非零的, 因为我们假设u是n维空间中<strong>任意一个向量</strong>, 因此这个线性系统无解, 矛盾</p>
<p><strong>因此, 对于一个n维空间, 至少需要n个向量才能够生成</strong></p>
<br>

<p>这里我们说<strong>至少</strong>需要三个向量, 但反过来说, n个向量<strong>一定可以</strong>生成n维空间?</p>
<p>并不一定, 例如二维空间中, 两个向量共线</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation_16.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>那么n个向量何时可以生成整个空间?</p>
<p>即当这些向量组成的系数矩阵化为行最简形式对应的是这样的单位矩阵时</p>
<p><img src="/Blog/Blog/intro/generate_space_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因为对于右侧的u都有可能是非零的</p>
<br>

<p>回忆一下之前等价的命题</p>
<p>Ax &#x3D; b有唯一解</p>
<p><img src="/Blog/Blog/intro/generate_space_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>即我们可以把: <strong>方阵A的列向量可以生成n维空间</strong></p>
<p>这个命题放入等价列表中</p>
<p><img src="/Blog/Blog/intro/generate_space_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>此时就把生成空间这个概念和其他概念都联系起来了</p>
<br>

<p>n个向量什么时候可以生成整个n维空间?</p>
<p>将n个向量作为列向量排成方阵, 只要这个方阵排成系数矩阵</p>
<p>只要这个<strong>矩阵有唯一解</strong>, 这些列向量就可以生成n维空间</p>
<p>且由于上述命题都是等价的, 只要满足其中一个条件即可</p>
<br>

<h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><p>我们说一组向量可以生成整个空间就是指这个空间中的任意一个向量都可以表示为这组向量的<strong>线性组合</strong></p>
<p>对于一个n维空间, 最少需要n个向量生成整个空间</p>
<p>n个向量不一定能生成整个n维空间, 它必须满足一定条件</p>
<br>

<br>

<h2 id="空间的基"><a href="#空间的基" class="headerlink" title="空间的基"></a>空间的基</h2><p>若m个向量生成n维空间, <strong>则m最小为n</strong></p>
<p>之前提过一个这样一个命题</p>
<p><img src="/Blog/Blog/intro/inverse_matrix_linear_relation.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>反之, 若m个n维向量线性无关, <strong>m最大为n</strong></p>
<br>

<p>若一组向量既可以生成整个n维空间, 又线性无关, m一定等于n, 即这组向量一定有n个, 则称这组向量为这个n维空间的一组<strong>基</strong></p>
<p>可以理解为这组n维向量是整个空间的基础</p>
<ul>
<li><p>首先这组n维向量可以生成整个空间</p>
</li>
<li><p>其次这组向量彼此线性无关, 没有任何一个向量可以表示为其他向量的线性组合(每一个向量都包含它独有的信息, 缺一不可)</p>
</li>
</ul>
<br>

<h3 id="空间的基的定义"><a href="#空间的基的定义" class="headerlink" title="空间的基的定义"></a>空间的基的定义</h3><p><img src="/Blog/Blog/intro/space_basics.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><strong>一个空间有无数组基</strong>, 就像我们之前说的, 二维空间中随便取两个向量, 只要它们不共线, 它们就是空间的一组基</p>
<p><img src="/Blog/Blog/intro/space_basics_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>我们最常用的二维空间中的一组基是</p>
<p>而且我们还对它们进行标准化处理 (让他们的模等于1)</p>
<p><img src="/Blog/Blog/intro/space_basics_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>即 e1, e2 两个标准单位向量</p>
<br>

<h3 id="空间的基的性质"><a href="#空间的基的性质" class="headerlink" title="空间的基的性质"></a>空间的基的性质</h3><p><img src="/Blog/Blog/intro/space_basics_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>不用说, 它们肯定具有同样的定义(空间的基的定义)</p>
<p>此外它们的共性: 在二维空间, 任意一个向量(或者是点) 都可以表示成e1, e2的线性组合</p>
<p><img src="/Blog/Blog/intro/space_basics_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>同样, 根据之前所说, 在二维空间, 任何一个向量(或者点) 都可以表示成u和v的线性组合</p>
<br>

<p>e1, e2就是初等数学中的坐标系, u和v也是一个坐标系</p>
<p>这二者都是二维空间的坐标系, 只不过这两个坐标系不一样</p>
<p>虽然对于同一个点, 我们既能通过e1, e2坐标系观测到; 又能在 u, v坐标系观测到, 但更换坐标系之后, 对于同一个点, 它的表示方法就不一样了</p>
<p>更为重要的: 当我们选定了这个空间中的一组基后, 对于任意一个点, 它在这组基下的表示方法是<strong>唯一</strong>的 (这个唯一性在线性代数领域非常重要)</p>
<br>

<h3 id="证明一个向量在一组基中的表示方法唯一"><a href="#证明一个向量在一组基中的表示方法唯一" class="headerlink" title="证明一个向量在一组基中的表示方法唯一"></a>证明一个向量在一组基中的表示方法唯一</h3><p>更一般地: 在n维空间中, 如果给定一组基, 那么任何一个向量 (或者是点) 都可以表示成这组基的线性组合. <strong>且表示方法唯一</strong></p>
<br>

<h4 id="证明-标准单位向量满足性质"><a href="#证明-标准单位向量满足性质" class="headerlink" title="证明: 标准单位向量满足性质"></a>证明: 标准单位向量满足性质</h4><p><img src="/Blog/Blog/intro/space_basics_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因此现在问题变成看线性系统是否有解(能否表示), 且只有唯一解(只有一种表示方法)</p>
<p><img src="/Blog/Blog/intro/space_basics_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>显然这个系数矩阵一定有解, 且解唯一, 得证</p>
<br>

<h4 id="证明-任意一组空间的基满足性质"><a href="#证明-任意一组空间的基满足性质" class="headerlink" title="证明: 任意一组空间的基满足性质"></a>证明: 任意一组空间的基满足性质</h4><p><img src="/Blog/Blog/intro/space_basics_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因为这组v是n为空间的基</p>
<p>即这组v可以生成整个空间, 线性无关</p>
<p>根据这组等价命题</p>
<p><img src="/Blog/Blog/intro/generate_space_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>等价于Ax &#x3D; b只有唯一解, 得证</p>
<br>

<h5 id="另一种证明思路"><a href="#另一种证明思路" class="headerlink" title="另一种证明思路"></a>另一种证明思路</h5><p>对于<strong>任意向量空间</strong>V中的一组基S, V中的任何向量<strong>u</strong>只有<strong>唯一</strong>的表示方法</p>
<p><img src="/Blog/Blog/intro/proof_basis_unique.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h3><p><strong>空间的基的概念</strong></p>
<p><img src="/Blog/Blog/intro/space_basics.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><strong>重要的性质</strong></p>
<p>在n维空间中, 如果给定一组基, 那么任何一个向量 (或者是点) 都可以表示成这组基的线性组合. <strong>且表示方法唯一</strong></p>
<p>可以理解为: 给定一组基就是给定一组坐标系</p>
<br>

<p>此时再看这张图</p>
<p><img src="/Blog/Blog/intro/linear_combin_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这张图原本说是表示矩阵的乘法</p>
<p>现在就可以理解成, 在直角坐标系中(12, 8)这个点, 可以变化成在u, v这组向量所组成的<strong>基</strong>中相应的表示为(2, 2)</p>
<p>即: </p>
<p><img src="/Blog/Blog/intro/space_basics_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="空间的基的更多性质"><a href="#空间的基的更多性质" class="headerlink" title="空间的基的更多性质"></a>空间的基的更多性质</h2><p><img src="/Blog/Blog/intro/space_basics.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>其实我们在这个定义中, 不需要声明这一组向量有n个, 只要有一组向量, 它们能生成整个n维空间, 同时它们线性无关的话, 这组向量一定有n个</p>
<p>所以在我们的定义中, “n个向量” 这个限制条件其实是多于的</p>
<br>

<p>既然”n个向量”这个条件可以被下面定义的两个条件 (生成空间, 线性无关) 推导出来, 反过来在这三个条件中, 我们也可以用其他的两个条件推导出第三个条件, 即:</p>
<ul>
<li>n维空间中, 任意n个线性无关的向量, 一定是这个n维空间的基(证明可以生成整个空间)</li>
<li>n维空间中, 如果n个向量可以生成整个空间, 则这n个向量, 是这n维空间的基(证明线性无关)</li>
</ul>
<p>注意: <strong>线性无关</strong>和<strong>生成整个空间</strong>是两个不同的概念</p>
<p><img src="/Blog/Blog/intro/property_space_base.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>通过文字再整理一下</p>
<p><img src="/Blog/Blog/intro/property_space_base_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="空间的基的性质-1"><a href="#空间的基的性质-1" class="headerlink" title="空间的基的性质"></a>空间的基的性质</h3><p><img src="/Blog/Blog/intro/property_space_base_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<h4 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h4><p>假设第i个向量是其他向量的线性组合</p>
<p><img src="/Blog/Blog/intro/property_space_base_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>由于这组向量生成n维空间, 则对于空间中任意向量u, 都可以表示成这p个向量的线性组合</p>
<p><img src="/Blog/Blog/intro/property_space_base_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>肯定有一项是 ci * vi,</p>
<p>所以可以把上面的式子代入下面的式子</p>
<p>此时右侧的式子不再有vi了</p>
<p>u就被表示为这p-1个向量的线性组合</p>
<br>

<p>因此可以得到下面的性质:</p>
<p><img src="/Blog/Blog/intro/property_space_base_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="本章小结"><a href="#本章小结" class="headerlink" title="本章小结"></a>本章小结</h2><p><img src="/Blog/Blog/intro/property_space_base_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这些概念都是和一组向量相关的, 而不是单单考虑某一个向量</p>
<p>对于这组向量, 有多少个向量是我们在这一章中探讨问题最为关注的内容</p>
<br>

<p><img src="/Blog/Blog/intro/property_space_base_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>对于空间中任意一个向量, 都可以表示为空间的基的线性组合.</p>
<p>虽然上面两者都是空间的基, 但用标准单位向量所表示的基, 它有非常独特的地方, 这组基有一个单独的名字: <strong>标准正交基</strong></p>
<br>

<p>为什么如此泛华空间的基的概念?</p>
<p>我们有时候会对空间的其他基感兴趣, 而不仅仅是标准正交基</p>
<p>例如: 高中物理的受力分析, 此时使用这样的坐标系比使用标准正交基更有意义, 虽然这个坐标系是斜的, 但对于我们关注的物体来说其实是正的</p>
<p><img src="/Blog/Blog/intro/property_space_base_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>还有物理学中, 研究飞机受力时, 同常考虑飞机引擎带给飞机的动力和外界阻力(风力)这两个方向</p>
<p><img src="/Blog/Blog/intro/property_space_base_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因此以这两个方向作为基来分析这个飞机的飞行结果</p>
<br>

<br>

<h1 id="向量空间-维度-和四大子空间"><a href="#向量空间-维度-和四大子空间" class="headerlink" title="向量空间, 维度, 和四大子空间"></a>向量空间, 维度, 和四大子空间</h1><br>

<h2 id="空间-向量空间和欧几里得空间"><a href="#空间-向量空间和欧几里得空间" class="headerlink" title="空间, 向量空间和欧几里得空间"></a>空间, 向量空间和欧几里得空间</h2><p>虽然我们经常使用”空间”, 但我们并没有定义, 数学本身非常强调定义</p>
<h3 id="什么是空间"><a href="#什么是空间" class="headerlink" title="什么是空间"></a>什么是空间</h3><p>空间是一个集合, 通常我们称这些空间为<strong>欧几里得空间</strong></p>
<p><strong>欧几里得空间是有序实数元组的集合</strong></p>
<p>例如:</p>
<p><img src="/Blog/Blog/intro/ojilide_space.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>有序, 实数, 元组的集合这种说法有点太绕了</p>
<p>所以我们也说, <strong>欧几里得空间是点集; 是起点为原点的向量集合</strong>(每一个点本身就是一个有序实数元组)</p>
<br>

<h3 id="什么是向量空间"><a href="#什么是向量空间" class="headerlink" title="什么是向量空间"></a>什么是向量空间</h3><p>欧几里得空间不仅仅是一个空间, 它还是一类特殊的空间: <strong>向量空间</strong></p>
<p>空间只是集合而已, 对于杂乱无章的集合, 线性代数不感兴趣</p>
<p>线性代数感兴趣的是具有某些特殊性质的空间 &#x3D;&gt; 向量空间</p>
<br>

<p>什么是向量空间?        即空间中的元素是”<strong>向量</strong>“ (向量的定义是很广泛的, 不仅仅是<strong>起点在原点并且具有方向</strong>, 实际上这个向量的定义是<strong>欧几里得空间中的向量</strong>)</p>
<blockquote>
<p>还存在其他向量空间, 在这些空间中, 向量是其他样子的</p>
</blockquote>
<br>

<p><strong>到底什么是向量? 什么让向量成为向量</strong></p>
<p>对于向量来说, 首先我们必须定义两种运算:</p>
<ol>
<li>加法运算</li>
<li>数量乘法运算</li>
</ol>
<p><img src="/Blog/Blog/intro/def_vector_operation.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>但是如果只是定义两种运算, 其实我们可以胡乱地定义</p>
<p>为什么一定要这样定义?</p>
<p>不能随便定义, 数学家规定, 这<strong>两种运算</strong>必须满足<strong>十条性质</strong></p>
<p><img src="/Blog/Blog/intro/ten_rules_for_vec_space.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h4 id="封闭性"><a href="#封闭性" class="headerlink" title="封闭性"></a>封闭性</h4><p>对于向量空间V</p>
<ul>
<li>如果 u, v 都属于V, 则 u+v 属于V</li>
<li>如果 u 属于V, k是一个实数, 则 ku 属于 V</li>
</ul>
<p>这两个是最为重要的性质, 在数学上, 这两条性质被成为 **封闭 (closure) **</p>
<p>如果某些元素已经在这个空间中, 那么进行相应的运算后, 运算的结果还需要在这个空间中</p>
<p>有一些特殊的空间不一定满足这个性质, 例如: 整数集合</p>
<p>整数集合对于加法是满足封闭性的, 但对于除法不封闭</p>
<p>但在线性代数领域讨论的向量空间, 必须满足封闭性</p>
<br>

<h3 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h3><p>线性代数讨论的主题内容都是基于向量空间的</p>
<p><img src="/Blog/Blog/intro/what_is_vector_space.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>最常用的向量空间是 <strong>欧几里得空间</strong></p>
<p>欧几里得空间是向量空间, 它满足向量空间的性质</p>
<p><img src="/Blog/Blog/intro/what_is_vector_space_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>在介绍向量时, 我们也证明了部分性质</p>
<br>

<br>

<h2 id="广义向量空间"><a href="#广义向量空间" class="headerlink" title="广义向量空间"></a>广义向量空间</h2><p>由于欧几里得空间太常用了, 所以向量这个词近乎就是指<strong>有序实数元组</strong>了, 而向量空间就专属指欧几里得空间了. 因此为了区别, 对于不是欧几里得空间的向量空间有时也被称之为<strong>广义向量空间</strong></p>
<br>

<p>向量空间: 一个集合, 集合中的元素可以定义两种运算: 加法和数量乘法, 使得满足十条性质.</p>
<br>

<h3 id="例一"><a href="#例一" class="headerlink" title="例一"></a>例一</h3><p>例如, 我们定义:</p>
<p>所有2 * 2的方阵, 构成一个向量空间.</p>
<p>加法: 矩阵加法; 数量乘法: 矩阵数量乘法</p>
<p>可以证明完全满足十条性质</p>
<p>而这个向量空间中的每一个元素, 我们也可以将其称之为向量, 只不过这里的每一个向量是一个2 * 2的方阵</p>
<br>

<p>在这两种运算下</p>
<p>更广泛地, 所有n阶方阵, 构成一个向量空间</p>
<p>所有m * n的矩阵, 构成一个向量空间,</p>
<p>但所有的二阶方阵<strong>和</strong>三阶方阵, 不构成一个向量空间, 因为阶数不同矩阵无法相加</p>
<br>

<h3 id="例二"><a href="#例二" class="headerlink" title="例二"></a>例二</h3><p>另一个例子:</p>
<p>所有多项式, 构成了一个向量空间</p>
<p><img src="/Blog/Blog/intro/what_is_vector_space_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><strong>加法</strong>: 多项式加法;     <strong>数量乘法</strong>: 多项式乘以一个数</p>
<p>矩阵必须同形才能进行加法, 而对于多项式, 即使阶数不同也可以相加</p>
<p>这个空间满足向量空间这个定义, 这意味着我们可以把每一个多项式看作是一个向量, 同时意味着我们在线性代数中学到的很多向量空间的性质可以应用到多项式这个集合中的</p>
<br>

<h3 id="例三"><a href="#例三" class="headerlink" title="例三"></a>例三</h3><p><img src="/Blog/Blog/intro/what_is_vector_space_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>下面那个, 不满足加法的封闭性</p>
<p>当然, 这么说的前提是默认对加法的定义是矩阵的加法</p>
<br>

<p><img src="/Blog/Blog/intro/what_is_vector_space_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<blockquote>
<p>某类函数构成的向量空间叫做函数空间</p>
</blockquote>
<br>

<br>

<h2 id="子空间"><a href="#子空间" class="headerlink" title="子空间"></a>子空间</h2><p>空间本身是一个集合, 子空间就是空间这个集合的子集, 不过通常在线性代数领域讨论子空间通常讨论向量子空间或子的向量空间</p>
<br>

<blockquote>
<p>线性代数中, 只对向量空间感兴趣, 所以一般提到空间都指的是向量空间</p>
</blockquote>
<p>定义: </p>
<p><strong>假设 V 是一个向量空间, 如果 S 是 V 的子集, 且 S 还是一个向量空间</strong></p>
<p><strong>则称 S 是 V 的一个子空间</strong></p>
<br>

<p>例如</p>
<p><img src="/Blog/Blog/intro/vector_subspace.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>它满足: S是V的子集, 同时S还是向量空间</p>
<p><img src="/Blog/Blog/intro/vector_subspace_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>虽然S是V的子集, 但S不是V的子空间, 因为S不满足向量空间的定义</p>
<br>

<p>判断S是不是V的子集很简单, 但是判断S是否满足向量空间的定义却很麻烦, 要满足十条性质</p>
<p>因此本节的重点就是要介绍和子空间相关的非常重要的定理</p>
<p>就是把上面的条件替换为下面的条件</p>
<p><img src="/Blog/Blog/intro/important_rule_subspace.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>这条定理告诉我们, 判断S是不是一个子空间并不需要把那十条性质都判断一遍, 只需要判断这两条就好了</p>
<p>这也是之前说<strong>封闭性</strong>非常重要的原因, 它是其他性质的基石</p>
<p><img src="/Blog/Blog/intro/important_rule_subspace_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>很多书只把这条性质以定义的方式进行介绍, 而对于工科证明这条性质确实没有太大用途, 但这里还是想证明一下</p>
<h3 id="证明-1"><a href="#证明-1" class="headerlink" title="证明:"></a>证明:</h3><h4 id="证明之前-理清思路"><a href="#证明之前-理清思路" class="headerlink" title="证明之前, 理清思路"></a>证明之前, 理清思路</h4><p>我们要证明S满足十大性质</p>
<p><img src="/Blog/Blog/intro/important_rule_subspace_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>证明之前先重新看一下向量空间的十大性质</p>
<p><img src="/Blog/Blog/intro/ten_rules_for_vec_space_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>再看蓝色的六条性质, 这六个性质其实和是不是子空间并没有关系, 这六条性质本质描述的是<strong>加法和数量乘法</strong>这<strong>两种运算</strong>的性质</p>
<p>而如果V是一个向量空间, 那么<strong>在V上我们肯定对其中的向量定义了向量的加法和数量乘法</strong>, 而这些<strong>加法和数量乘法就肯定满足这6条性质</strong>, 而<strong>S是V的子空间</strong>, 所以这些<strong>运算是没有变化</strong>的, 依然满足这6个性质</p>
<br>

<p>所以对这十大性质我们只要证明黑色的两条即可</p>
<p>即: 证明存在零向量和负向量</p>
<p>即对于u属于S</p>
<ul>
<li>存在O属于S, 使得 u + O &#x3D; u</li>
<li>对每一个 u 存在 -u 属于S, 使得 u + (-u) &#x3D; O</li>
</ul>
<br>

<h4 id="向量空间的性质"><a href="#向量空间的性质" class="headerlink" title="向量空间的性质"></a>向量空间的性质</h4><p>证明之前先看一下向量空间的两条性质</p>
<p>很快我们就会发现, 当我们把向量空间的两条性质证明出来后, 我们证明S满足这两条性质是非常容易的</p>
<br>

<h5 id="证明-0u-x3D-O"><a href="#证明-0u-x3D-O" class="headerlink" title="证明: 0u &#x3D; O"></a>证明: 0u &#x3D; O</h5><br>

<p>若V是一个向量空间, 则满足</p>
<ul>
<li>存在O属于向量空间, 使得u + O &#x3D; u</li>
<li>如果u属于V, k是一个实数, 则ku属于V</li>
</ul>
<p>下面我们要证明的一个性质就是:</p>
<p><strong>既然ku属于V, 当k&#x3D;0时, 证明 0u &#x3D; O</strong></p>
<p>即 0u 的结果满足u + O &#x3D; u</p>
<p>这个结论看起来很简单, 但这其实是因为大家熟悉欧几里得空间的表示, 但是向量空间中O向量的定义是u + O &#x3D; u, 并没有说零向量一定等于 0u &#x3D; O</p>
<br>

<p><img src="/Blog/Blog/intro/ten_rules_for_vec_space_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<blockquote>
<p>证明本身不重要, 重要的是证明的逻辑: 我们到底已知什么, 到底在证明什么, 每一步所依据的已知是什么?</p>
<p>因为我们现在面对的是更加一般化的向量空间, 所以我们能依据的只有十大性质</p>
</blockquote>
<br>

<h5 id="证明-u-x3D-1u"><a href="#证明-u-x3D-1u" class="headerlink" title="证明: -u &#x3D; -1u"></a>证明: -u &#x3D; -1u</h5><br>

<p>若V是一个向量空间, 则满足</p>
<ul>
<li>对于每一个u存在-u, 使得u + -u &#x3D; O</li>
<li>如果u属于V, k是一个实数, 则ku属于V</li>
</ul>
<p>下面我们要证明的一个性质就是:</p>
<p><strong>既然ku属于V, 当k&#x3D;-1时, 证明 -u &#x3D; -1u</strong></p>
<p>-u只是符号而已表示u的反向量, 我们只知道它存在, 但不知道它到底是谁</p>
<br>

<p><img src="/Blog/Blog/intro/ten_rules_for_vec_space_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>u + (-1u) &#x3D; O &#x3D; u + (-u)</p>
<p>因此, -1u &#x3D; -u</p>
<br>

<h3 id="开始证明"><a href="#开始证明" class="headerlink" title="开始证明"></a>开始证明</h3><p>回过头看要证明什么</p>
<p><img src="/Blog/Blog/intro/proof_subspace.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs coq">既然S对数量乘法封闭, 则对于u属于S<br> <span class="hljs-number">0</span>u 属于 S =&gt;  O 属于 S<br><span class="hljs-number">-1</span>u 属于 S =&gt; -u 属于 S<br></code></pre></td></tr></table></figure>

<br>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本节主要证明:</p>
<p>假设V是一个<strong>向量空间</strong>, 如果S是V的子集, 且<strong>S对加法和数量乘法封闭</strong>, 则称S是V的一个子空间</p>
<br>

<p>因此V的任何<strong>子空间</strong>都一定包含O</p>
<p>对于V的子空间S, 如果u属于S, 则-u一定属于S</p>
<br>

<br>

<h2 id="直观理解欧几里得空间的子空间"><a href="#直观理解欧几里得空间的子空间" class="headerlink" title="直观理解欧几里得空间的子空间"></a>直观理解欧几里得空间的子空间</h2><p><img src="/Blog/Blog/intro/direct_understand_subspace.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>以二维平面 (二维欧几里得空间) 为例</p>
<p><img src="/Blog/Blog/intro/space_example.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>我们在这个平面过原点画一条直线, 这条直线就是该平面的一个子空间</p>
<p><img src="/Blog/Blog/intro/space_example_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这条直线其实是向量的集合</p>
<br>

<p>很容易看出来, 这条直线是整个空间的一个子集, 同时它也是对加法和数量乘法封闭(加法和数量乘法的结果还猜这条直线上)</p>
<p>因此我们可以说这条直线是整个二维平面的子空间</p>
<br>

<p><img src="/Blog/Blog/intro/space_example_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>反例: 子空间一定要存在零向量(过原点); 同时如果u在子空间中, -u也一定在子空间中</p>
<br>

<p>在二维平面中, 任意一个<strong>过原点的直线</strong>都是该二维平面的子空间</p>
<p>对三维空间来说:</p>
<p>**过原点的一个平面(无限延伸的平面)**是三维空间的一个子空间</p>
<p>过原点的一个直线, 也是三维空间的一个子空间</p>
<p>原点本身, 是三维空间的一个子空间</p>
<br>

<p><strong>对于n维空间:</strong></p>
<p><strong>过原点的一个m维空间 (m&lt;&#x3D;n), 是n维空间的一个子空间</strong></p>
<blockquote>
<p>子空间的应用: 机器学习降维</p>
</blockquote>
<br>

<br>

<h2 id="维度"><a href="#维度" class="headerlink" title="维度"></a>维度</h2><p>虽然我们经常说n维空间, 但维度到底是什么意思? 我们一直没有进行严谨准确的数学定义</p>
<p>空间的基:  一组向量:  1)  生成空间; 2)  线性无关</p>
<br>

<p><strong>维度的定义:</strong></p>
<p>一个空间的基中, 向量的个数, 称为<strong>维度</strong></p>
<p><img src="/Blog/Blog/intro/linear_algebra_dim_def.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>dim 是 维度(dimension) 的缩写</p>
<br>

<p>这里有一个疑问, 一个空间是有无数个基的 ( 除了只包含零向量的空间, 这个空间只有一个基 ), 这里我们只举出**标准正交基(标准单位向量)**的例子, 我们怎么知道这个空间中其余的基中向量的个数和标准正交基的个数是一致的呢?</p>
<p>之前我们介绍空间的基的定义时其实说过, n个向量这个条件是多余的</p>
<p><img src="/Blog/Blog/intro/space_basics.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>n维说明我们当前探讨的欧几里得空间中的元素是含有n个数字的有序实数元组, <strong>若想生成空间, 向量个数就要 &gt;&#x3D; n, 若想线性无关, 向量个数就要 &lt;&#x3D; n,</strong> 因此这两个条件合在一起, 这组向量就一定有n个</p>
<p>因此, 对于任何一个(欧几里得)空间的任何一组基, 其中的向量个数是相同的</p>
<p>上一章我们证明过适用于欧几里得空间, 但这个结论其实更加深刻, 它可以拓展到所有向量空间中: <strong>任何一个向量空间, 它可以有无数组基, 每一个基的向量个数一定是相同的</strong></p>
<br>

<h3 id="子空间和维度"><a href="#子空间和维度" class="headerlink" title="子空间和维度"></a>子空间和维度</h3><p>对于欧几里得空间, 每一个元素里面有几个数字我们就说它的维度是多少</p>
<p>站在整个欧几里得空间的角度来讲是没有错的, 但是一旦我们涉及到子空间, 这个说法就有问题了</p>
<p><img src="/Blog/Blog/intro/subspace_dim.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这条直线是这个二维空间的一个子空间, 同时这条线上的元素都是包含两个数字的</p>
<p>任何一个这条直线上的非零向量, 都可以<strong>生成</strong>这条直线 (子空间)上所有的向量</p>
<p>因此根据定义, 这个子空间的维度为1, 虽然这个子空间上所有的点(元素)都是包含两个数字的(因为这条直线是镶嵌在二维平面中的)</p>
<p><img src="/Blog/Blog/intro/subspace_dim_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>一个欧几里得空间的任何一组基, 其中向量的个数是相同的.</p>
<p>一个欧几里得空间的维度是固定的.</p>
<p>一个欧几里得空间中的每一个有序实数元组包含n个元素, 这个空间的维度**不一定(子空间的概念)**是n</p>
<br>

<p>很自然地我们会思考这样的问题:</p>
<p>被向量 u &#x3D; (2, 0, 0); v &#x3D; (-1, 0, 0); w &#x3D; (0, 0, 1)生成的空间, 维度是多少?</p>
<p>这三个向量生成的空间不一定是三维的, 也可能是二维或者一维.<br>因此要回答这个问题要从维度的定义出发,<br>我们要看被这三个向量生成的空间的基中, 有多少个向量</p>
<p>回忆:</p>
<p><img src="/Blog/Blog/intro/property_space_base_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>找这个子集的方法: 每一次从这个子集中删除一个和其他向量线性相关的向量, 直到不能再删除为止</p>
<p>套到问题中: 显然 u 和 v 线性相关, 所以可以删除u ( 或v )</p>
<p>v 和 w 线性无关, 所以这个生成空间的<strong>维度为2</strong></p>
<br>

<p>直观理解:</p>
<p><img src="/Blog/Blog/intro/subspace_dim_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>v 和 w 是在一条直线上的, 整体生成空间是一个平面</p>
<br>

<p><img src="/Blog/Blog/intro/subspace_dim_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>虽然我们不敢肯定u, v, w三个向量的生成空间一定为3. 但我们知道其生成空间一定是三维空间的子空间</p>
<p>一组三维向量的生成空间无论如何都不可能是四维空间</p>
<p><img src="/Blog/Blog/intro/subspace_dim_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="行空间和矩阵的行秩"><a href="#行空间和矩阵的行秩" class="headerlink" title="行空间和矩阵的行秩"></a>行空间和矩阵的行秩</h2><p>上一小节提到的问题</p>
<p><img src="/Blog/Blog/intro/problem_from_prev.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>同理我们可以用同样的方法求一组n维向量生成空间的维度</p>
<p><img src="/Blog/Blog/intro/problem_from_prev_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>我们就可以不断删除线性相关的向量, 看最后剩下多少组向量</p>
<p>换句话说, 这个过程就是要找到<strong>这组向量有多少和其他向量线性相关</strong></p>
<br>

<p><strong>回忆: Gauss-Jordan消元法的结果的每一行, 都是原来矩阵各行的一个线性组合</strong></p>
<p><img src="/Blog/Blog/intro/linear_combin_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>当化为行最简形式后, 零行肯定出现在最下面, 而零行用向量的角度去看就是一个零向量</p>
<p>在这个例子中, 我们得到的结果就是</p>
<p><img src="/Blog/Blog/intro/problem_from_prev_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这意味着r1, r2, r3存在非零系数, 使得它们的线性组合的结果为0</p>
<p>换句话说, 这三个向量是线性相关的</p>
<p>而Gauss-Jordan消元法的过程中, 其实只进行Gauss消元法的过程, 所以r3前面的系数肯定为1. 高斯消元法是上面的主元行乘以某个倍数加当前行来消元, 所以当前行的系数肯定为1.</p>
<p>所以这个式子可以写成</p>
<p><img src="/Blog/Blog/intro/problem_from_prev_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>即 r3 可以表示为 r1 和 r2 的线性组合, 因此我们可以把 r3 删除掉</p>
<br>

<p>更进一步, 如果我们进行Gauss-Jordan消元一个有m行的矩阵, 下面x行都为 0 行, 这就意味着, 这 x 行所以应的行向量都可以表示成上面 m-x 行行向量的线性组合</p>
<p>所以这x个最终为零向量的向量都可以删去</p>
<p><img src="/Blog/Blog/intro/line_space.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p><img src="/Blog/Blog/intro/line_space_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="行空间和列空间"><a href="#行空间和列空间" class="headerlink" title="行空间和列空间"></a>行空间和列空间</h3><p><img src="/Blog/Blog/intro/line_space_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>例子:</p>
<p><img src="/Blog/Blog/intro/line_space_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>本小节, 我们主要聚焦在行空间上.</p>
<p>m 行 n 列, 行空间是 n 维空间的子集</p>
<p>行空间的维度 &lt;&#x3D; n</p>
<p>具体怎么求? &#x3D;&gt; 求矩阵<strong>行最简形式的非零行数量</strong></p>
<br>

<p>一个矩阵的行最简形式的非零行数量很重要</p>
<p>无论是增广矩阵还是系数矩阵, rref的非零行个数其实就是整个方程组的约束数, 或者说整个方程组<strong>化简后剩下的方程数</strong>, 剩下的方程数和未知数的关系就生成了方程组解的结构</p>
<br>

<h3 id="行秩-Row-Rank"><a href="#行秩-Row-Rank" class="headerlink" title="行秩 (Row Rank)"></a>行秩 (Row Rank)</h3><p>由于矩阵的行最简形式的非零行数量很重要, 因此我们给他一个名字:</p>
<p><strong>一个矩阵的行最简形式的非零行数量成为矩阵的行秩 (Row Rank)</strong></p>
<p>行空间的维度, 为矩阵的行秩</p>
<p>注意行秩和维度作用的<strong>对象</strong>是不同的. 空间是没有行秩的, 只有矩阵有行秩, 但矩阵是没有维度的. 但行秩和维度间存在着这样的联系</p>
<br>

<h4 id="如何求矩阵行空间的基"><a href="#如何求矩阵行空间的基" class="headerlink" title="如何求矩阵行空间的基"></a>如何求矩阵行空间的基</h4><p>更近一步, 如何求出空间的一组基?</p>
<p>非常简单, 当化为行最简形式后, 最终得到的非零行的行向量, 就是这个矩阵行空间的一组基</p>
<p><img src="/Blog/Blog/intro/line_space_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h5 id="证明-2"><a href="#证明-2" class="headerlink" title="证明:"></a>证明:</h5><p><img src="/Blog/Blog/intro/line_space_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>对于矩阵R来说, 所有非零向量已经是线性无关的, 接下来只要<strong>证明A的行空间就是R的行空间</strong>, 就说明 R 的非零行的行向量是空间中的一组基</p>
<br>

<p><strong>证明A的行空间就是R的行空间</strong></p>
<blockquote>
<p>有点像集合论中的证明方式</p>
<p>如果想证明两个集合a,b相等, 就要证明a是b的子集, b是a的子集</p>
<p>即a中所有元素都在b中, b中所有元素都在a中</p>
</blockquote>
<p>这里我们证明:</p>
<p><strong>A的行空间的每一个向量, 都在R的行空间中</strong></p>
<p><strong>R的行空间的每一个向量, 都在A的行空间中</strong></p>
<p>就可以证明A的行空间等于R的行空间了 (空间就是向量的集合)</p>
<br>

<p>显然是有这样的关系的</p>
<p>A的行空间中的每一个向量都是A的行向量的线性组合</p>
<p>R的每一行也是原来A的行向量的线性组合</p>
<p>很显然, A的行空间的每一个向量都可以表示为R的行向量的线性组合</p>
<p>反过来, A矩阵的每一行也可以表示为R矩阵的每一行的线性组合</p>
<p>所以, R的行空间的每一个向量都可以表示为A的行向量的线性组合</p>
<p>R 是由 A 进行Gauss-Jordan 消元得来的(初等变换), 这两个矩阵的行空间是完全一样的</p>
<p>A的行空间等于R的行空间, 而R的行空间的基就是其中的非零行(已经是行最简形式, 非零行已经线性无关了)</p>
<p><strong>一个矩阵A的行最简形式的非零行向量, 是A的行空间的一组基</strong></p>
<br>

<h3 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h3><p>对于一个矩阵</p>
<ul>
<li>行向量生成的空间, 称为<strong>行空间</strong> (Row Space)</li>
<li>m行n列, 行空间是n维空间的子空间</li>
<li>一个矩阵的行最简形式的非零行数量称为矩阵的<strong>行秩</strong> (Row Rank)</li>
<li>行空间的维度, 维矩阵的行秩</li>
<li>一个矩阵A的行最简形式的非零行向量, 是A的行空间的一组基</li>
</ul>
<br>

<br>

<h2 id="列空间"><a href="#列空间" class="headerlink" title="列空间"></a>列空间</h2><p>从一个问题出发:</p>
<p>被向量 u &#x3D; (2, 0, 0); v &#x3D; (-1, 0, 0); w &#x3D; (0, 0, 1) 生成的空间, 维度是多少?</p>
<p>看这组向量是否线性无关</p>
<p><img src="/Blog/Blog/intro/col_space.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>因此, 现在的任务就变成了看这个线性方程组是否只有唯一解</p>
<br>

<p>因此, 这个问题又转化成了求解 <strong>线性方程组 &#x2F; 线性系统</strong> 这样的问题</p>
<p><img src="/Blog/Blog/intro/col_space_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>对于这个线性系统, 它是一个齐次线性方程组 (因为等号右边全为0), 所以我们只要看系数矩阵就好了</p>
<p>而求解这个系统就是把它化为行最简形式</p>
<p><img src="/Blog/Blog/intro/col_space_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而这个行最简形式, 其实只包含两个主元, 相应的两列就被称为主元列</p>
<p><img src="/Blog/Blog/intro/col_space_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>自由列上的元素意味着可以随便取值, 当然可以取非零值!</p>
<p>例如第一行就可以表示为</p>
<p>​        k1 - 0.5k2 &#x3D; 0</p>
<p>即:   k1 &#x3D; 0.5k2</p>
<p>此时k2随便取一个值就对应有一个k1的值</p>
<p>这就意味着这些向量是线性相关的, 因为这些向量并不是只有唯一的零解</p>
<p><strong>自由列的个数, 为可以表示为其他向量线性组合的向量个数</strong></p>
<p>以这个例子为例, 有一个自由列k2</p>
<p>因此我们就知道 v向量可以表示为 u 和 w 的线性组合</p>
<p><strong>主元列的个数, 为线性无关的向量的个数</strong></p>
<p>因此可以很自然地推出: <strong>主元列的个数, 为维度!</strong></p>
<p>有两个主元列, 就说明这三个向量所生成的空间的维度为二</p>
<p>这和我们把这三个向量以行的形式累计起来, 按行空间的方式处理, 把它化为<strong>行最简形式</strong>看<strong>非零行的个数</strong>得到的结论是一致的</p>
<br>

<p>这里相当于我们把这三个向量按列的方式排列起来形成这样一个矩阵</p>
<p><img src="/Blog/Blog/intro/col_space_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>我们看待是这个矩阵的列空间</p>
<p><strong>主元列的个数, 为列秩 (Column Rank)</strong></p>
<br>

<h3 id="列空间的定义"><a href="#列空间的定义" class="headerlink" title="列空间的定义"></a>列空间的定义</h3><p>对于一个矩阵</p>
<ul>
<li>列向量生成的空间, 成为<strong>列空间 (Column Space)</strong></li>
<li>m行n列, 列空间是m维空间的子空间 (每一个向量都是m维的向量)</li>
<li>一个矩阵的行最简形式的主元列数称为矩阵的<strong>列秩</strong></li>
<li>列空间的维度, 为矩阵的列秩</li>
<li>行最简形式主元列的对应原矩阵的列, 是列空间的一组基</li>
</ul>
<br>

<h4 id="如何求矩阵列空间的一组基"><a href="#如何求矩阵列空间的一组基" class="headerlink" title="如何求矩阵列空间的一组基?"></a>如何求矩阵列空间的一组基?</h4><p>要回答这个问题, 我们还是要仔细分析一下求矩阵**列秩(列空间维度)**的过程</p>
<p><img src="/Blog/Blog/intro/col_space_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这个过程其实是求解这个线性系统, 将其化为行最简形式, 之后看主元列的个数</p>
<br>

<p>思考一下: 到底为什么要看主元列的个数</p>
<p>之前说过, 自由列所对应的未知数可以表达为其他未知数的线性组合(线性相关), 根据空间的基的性质, 是可以将其删掉, 其余的向量依然可以生成整个空间</p>
<p>如果把这些自由列全都删掉, 剩下的主元列就全都是<strong>线性无关</strong>的了</p>
<p><img src="/Blog/Blog/intro/col_space_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>所以主元列的对应原矩阵的列, 就是列空间的一组基</p>
<p>注意: <strong>主元列本身并不是列空间的一组基</strong>, 而是主元列对应的原矩阵的列</p>
<p>这是因为主元列在告诉我们, 经过这样的变化之后, 原矩阵的那些列是线性无关的</p>
<p>这是和行空间最大的区别</p>
<br>

<p>在求行空间的一组基的时候, 我们直接找到行最简形式中的非零行就好了</p>
<p>这是因为行最简形式中的每一行本身就是原矩阵的行进行行操作得来的, 而在上一小节也证明了: <strong>行最简形式的行空间和原矩阵的行空间本质是一个空间</strong></p>
<br>

<p>但是这个性质在列空间是不存在的</p>
<p>在解列空间的问题时, 也要解这个线性系统, 求它的行最简形式, 也在进行矩阵的初等行变化</p>
<p>而这些<strong>行变换</strong>会<strong>改变矩阵中的列</strong>所对应的这些向量的, 所以最后得到的行最简形式的列已经和原来矩阵的列没有关系了</p>
<p>所以最后的主元列和自由列都是在说未知数k1, k2, k3之间的关系</p>
<p>透过k1, k2, k3 的关系, 我们来看原矩阵中这些列之间的关系</p>
<br>

<h3 id="总结-行空间和列空间"><a href="#总结-行空间和列空间" class="headerlink" title="总结: 行空间和列空间"></a>总结: 行空间和列空间</h3><p>为了不混淆, 总结一下</p>
<p>对于一个m行n列的矩阵</p>
<ul>
<li>所有行向量生成的空间就叫<strong>行空间</strong><ul>
<li>行空间是n维空间的子空间</li>
<li>行最简形式非零行的个数为矩阵的<strong>行秩</strong></li>
<li>行空间的维度为矩阵的行秩</li>
<li><strong>行最简形式的非零行</strong>, 是行空间的一组基</li>
</ul>
</li>
<li>所有列向量生成的空间叫<strong>列空间</strong><ul>
<li>列空间是m维空间的子空间</li>
<li>行最简形式的主元列数量为矩阵的<strong>列秩</strong></li>
<li>列空间的维度为矩阵的列秩</li>
<li><strong>主元列的对应原矩阵的列</strong>, 是列空间的一组基</li>
</ul>
</li>
</ul>
<blockquote>
<p>行空间和列空间不止有区别, 下一节会介绍行空间和列空间的优美的联系, 进而引出线性代数的一个重要概念: 矩阵的秩</p>
</blockquote>
<br>

<br>

<h2 id="矩阵的秩和矩阵的逆"><a href="#矩阵的秩和矩阵的逆" class="headerlink" title="矩阵的秩和矩阵的逆"></a>矩阵的秩和矩阵的逆</h2><p>从上一章的问题出发</p>
<p><img src="/Blog/Blog/intro/matrix_rank_rev.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>矩阵的列空间就是由矩阵的列向量生成的空间, 相应的我们就希望知道矩阵的列空间的维度</p>
<p>求矩阵列空间的维度就是求矩阵的列秩, 即将矩阵看作是系数矩阵, 化为行最简形式, 看它<strong>主元列的个数</strong>, 因此该矩阵的列秩为2</p>
<br>

<p>如何求矩阵的行秩?</p>
<p>同样是这个矩阵, 使用Gauss-Jordan 消元法化为行最简形式, 看它行最简形式<strong>非零行的个数</strong>, 因此该矩阵的行秩也为2</p>
<p>即该矩阵的行秩 &#x3D; 矩阵的列秩</p>
<p>这是否是一个巧合? 这不是一个巧合, 这是一个非常重要的性质!</p>
<p><strong>矩阵的行秩 &#x3D; 矩阵的列秩</strong></p>
<br>

<h3 id="证明-矩阵的行秩等于矩阵的列秩"><a href="#证明-矩阵的行秩等于矩阵的列秩" class="headerlink" title="证明: 矩阵的行秩等于矩阵的列秩"></a>证明: 矩阵的行秩等于矩阵的列秩</h3><p>对于一个 m*n 的矩阵, 无论我们要求矩阵的行秩还是列秩都要把它化为行最简形式</p>
<p>只不过行秩我们看非零行的个数, 列秩我们看主元列的个数</p>
<p><img src="/Blog/Blog/intro/rref.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>对于行最简形式来说, 如果有零行, 那么零行一定在行最简形式的最下面</p>
<p>之后可以把主元列和自由列也区分开</p>
<p>对于特殊的矩阵还要进行一次列变换交换两列的位置</p>
<p><img src="/Blog/Blog/intro/rref_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>最终肯定可以变成这个样子</p>
<p><img src="/Blog/Blog/intro/rref_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而此时这个矩阵的左上角就是一个单位矩阵</p>
<p>我们任何一个矩阵, 经过消元和列变换, 最终肯定会变成这个样子</p>
<br>

<p>关键就是左上角是一个单位矩阵</p>
<p>单位矩阵一定是方阵, 它有 r 行(矩阵行秩为 r), 那么对应的单位矩阵就就一定有 r 列(矩阵列秩为 r)</p>
<p><img src="/Blog/Blog/intro/rref_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>这里对于这个矩阵, 广义的来说, 其实我们是把它解释成了这个样子</p>
<p><img src="/Blog/Blog/intro/rref_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>我们把主元列凑在一起最终形成单位矩阵 I, 把自由列都放在后面形成矩阵F, 因为I是方阵, r行r列, 所以我们就得到了矩阵的行秩等于矩阵的列秩</p>
<br>

<h3 id="矩阵的秩"><a href="#矩阵的秩" class="headerlink" title="矩阵的秩"></a>矩阵的秩</h3><p>因此对于矩阵来说, 行秩和列秩是完全相等的</p>
<p>行秩: 行最简形式的非零行数</p>
<p>列秩: 行最简形式的主元列数</p>
<p>因此我们完全可以不区分这两个概念了, 直接称它们为<strong>矩阵的秩(Rank)</strong></p>
<br>

<p>这就意味着对于任意一个矩阵, <strong>它的行空间和列空间维度相等</strong></p>
<p>而对于一个m * n的矩阵来说, 行空间是n维空间的子空间, 列空间是m维空间的子空间. </p>
<br>

<p>矩阵的秩 &#x3D; 矩阵的行秩 &#x3D; 矩阵的列秩</p>
<p>有什么意义?</p>
<p>很多时候可以快速的做出一些基本判断</p>
<p>例如:</p>
<p>u &#x3D; (1, 1, 2), v &#x3D; (2, 2, 3), w &#x3D; (3, 3, 4) 的生成空间的维度?</p>
<p>无所谓用 (行&#x2F;列) 的方式组成矩阵</p>
<p><img src="/Blog/Blog/intro/rank.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>就是求这个矩阵行空间的维度, 我们就可以说这个行空间的维度最大只能为2.</p>
<p>因为对于这个矩阵, 从列的视角来看, 前两列完全一样, 所以这个矩阵的列秩不可能为3 一定小于等于2, 行秩等于列秩, 所以行秩小于等于2</p>
<p>因此这三个向量肯定是线性相关的</p>
<br>

<p>方阵的秩</p>
<p>这矩阵的秩我们并没有限制它为方阵. 但现在我们把它放入方阵中探讨一下</p>
<p><img src="/Blog/Blog/intro/square_rank.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>对于一个n阶方阵(n行n列)</p>
<p>行空间是n维空间的子空间</p>
<p>列空间是n维空间的子空间</p>
<br>

<p>此时我们就对一种情况感兴趣了</p>
<p>什么时候行空间和列空间都是n维空间?</p>
<p>即矩阵的秩 r &#x3D; n</p>
<p>我们称这样的方阵为<strong>满秩</strong>的方阵**(Full Rank)**</p>
<p>满秩的情况下, 非零行的个数为n, 主元列的个数也为n, 每一行都死非零行, 每一列都是主元列</p>
<p>那么它的行最简形式一定是<strong>单位矩阵</strong> I</p>
<br>

<p>对于方阵A来说有诸多等价命题</p>
<p><img src="/Blog/Blog/intro/matrix_properity.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>rref(A) &#x3D; I</p>
<p>我们此时又可以往里添加新的内容了</p>
<br>

<p>首先根据最后两个命题可以得到: <strong>方阵A的列向量是n维空间的基</strong></p>
<p>因为方阵A的列向量<strong>生成n维空间</strong>同时<strong>线性无关</strong></p>
<br>

<p>其次因为rref &#x3D; I, 所以根据本小节所讲述:</p>
<p><strong>A为满秩矩阵 ( 秩 &#x3D; n )</strong></p>
<p>A 的行秩为 n</p>
<p>A 的列秩为 n</p>
<p>A 的行空间是 n维空间</p>
<p>A 的列空间是 n维空间</p>
<br>

<h3 id="小结-6"><a href="#小结-6" class="headerlink" title="小结"></a>小结</h3><p>矩阵的行秩等于矩阵的列秩, 我们统称矩阵的秩</p>
<p>在方阵中, 我们引入满秩的概念</p>
<p>它和前面矩阵A可逆等诸多命题等价</p>
<p><img src="/Blog/Blog/intro/properties_for_squear.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="零空间与看待零空间的三个视角"><a href="#零空间与看待零空间的三个视角" class="headerlink" title="零空间与看待零空间的三个视角"></a>零空间与看待零空间的三个视角</h2><p>零空间不同于行空间和列空间, 不能通过一个显示的矩阵获得</p>
<p>本小节要证明一个重要的结论:</p>
<p><strong>一个齐次线性方程组的所有解, 形成一个向量空间</strong></p>
<br>

<p><img src="/Blog/Blog/intro/harmong_matrix.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>一个齐次方程组一定有解, 或者有唯一零解</p>
<p>一个空间如果只有零向量一个向量, 它是一个向量空间</p>
<br>

<p>问题是如何证明在有无数解的情况下, 这无数个解形成一个向量空间</p>
<p>如果系数矩阵为m * n的矩阵, 解为n维向量</p>
<p>因此如果解形成向量空间, 则该向量空间是n维空间的一个<strong>子空间</strong></p>
<br>

<p>回忆: 在介绍子空间时, 我们证明过一个重要的结论:</p>
<p>假设V是一个向量空间, 如果S是V的子集, <strong>且S对加法和数量乘法封闭</strong>, 则称S是V的一个子空间</p>
<p>因此只需要证明齐次线性方程组的解所组成的空间对加法和数量乘法封闭</p>
<br>

<p><strong>加法封闭:</strong></p>
<p><img src="/Blog/Blog/intro/zero_space_proof_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><strong>乘法封闭:</strong></p>
<p><img src="/Blog/Blog/intro/zero_space_proof_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="零空间"><a href="#零空间" class="headerlink" title="零空间"></a>零空间</h3><p>因此<strong>一个齐次线性方程组的所有解, 形成一个向量空间</strong></p>
<p>称这个空间, 为<strong>零空间</strong> (Null Space)</p>
<p><strong>矩阵A的零空间, 就是Ax &#x3D; 0中, 所有x组成的空间.</strong></p>
<blockquote>
<p>一般教材介绍到这就结束了, 只用代数的视角满足以上条件的空间就是零空间, 但为了更加感性地理解, 这里用另外两个视角进行理解 </p>
</blockquote>
<br>

<h4 id="看作是向量的函数的视角"><a href="#看作是向量的函数的视角" class="headerlink" title="看作是向量的函数的视角"></a>看作是向量的函数的视角</h4><p>回忆: 我们可以把矩阵看作是向量的函数 (转换函数)</p>
<p>如果使用这个视角来看零空间的定义, 我们可以把A这个系数矩阵看作是一个转换函数</p>
<p>此时x形成的空间就是: 在A的转换下, 可以被映射到零点的这样的向量, 所形成的集合</p>
<p><strong>零空间是一个集合, 集合中的所有的向量, 在A的变换下, 都将映射到零点</strong></p>
<br>

<h4 id="看作是空间"><a href="#看作是空间" class="headerlink" title="看作是空间"></a>看作是空间</h4><p>回忆: 我们可以把矩阵看作是空间</p>
<p>零空间是一个集合, 这个集合的所有的向量, 和A的<strong>行向量</strong>点乘的结果为0</p>
<p><img src="/Blog/Blog/intro/zero_space_proof_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>更进一步, 这个集合中的所有向量, 和A的<strong>行空间中所有向量</strong>点乘结果为0!</p>
<blockquote>
<p> A的行空间就是A的行向量所有线性组合可以生成的向量</p>
</blockquote>
<p>而点乘为0意味着: 这个集合中的所有向量, 和A的行空间中的所有向量<strong>垂直(正交)</strong></p>
<p>这就说明, 这个集合和A的行空间正交. 换句话说, A的零空间和A的行空间正交</p>
<br>

<h3 id="可视化地看什么是两个空间相垂直"><a href="#可视化地看什么是两个空间相垂直" class="headerlink" title="可视化地看什么是两个空间相垂直"></a>可视化地看什么是两个空间相垂直</h3><p>A的零空间和A的行空间正交是指:</p>
<p>A的零空间中所有的向量, 和A的行空间中所有向量垂直</p>
<p><img src="/Blog/Blog/intro/zero_space_proof_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>两个二维平面在三维空间中是不可能正交的, 它们有一条线重合, 便说明这条线上的向量同属于两个屏幕且不互相垂直</p>
<br>

<h3 id="小结-7"><a href="#小结-7" class="headerlink" title="小结"></a>小结</h3><p><img src="/Blog/Blog/intro/zero_space_proof_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="零空间的基-与-秩-零化度定理"><a href="#零空间的基-与-秩-零化度定理" class="headerlink" title="零空间的基 与 秩-零化度定理"></a>零空间的基 与 秩-零化度定理</h2><h3 id="零空间的维度和基"><a href="#零空间的维度和基" class="headerlink" title="零空间的维度和基"></a>零空间的维度和基</h3><p>零空间的维度是多少?  能否给出一组基?</p>
<br>

<p>由于零空间是齐次线性方程组所有的解构成的空间, 所以先从解齐次线性方程组开始</p>
<p>解齐次线性方程组就是用Gauss-Jordan消元法将其化为行最简形式</p>
<p><img src="/Blog/Blog/intro/base_null_space.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>而这个行最简形式意味着:</p>
<p><img src="/Blog/Blog/intro/base_null_space_1.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>由于最后一行是零向量, 这就意味着对于x3没有任何约束</p>
<p>进而就可以将其写为:</p>
<p><img src="/Blog/Blog/intro/base_null_space_2.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<p>零空间是指齐次线性方程组的解组成的空间, 每一个解其实都是一个向量</p>
<p><img src="/Blog/Blog/intro/base_null_space_3.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这个形式就可以表示之前那个齐次线性方程组的所有解向量</p>
<p>它本质就是(-7, -5, 1)这个向量的所有线性组合</p>
<p>换句话说, 这个解的形式是一个维度为1的子空间, 其一组基为(-7, -5, 1)</p>
<br>

<p>另一个例子:</p>
<p><img src="/Blog/Blog/intro/base_null_space_4.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p><img src="/Blog/Blog/intro/base_null_space_5.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>解向量就长这样</p>
<p><img src="/Blog/Blog/intro/base_null_space_6.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>更进一步</p>
<p><img src="/Blog/Blog/intro/base_null_space_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>这其实就是这四个向量的<strong>生成空间</strong>, 就是这四个向量的<strong>线性组合</strong>能表示出来所有的向量, 也就是这个<strong>齐次线性方程组所有的解</strong></p>
<p>也就是说这个生成空间就是这个矩阵的零空间</p>
<p>显然这个零空间的维度为4, 这四个向量线性无关(可以从最后4行看出, 一个向量不能表示成其他向量的线性组合), 因此他们的生成<strong>空间的基</strong>一共包含4个向量, 也就是说零空间的维度为4</p>
<br>

<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结:"></a>总结:</h4><p>在行最简形式, 主元列有2个, 自由列有4个. 4个自由列对应4个未知数. 每个自由列是一个自由元, 可以随便取值. 随便取的值都和某个向量相乘在相加就形成了齐次线性方程组的解空间</p>
<p><img src="/Blog/Blog/intro/base_null_space_7.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>具体这些向量是如何构造的? 这个向量分为两部分</p>
<p>上面的部分其实就是自由列中非零行对应的那一部分的相反数, 因为他们原本是x1+…+xn&#x3D;0, 把除x1以外的项移到等号右边就会变号, 因此是取相反数</p>
<p>下面的部分何在一起就是一个单位矩阵, 每一个向量的这一部分用于控制一个自由元</p>
<p>这样我们就得到了四个向量, 而这四个向量是线性无关的, 所以他们就是解空间的基中包含的四个向量, 就是<strong>零空间的基中包含的四个向量</strong>, 零空间的维度为4</p>
<p><strong>零空间的维度就看自由列有多少列, 零空间的基本质是先找到解空间, 对解空间进行简单变形之后便可以看到解空间是若干列的线性组合, 这些列就是零空间的基</strong></p>
<p>更为重要的:</p>
<p><img src="/Blog/Blog/intro/base_null_space_8.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<h3 id="秩-零化度定理"><a href="#秩-零化度定理" class="headerlink" title="秩-零化度定理"></a>秩-零化度定理</h3><p>列空间的维度 + 零空间的维度 &#x3D; n</p>
<p><strong>秩(Rank) + 零化度(Nullity) &#x3D; n</strong></p>
<br>

<h3 id="列空间和零空间的关系"><a href="#列空间和零空间的关系" class="headerlink" title="列空间和零空间的关系"></a>列空间和零空间的关系</h3><p>对于一个m * n的矩阵</p>
<table>
<thead>
<tr>
<th align="center">列空间</th>
<th align="center">零空间</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Ax &#x3D; v (x任取)</td>
<td align="center">Av &#x3D; 0</td>
</tr>
<tr>
<td align="center">列空间是m维空间的子空间</td>
<td align="center">零空间是n维空间的子空间</td>
</tr>
<tr>
<td align="center">列空间的维度, 为行最简形式中主元列数</td>
<td align="center">零空间的维度, 为行最简形式中自由列数</td>
</tr>
<tr>
<td align="center">主元列的对应原矩阵的列, 是列空间的一组基</td>
<td align="center">求零空间的基需要求解Av &#x3D; 0</td>
</tr>
</tbody></table>
<br>

<p>何时零空间的维度为0?</p>
<p>列空间的维度为n, 相应地零空间的维度为0</p>
<p>因此对于方阵的情况下, 即为满秩的情况下, 因此等价命题表又可以添加一条</p>
<p><img src="/Blog/Blog/intro/base_null_space_9.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<br>

<br>

<h2 id="左零空间-四大子空间和为什么研究子空间"><a href="#左零空间-四大子空间和为什么研究子空间" class="headerlink" title="左零空间, 四大子空间和为什么研究子空间"></a>左零空间, 四大子空间和为什么研究子空间</h2><h3 id="四大子空间"><a href="#四大子空间" class="headerlink" title="四大子空间"></a>四大子空间</h3><p>对于m * n的矩阵A来说, 我们可以找到它的列空间, 也可以找到它的零空间. 在一些教材中, 可能会用符号来表示他们</p>
<p><img src="/Blog/Blog/intro/4_subspace.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>行空间并不是写作Row(A), 我们更喜欢把向量表示为<strong>列向量</strong>的样子, 这样按列排列完之后, 在乘以一个向量就是这些<strong>列的线性组合</strong></p>
<p>因此我们打算用列空间的符号来表示行空间: Col (A的转置)</p>
<br>

<p>如图中所示, 既然有Null (A) 那么也应该有对应的Null (A的转置)</p>
<p>我们称这个空间为<strong>左零空间</strong>, 而正如零空间与行空间正交, <strong>左零空间则是和列空间正交</strong></p>
<br>

<h3 id="左零空间"><a href="#左零空间" class="headerlink" title="左零空间"></a>左零空间</h3><p>为什么称 Null (A的转置) 为左零空间</p>
<p><img src="/Blog/Blog/intro/left_null_space.PNG" srcset="/Blog/img/loading.gif" lazyload></p>
<p>满足 <strong>x的转置左乘A等于0</strong> 这个条件的x所在的空间</p>
<p>因此称为左零空间</p>
<blockquote>
<p>左零空间的维度为m-r</p>
<p>能否求出左零空间的一组基?</p>
<p>可以, 但是这个问题超出了课程的范畴, 稍微有一些复杂. 很多教科书甚至都不会涉及左零空间</p>
<p>这里了解这个概念就好了</p>
</blockquote>
<br>

<h3 id="为什么要研究子空间"><a href="#为什么要研究子空间" class="headerlink" title="为什么要研究子空间?"></a>为什么要研究子空间?</h3><br>

<p>子空间维度大大降低</p>
<p>机器学习中很多问题, 我们接触的数据通常是极其<strong>高维</strong>的数据</p>
<p>而在这么高的维度上, 一方面难以分析, 另一方面计算的性能低, 而且搞不好在这么高的维度上分析的结果也不够好(<strong>维度灾难</strong>)</p>
<p>因此如果我们能够降维的话, 找到更低维度的空间, 在这个空间中我们表示数据误差并不多的话, 我们便更倾向于在这个子空间里研究问题</p>
<p>而<strong>四大子空间</strong>便是构成更加复杂的降维子空间的基础</p>
<br>

<p>是其他应用的基础</p>
<p>之前也说过, 生活中很多问题都可以抽象为Ax&#x3D;b这样一个线性系统, 我们就是要求解出x等于多少</p>
<p>但在真实的世界中, 矩阵A很有可能是有很多行的, 因为我们会疯狂采样, 我们倾向于认为采样越多越能反应真实的情况(大数据), 我们探究一些特征(未知数的数量)和我们探究的结果之间的关系. </p>
<p>因此大概率的矩阵A的行数大于列数, 大多数情况都是无解的 (方程数大于未知数的个数就很可能产生矛盾)</p>
<p>而这种无解不一定是这个问题无解, 有可能是有各种误差. 或者描述问题的模型本身就不准确. 然而如果得到一个差不多的解即可的情况下.</p>
<p>不看b只看Ax, Ax就是这个矩阵的列空间. x的每一个未知数都可以和A的每一列相乘在相加, 最终得到一个结果. 我们要在列空间中找是否有一个向量是b向量. 当行数大于列数大概率是找不到的, 因此我们必须让b这个向量在列空间中. 这样纵使A的行数大于列数, 也是有解的.</p>
<p>因此在实际中我们解决这个问题的方式是: 找A的列空间中离b最近的b’</p>
<p>转而求解Ax&#x3D;b’ , 用这个等式的解来近似Ax&#x3D;b的解</p>
<p>若想找到b’我们必须了解A的列空间在哪里</p>
<br>
            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/Blog/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/Blog/tags/%E6%95%B0%E5%AD%A6/">数学</a>
                    
                      <a class="hover-with-bg" href="/Blog/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/Blog/2020/01/24/play-with-linear-algebra-3/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile"><专为程序员设计的线性代数>学习笔记(3)</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/Blog/2019/12/19/stat-for-programmer/">
                        <span class="hidden-mobile"><专为程序员设计的统计课>学习笔记(1)</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/Blog/js/events.js" ></script>
<script  src="/Blog/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/Blog/js/local-search.js" ></script>



  
    <script  src="/Blog/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/Blog/js/boot.js" ></script>


</body>
</html>
